{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Detecting Issues in a Text Dataset with Cleanlab\n\nWorking through page in Open-source AI cookbook:\n\n[https://huggingface.co/learn/cookbook/issues_in_text_dataset](https://huggingface.co/learn/cookbook/issues_in_text_dataset)\n\n## Dataset\n\nWe are using a subset of the Banking77-OOS Dataset containing 1,000 customer service requests which are classified into 10 categories based on their intent (you can run this same code on any text classification dataset).\n\n## Overview\n\n- Use a pretrained transformer model to extract the text embeddings from the customer service requests\n- Train a simple Logistic Regression model on the text embeddings to compute out-of-sample predicted probabilities\n- Run Cleanlab’s Datalab audit with these predictions and embeddings in order to identify problems like: label issues, outliers, and near duplicates in the dataset.","metadata":{}},{"cell_type":"code","source":"!pip install cleanlab","metadata":{"execution":{"iopub.status.busy":"2024-06-02T16:41:27.213237Z","iopub.execute_input":"2024-06-02T16:41:27.213587Z","iopub.status.idle":"2024-06-02T16:41:41.000253Z","shell.execute_reply.started":"2024-06-02T16:41:27.213559Z","shell.execute_reply":"2024-06-02T16:41:40.999157Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting cleanlab\n  Downloading cleanlab-2.6.5-py3-none-any.whl.metadata (63 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy>=1.22.0 in /opt/conda/lib/python3.10/site-packages (from cleanlab) (1.26.4)\nRequirement already satisfied: scikit-learn>=1.1 in /opt/conda/lib/python3.10/site-packages (from cleanlab) (1.2.2)\nRequirement already satisfied: tqdm>=4.53.0 in /opt/conda/lib/python3.10/site-packages (from cleanlab) (4.66.4)\nRequirement already satisfied: pandas>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from cleanlab) (2.2.1)\nRequirement already satisfied: termcolor>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from cleanlab) (2.4.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.4.0->cleanlab) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.4.0->cleanlab) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.4.0->cleanlab) (2023.4)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=1.1->cleanlab) (1.11.4)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=1.1->cleanlab) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=1.1->cleanlab) (3.2.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.4.0->cleanlab) (1.16.0)\nDownloading cleanlab-2.6.5-py3-none-any.whl (352 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m352.3/352.3 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[33mWARNING: Error parsing requirements for aiohttp: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/aiohttp-3.9.1.dist-info/METADATA'\u001b[0m\u001b[33m\n\u001b[0mInstalling collected packages: cleanlab\nSuccessfully installed cleanlab-2.6.5\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install -U scikit-learn sentence-transformers datasets\n!pip install -U \"cleanlab[datalab]\"","metadata":{"execution":{"iopub.status.busy":"2024-06-02T16:43:14.593884Z","iopub.execute_input":"2024-06-02T16:43:14.594765Z","iopub.status.idle":"2024-06-02T16:43:19.590751Z","shell.execute_reply.started":"2024-06-02T16:43:14.594728Z","shell.execute_reply":"2024-06-02T16:43:19.589731Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (1.2.2)\nCollecting scikit-learn\n  Downloading scikit_learn-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\nCollecting sentence-transformers\n  Downloading sentence_transformers-3.0.0-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.19.1)\nRequirement already satisfied: numpy>=1.19.5 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.26.4)\nRequirement already satisfied: scipy>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.11.4)\nRequirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\nRequirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (3.2.0)\nRequirement already satisfied: transformers<5.0.0,>=4.34.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.41.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.66.4)\nRequirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (2.1.2)\nRequirement already satisfied: huggingface-hub>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.23.2)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (9.5.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.13.1)\nRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (14.0.2)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.1)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.31.0)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.3.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets) (2024.3.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.1)\n\u001b[31mERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/aiohttp-3.9.1.dist-info/METADATA'\n\u001b[0m\u001b[31m\n\u001b[0mRequirement already satisfied: cleanlab[datalab] in /opt/conda/lib/python3.10/site-packages (2.6.5)\nRequirement already satisfied: numpy>=1.22.0 in /opt/conda/lib/python3.10/site-packages (from cleanlab[datalab]) (1.26.4)\nRequirement already satisfied: scikit-learn>=1.1 in /opt/conda/lib/python3.10/site-packages (from cleanlab[datalab]) (1.2.2)\nRequirement already satisfied: tqdm>=4.53.0 in /opt/conda/lib/python3.10/site-packages (from cleanlab[datalab]) (4.66.4)\nRequirement already satisfied: pandas>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from cleanlab[datalab]) (2.2.1)\nRequirement already satisfied: termcolor>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from cleanlab[datalab]) (2.4.0)\nRequirement already satisfied: datasets>=2.7.0 in /opt/conda/lib/python3.10/site-packages (from cleanlab[datalab]) (2.19.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.7.0->cleanlab[datalab]) (3.13.1)\nRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.7.0->cleanlab[datalab]) (14.0.2)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets>=2.7.0->cleanlab[datalab]) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.7.0->cleanlab[datalab]) (0.3.8)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.7.0->cleanlab[datalab]) (2.31.0)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets>=2.7.0->cleanlab[datalab]) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets>=2.7.0->cleanlab[datalab]) (0.70.16)\nRequirement already satisfied: fsspec<=2024.3.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets>=2.7.0->cleanlab[datalab]) (2024.3.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.7.0->cleanlab[datalab]) (3.9.1)\nRequirement already satisfied: huggingface-hub>=0.21.2 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.7.0->cleanlab[datalab]) (0.23.2)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets>=2.7.0->cleanlab[datalab]) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.7.0->cleanlab[datalab]) (6.0.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.4.0->cleanlab[datalab]) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.4.0->cleanlab[datalab]) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.4.0->cleanlab[datalab]) (2023.4)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=1.1->cleanlab[datalab]) (1.11.4)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=1.1->cleanlab[datalab]) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=1.1->cleanlab[datalab]) (3.2.0)\n\u001b[31mERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/aiohttp-3.9.1.dist-info/METADATA'\n\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"pip install -U sentence-transformers","metadata":{"execution":{"iopub.status.busy":"2024-06-02T16:44:03.214556Z","iopub.execute_input":"2024-06-02T16:44:03.214909Z","iopub.status.idle":"2024-06-02T16:44:16.498390Z","shell.execute_reply.started":"2024-06-02T16:44:03.214879Z","shell.execute_reply":"2024-06-02T16:44:16.497169Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Collecting sentence-transformers\n  Using cached sentence_transformers-3.0.0-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: transformers<5.0.0,>=4.34.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.41.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.66.4)\nRequirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (2.1.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.26.4)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.11.4)\nRequirement already satisfied: huggingface-hub>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.23.2)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (9.5.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.3.1)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2023.12.25)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.19.1)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.3)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.2.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.15.1->sentence-transformers) (3.1.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\nDownloading sentence_transformers-3.0.0-py3-none-any.whl (224 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.7/224.7 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[33mWARNING: Error parsing requirements for aiohttp: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/aiohttp-3.9.1.dist-info/METADATA'\u001b[0m\u001b[33m\n\u001b[0mInstalling collected packages: sentence-transformers\nSuccessfully installed sentence-transformers-3.0.0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import re\nimport string\nimport pandas as pd\nfrom sklearn.metrics import accuracy_score, log_loss\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.linear_model import LogisticRegression\nfrom sentence_transformers import SentenceTransformer\n\nfrom cleanlab import Datalab","metadata":{"execution":{"iopub.status.busy":"2024-06-02T16:44:42.206203Z","iopub.execute_input":"2024-06-02T16:44:42.207116Z","iopub.status.idle":"2024-06-02T16:44:58.942137Z","shell.execute_reply.started":"2024-06-02T16:44:42.207079Z","shell.execute_reply":"2024-06-02T16:44:58.941175Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n  from tqdm.autonotebook import tqdm, trange\n2024-06-02 16:44:49.751081: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-02 16:44:49.751234: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-02 16:44:49.855726: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"import random\nimport numpy as np\n\npd.set_option(\"display.max_colwidth\", None)\n\nSEED = 123456  # for reproducibility\nnp.random.seed(SEED)\nrandom.seed(SEED)","metadata":{"execution":{"iopub.status.busy":"2024-06-02T16:45:25.298965Z","iopub.execute_input":"2024-06-02T16:45:25.299916Z","iopub.status.idle":"2024-06-02T16:45:25.305284Z","shell.execute_reply.started":"2024-06-02T16:45:25.299881Z","shell.execute_reply":"2024-06-02T16:45:25.304170Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Load and format the dataset","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\n\ndataset = load_dataset(\"PolyAI/banking77\", split=\"train\")\ndata = pd.DataFrame(dataset[:1000])\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-02T16:45:41.586740Z","iopub.execute_input":"2024-06-02T16:45:41.587738Z","iopub.status.idle":"2024-06-02T16:45:44.712831Z","shell.execute_reply.started":"2024-06-02T16:45:41.587693Z","shell.execute_reply":"2024-06-02T16:45:44.711839Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/298k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"07a1f32ab71e4798b24d2a6d12495b73"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/93.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf2f17df19de44589f92ac99bbc140d7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/10003 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6c20eba44374f44a4654f71cb140391"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/3080 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce21d9d9514f45a69021f623eaf44260"}},"metadata":{}},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                                                           text  label\n0                                I am still waiting on my card?     11\n1  What can I do if my card still hasn't arrived after 2 weeks?     11\n2    I have been waiting over a week. Is the card still coming?     11\n3   Can I track my card while it is in the process of delivery?     11\n4        How do I know if I will get my card, or if it is lost?     11","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I am still waiting on my card?</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>What can I do if my card still hasn't arrived after 2 weeks?</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I have been waiting over a week. Is the card still coming?</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Can I track my card while it is in the process of delivery?</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>How do I know if I will get my card, or if it is lost?</td>\n      <td>11</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"raw_texts, labels = data[\"text\"].values, data[\"label\"].values\nnum_classes = len(set(labels))","metadata":{"execution":{"iopub.status.busy":"2024-06-02T16:46:12.711951Z","iopub.execute_input":"2024-06-02T16:46:12.712696Z","iopub.status.idle":"2024-06-02T16:46:12.719563Z","shell.execute_reply.started":"2024-06-02T16:46:12.712662Z","shell.execute_reply":"2024-06-02T16:46:12.718638Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"print(f\"This dataset has {num_classes} classes.\")\nprint(f\"Classes: {set(labels)}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-02T16:46:20.116305Z","iopub.execute_input":"2024-06-02T16:46:20.116685Z","iopub.status.idle":"2024-06-02T16:46:20.123145Z","shell.execute_reply.started":"2024-06-02T16:46:20.116655Z","shell.execute_reply":"2024-06-02T16:46:20.121248Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"This dataset has 7 classes.\nClasses: {32, 34, 36, 11, 13, 46, 17}\n","output_type":"stream"}]},{"cell_type":"code","source":"i = 1  # change this to view other examples from the dataset\nprint(f\"Example Label: {labels[i]}\")\nprint(f\"Example Text: {raw_texts[i]}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-02T16:46:29.726107Z","iopub.execute_input":"2024-06-02T16:46:29.726785Z","iopub.status.idle":"2024-06-02T16:46:29.731705Z","shell.execute_reply.started":"2024-06-02T16:46:29.726727Z","shell.execute_reply":"2024-06-02T16:46:29.730805Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Example Label: 11\nExample Text: What can I do if my card still hasn't arrived after 2 weeks?\n","output_type":"stream"}]},{"cell_type":"markdown","source":"We will use numeric representations from a pretrained Transformer model as embeddings of our text. The Sentence Transformers library offers simple methods to compute these embeddings for text data. Here, we load the pretrained electra-small-discriminator model, and then run our data through network to extract a vector embedding of each example.","metadata":{}},{"cell_type":"code","source":"transformer = SentenceTransformer(\"google/electra-small-discriminator\")\ntext_embeddings = transformer.encode(raw_texts)","metadata":{"execution":{"iopub.status.busy":"2024-06-02T16:47:18.102105Z","iopub.execute_input":"2024-06-02T16:47:18.102803Z","iopub.status.idle":"2024-06-02T16:47:23.011649Z","shell.execute_reply.started":"2024-06-02T16:47:18.102770Z","shell.execute_reply":"2024-06-02T16:47:23.010597Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"673eb317842f450487189c73a1dcbad6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/54.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e83a7de9ab2b4135aee3110f1403730a"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83f5cb88c965428882fbc312a9a1956d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0111d57c47264cf29ee6288e6723cf2a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d5501796f3e4f30adc6735f443da5ca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/32 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf5ac6813cf548f9830b2987bb0f6262"}},"metadata":{}}]},{"cell_type":"code","source":"text_embeddings[0].shape","metadata":{"execution":{"iopub.status.busy":"2024-06-02T16:47:48.320873Z","iopub.execute_input":"2024-06-02T16:47:48.321525Z","iopub.status.idle":"2024-06-02T16:47:48.327492Z","shell.execute_reply.started":"2024-06-02T16:47:48.321495Z","shell.execute_reply":"2024-06-02T16:47:48.326518Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"(256,)"},"metadata":{}}]},{"cell_type":"markdown","source":"Our subsequent ML model will directly operate on elements of text_embeddings in order to classify the customer service requests.\n\n---\n\n","metadata":{}},{"cell_type":"code","source":"model = LogisticRegression(max_iter=400)\n\npred_probs = cross_val_predict(model, text_embeddings, labels, method=\"predict_proba\")","metadata":{"execution":{"iopub.status.busy":"2024-06-02T16:51:03.429749Z","iopub.execute_input":"2024-06-02T16:51:03.430562Z","iopub.status.idle":"2024-06-02T16:51:06.190280Z","shell.execute_reply.started":"2024-06-02T16:51:03.430531Z","shell.execute_reply":"2024-06-02T16:51:06.188954Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"}]},{"cell_type":"code","source":"data_dict = {\"texts\": raw_texts, \"labels\": labels}","metadata":{"execution":{"iopub.status.busy":"2024-06-02T16:51:31.116148Z","iopub.execute_input":"2024-06-02T16:51:31.117060Z","iopub.status.idle":"2024-06-02T16:51:31.121318Z","shell.execute_reply.started":"2024-06-02T16:51:31.117025Z","shell.execute_reply":"2024-06-02T16:51:31.120183Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"lab = Datalab(data_dict, label_name=\"labels\")\nlab.find_issues(pred_probs=pred_probs, features=text_embeddings)","metadata":{"execution":{"iopub.status.busy":"2024-06-02T16:51:58.707569Z","iopub.execute_input":"2024-06-02T16:51:58.708380Z","iopub.status.idle":"2024-06-02T16:51:59.080739Z","shell.execute_reply.started":"2024-06-02T16:51:58.708350Z","shell.execute_reply":"2024-06-02T16:51:59.079644Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Finding null issues ...\nFinding label issues ...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Finding outlier issues ...\nFitting OOD estimator based on provided features ...\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Finding near_duplicate issues ...\nFinding non_iid issues ...\nFinding class_imbalance issues ...\nFinding underperforming_group issues ...\n\nAudit complete. 62 issues found in the dataset.\n","output_type":"stream"}]},{"cell_type":"code","source":"lab.report()","metadata":{"execution":{"iopub.status.busy":"2024-06-02T16:52:15.941492Z","iopub.execute_input":"2024-06-02T16:52:15.942539Z","iopub.status.idle":"2024-06-02T16:52:15.983856Z","shell.execute_reply.started":"2024-06-02T16:52:15.942488Z","shell.execute_reply":"2024-06-02T16:52:15.982963Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Here is a summary of the different kinds of issues found in the data:\n\n    issue_type  num_issues\n       outlier          37\nnear_duplicate          14\n         label          10\n       non_iid           1\n\nDataset Information: num_examples: 1000, num_classes: 7\n\n\n---------------------- outlier issues ----------------------\n\nAbout this issue:\n\tExamples that are very different from the rest of the dataset \n    (i.e. potentially out-of-distribution or rare/anomalous instances).\n    \n\nNumber of examples with this issue: 37\nOverall dataset quality in terms of this issue: 0.3671\n\nExamples representing most severe instances of this issue:\n     is_outlier_issue  outlier_score\n791              True       0.024866\n601              True       0.031162\n863              True       0.060738\n355              True       0.064199\n157              True       0.065075\n\n\n------------------ near_duplicate issues -------------------\n\nAbout this issue:\n\tA (near) duplicate issue refers to two or more examples in\n    a dataset that are extremely similar to each other, relative\n    to the rest of the dataset.  The examples flagged with this issue\n    may be exactly duplicated, or lie atypically close together when\n    represented as vectors (i.e. feature embeddings).\n    \n\nNumber of examples with this issue: 14\nOverall dataset quality in terms of this issue: 0.5961\n\nExamples representing most severe instances of this issue:\n     is_near_duplicate_issue  near_duplicate_score near_duplicate_sets  distance_to_nearest_neighbor\n459                     True              0.009549               [429]                      0.000566\n429                     True              0.009549               [459]                      0.000566\n412                     True              0.046045               [501]                      0.002781\n501                     True              0.046045          [412, 517]                      0.002781\n698                     True              0.054626               [607]                      0.003314\n\n\n----------------------- label issues -----------------------\n\nAbout this issue:\n\tExamples whose given label is estimated to be potentially incorrect\n    (e.g. due to annotation error) are flagged as having label issues.\n    \n\nNumber of examples with this issue: 10\nOverall dataset quality in terms of this issue: 0.9930\n\nExamples representing most severe instances of this issue:\n     is_label_issue  label_score  given_label  predicted_label\n379           False     0.025493           32               11\n100           False     0.032105           11               36\n300           False     0.037746           32               46\n485            True     0.057530           17               34\n159            True     0.059512           13               11\n\n\n---------------------- non_iid issues ----------------------\n\nAbout this issue:\n\tWhether the dataset exhibits statistically significant\n    violations of the IID assumption like:\n    changepoints or shift, drift, autocorrelation, etc.\n    The specific violation considered is whether the\n    examples are ordered such that almost adjacent examples\n    tend to have more similar feature values.\n    \n\nNumber of examples with this issue: 1\nOverall dataset quality in terms of this issue: 0.0000\n\nExamples representing most severe instances of this issue:\n     is_non_iid_issue  non_iid_score\n988              True       0.563774\n975             False       0.570179\n997             False       0.571891\n967             False       0.572357\n956             False       0.577413\n\nAdditional Information: \np-value: 0.0\n","output_type":"stream"}]},{"cell_type":"code","source":"raw_texts[429], raw_texts[459] # says these 2 are similar for example","metadata":{"execution":{"iopub.status.busy":"2024-06-02T16:54:41.743994Z","iopub.execute_input":"2024-06-02T16:54:41.744823Z","iopub.status.idle":"2024-06-02T16:54:41.750525Z","shell.execute_reply.started":"2024-06-02T16:54:41.744789Z","shell.execute_reply":"2024-06-02T16:54:41.749594Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"('I purchased something overseas and the incorrect exchange rate was applied.',\n 'I purchased something abroad and the incorrect exchange rate was applied.')"},"metadata":{}}]},{"cell_type":"code","source":"raw_texts[412], raw_texts[501], raw_texts[517] # says these 3 are similar for example","metadata":{"execution":{"iopub.status.busy":"2024-06-02T17:07:14.070005Z","iopub.execute_input":"2024-06-02T17:07:14.070995Z","iopub.status.idle":"2024-06-02T17:07:14.078289Z","shell.execute_reply.started":"2024-06-02T17:07:14.070954Z","shell.execute_reply":"2024-06-02T17:07:14.077213Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"(\"The exchange rate you are using is bad.This can't be the official interbank exchange rate.\",\n \"The exchange rate you are using is really bad.This can't be the official interbank exchange rate.\",\n \"The exchange rate you are using is really bad. This can't possibly be the official interbank exchange rate.\")"},"metadata":{}}]},{"cell_type":"code","source":"raw_texts[607], raw_texts[698] # says these 2 are similar for example","metadata":{"execution":{"iopub.status.busy":"2024-06-02T17:09:24.281606Z","iopub.execute_input":"2024-06-02T17:09:24.282344Z","iopub.status.idle":"2024-06-02T17:09:24.288592Z","shell.execute_reply.started":"2024-06-02T17:09:24.282310Z","shell.execute_reply":"2024-06-02T17:09:24.287732Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"(\"There is an odd 1£ charge that appears as pending on my statement. What's the reason for that? I haven't purchased anything for a pound.\",\n \"There is a strange 1£ charge that appears as pending on my statement. What's the cause for that? I haven't purchased anything for a pound.\")"},"metadata":{}}]},{"cell_type":"code","source":"raw_texts[397], labels[397] # says this has a LABEL issue i.e. wrongly classified\n\n# says 32 : exchange_rate\n# should be 11 : card_arrival","metadata":{"execution":{"iopub.status.busy":"2024-06-02T17:19:20.312277Z","iopub.execute_input":"2024-06-02T17:19:20.312634Z","iopub.status.idle":"2024-06-02T17:19:20.318947Z","shell.execute_reply.started":"2024-06-02T17:19:20.312605Z","shell.execute_reply":"2024-06-02T17:19:20.318005Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"('I want to know your exchange rates.', 32)"},"metadata":{}}]},{"cell_type":"code","source":"raw_texts[485], labels[485]\n\n# is labelled\n# 17: card_payment_wrong_exchange_rate\n# should be\n# 34: extra_charge_on_statement\n# YES seems correct (didnt read all labels description, but 17 does seem wrong in any case)","metadata":{"execution":{"iopub.status.busy":"2024-06-02T17:22:04.222306Z","iopub.execute_input":"2024-06-02T17:22:04.222684Z","iopub.status.idle":"2024-06-02T17:22:04.229163Z","shell.execute_reply.started":"2024-06-02T17:22:04.222657Z","shell.execute_reply":"2024-06-02T17:22:04.228322Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"('Was I charged more than I should of been for a currency exchange?', 17)"},"metadata":{}}]},{"cell_type":"code","source":"label_issues = lab.get_issues(\"label\")\nlabel_issues.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-02T17:18:13.506138Z","iopub.execute_input":"2024-06-02T17:18:13.506509Z","iopub.status.idle":"2024-06-02T17:18:13.520563Z","shell.execute_reply.started":"2024-06-02T17:18:13.506480Z","shell.execute_reply":"2024-06-02T17:18:13.519549Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"   is_label_issue  label_score  given_label  predicted_label\n0           False     0.903878           11               11\n1           False     0.860550           11               11\n2           False     0.658273           11               11\n3           False     0.697050           11               11\n4           False     0.435318           11               11","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>is_label_issue</th>\n      <th>label_score</th>\n      <th>given_label</th>\n      <th>predicted_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>False</td>\n      <td>0.903878</td>\n      <td>11</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>False</td>\n      <td>0.860550</td>\n      <td>11</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>False</td>\n      <td>0.658273</td>\n      <td>11</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>False</td>\n      <td>0.697050</td>\n      <td>11</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>False</td>\n      <td>0.435318</td>\n      <td>11</td>\n      <td>11</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"This method returns a dataframe containing a label quality score for each example. These numeric scores lie between 0 and 1, where lower scores indicate examples more likely to be mislabeled. The dataframe also contains a boolean column specifying whether or not each example is identified to have a label issue (indicating it is likely mislabeled).\n\nWe can get the subset of examples flagged with label issues, and also sort by label quality score to find the indices of the 5 most likely mislabeled examples in our dataset.","metadata":{}},{"cell_type":"code","source":"identified_label_issues = label_issues[label_issues[\"is_label_issue\"] == True]\nlowest_quality_labels = label_issues[\"label_score\"].argsort()[:5].to_numpy()\n\nprint(\n    f\"cleanlab found {len(identified_label_issues)} potential label errors in the dataset.\\n\"\n    f\"Here are indices of the top 5 most likely errors: \\n {lowest_quality_labels}\"\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-02T17:28:17.451333Z","iopub.execute_input":"2024-06-02T17:28:17.451987Z","iopub.status.idle":"2024-06-02T17:28:17.459692Z","shell.execute_reply.started":"2024-06-02T17:28:17.451955Z","shell.execute_reply":"2024-06-02T17:28:17.458768Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"cleanlab found 10 potential label errors in the dataset.\nHere are indices of the top 5 most likely errors: \n [379 100 300 485 159]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Let’s review some of the most likely label errors.\n\nHere we display the top 5 examples identified as the most likely label errors in the dataset, together with their given (original) label and a suggested alternative label from cleanlab.","metadata":{}},{"cell_type":"code","source":"data_with_suggested_labels = pd.DataFrame(\n    {\"text\": raw_texts, \"given_label\": labels, \"suggested_label\": label_issues[\"predicted_label\"]}\n)\ndata_with_suggested_labels.iloc[lowest_quality_labels]","metadata":{"execution":{"iopub.status.busy":"2024-06-02T17:28:42.120316Z","iopub.execute_input":"2024-06-02T17:28:42.121103Z","iopub.status.idle":"2024-06-02T17:28:42.132468Z","shell.execute_reply.started":"2024-06-02T17:28:42.121071Z","shell.execute_reply":"2024-06-02T17:28:42.131493Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"                                                                                                          text  \\\n379  Is there a specific source that the exchange rate for the transfer I'm planning on making is pulled from?   \n100                                                                        can you share card tracking number?   \n300                                                   If I need to cash foreign transfers, how does that work?   \n485                                          Was I charged more than I should of been for a currency exchange?   \n159                                                                Is there any way to see my card in the app?   \n\n     given_label  suggested_label  \n379           32               11  \n100           11               36  \n300           32               46  \n485           17               34  \n159           13               11  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>given_label</th>\n      <th>suggested_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>379</th>\n      <td>Is there a specific source that the exchange rate for the transfer I'm planning on making is pulled from?</td>\n      <td>32</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>100</th>\n      <td>can you share card tracking number?</td>\n      <td>11</td>\n      <td>36</td>\n    </tr>\n    <tr>\n      <th>300</th>\n      <td>If I need to cash foreign transfers, how does that work?</td>\n      <td>32</td>\n      <td>46</td>\n    </tr>\n    <tr>\n      <th>485</th>\n      <td>Was I charged more than I should of been for a currency exchange?</td>\n      <td>17</td>\n      <td>34</td>\n    </tr>\n    <tr>\n      <th>159</th>\n      <td>Is there any way to see my card in the app?</td>\n      <td>13</td>\n      <td>11</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"**I read through the label lookup on the dataset page and tbh only 1-2 of these seem wrong**\n\n[https://huggingface.co/datasets/PolyAI/banking77](https://huggingface.co/datasets/PolyAI/banking77)\n\n\n\n---\n\n\n# Outliers\n\nAccording to the report, our dataset contains some outliers. We can see which examples are outliers (and a numeric quality score quantifying how typical each example appears to be) via get_issues. We sort the resulting DataFrame by cleanlab’s outlier quality score to see the most severe outliers in our dataset.","metadata":{}},{"cell_type":"code","source":"outlier_issues = lab.get_issues(\"outlier\")\noutlier_issues.sort_values(\"outlier_score\").head()","metadata":{"execution":{"iopub.status.busy":"2024-06-02T17:30:56.842451Z","iopub.execute_input":"2024-06-02T17:30:56.842848Z","iopub.status.idle":"2024-06-02T17:30:56.855990Z","shell.execute_reply.started":"2024-06-02T17:30:56.842816Z","shell.execute_reply":"2024-06-02T17:30:56.855097Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"     is_outlier_issue  outlier_score\n791              True       0.024866\n601              True       0.031162\n863              True       0.060738\n355              True       0.064199\n157              True       0.065075","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>is_outlier_issue</th>\n      <th>outlier_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>791</th>\n      <td>True</td>\n      <td>0.024866</td>\n    </tr>\n    <tr>\n      <th>601</th>\n      <td>True</td>\n      <td>0.031162</td>\n    </tr>\n    <tr>\n      <th>863</th>\n      <td>True</td>\n      <td>0.060738</td>\n    </tr>\n    <tr>\n      <th>355</th>\n      <td>True</td>\n      <td>0.064199</td>\n    </tr>\n    <tr>\n      <th>157</th>\n      <td>True</td>\n      <td>0.065075</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"lowest_quality_outliers = outlier_issues[\"outlier_score\"].argsort()[:5]\n\ndata.iloc[lowest_quality_outliers]","metadata":{"execution":{"iopub.status.busy":"2024-06-02T17:31:19.659137Z","iopub.execute_input":"2024-06-02T17:31:19.659526Z","iopub.status.idle":"2024-06-02T17:31:19.670847Z","shell.execute_reply.started":"2024-06-02T17:31:19.659495Z","shell.execute_reply":"2024-06-02T17:31:19.669764Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"                                            text  label\n791                  withdrawal pending meaning?     46\n601                    $1 charge in transaction.     34\n863              My atm withdraw is stillpending     46\n355          explain the interbank exchange rate     32\n157  lost card found, want to put it back in app     13","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>791</th>\n      <td>withdrawal pending meaning?</td>\n      <td>46</td>\n    </tr>\n    <tr>\n      <th>601</th>\n      <td>$1 charge in transaction.</td>\n      <td>34</td>\n    </tr>\n    <tr>\n      <th>863</th>\n      <td>My atm withdraw is stillpending</td>\n      <td>46</td>\n    </tr>\n    <tr>\n      <th>355</th>\n      <td>explain the interbank exchange rate</td>\n      <td>32</td>\n    </tr>\n    <tr>\n      <th>157</th>\n      <td>lost card found, want to put it back in app</td>\n      <td>13</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"We see that cleanlab has identified entries in this dataset that do not appear to be proper customer requests. Outliers in this dataset appear to be out-of-scope customer requests and other nonsensical text which does not make sense for intent classification. Carefully consider whether such outliers may detrimentally affect your data modeling, and consider removing them from the dataset if so.\n\n---\n\n# Duplicates\n\nAccording to the report, our dataset contains some sets of nearly duplicated examples. We can see which examples are (nearly) duplicated (and a numeric quality score quantifying how dissimilar each example is from its nearest neighbor in the dataset) via get_issues. We sort the resulting DataFrame by cleanlab’s near-duplicate quality score to see the text examples in our dataset that are most nearly duplicated.","metadata":{}},{"cell_type":"code","source":"duplicate_issues = lab.get_issues(\"near_duplicate\")\nduplicate_issues.sort_values(\"near_duplicate_score\").head()","metadata":{"execution":{"iopub.status.busy":"2024-06-02T17:31:58.799852Z","iopub.execute_input":"2024-06-02T17:31:58.800557Z","iopub.status.idle":"2024-06-02T17:31:58.816899Z","shell.execute_reply.started":"2024-06-02T17:31:58.800528Z","shell.execute_reply":"2024-06-02T17:31:58.815903Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"     is_near_duplicate_issue  near_duplicate_score near_duplicate_sets  \\\n459                     True              0.009549               [429]   \n429                     True              0.009549               [459]   \n412                     True              0.046045               [501]   \n501                     True              0.046045          [412, 517]   \n698                     True              0.054626               [607]   \n\n     distance_to_nearest_neighbor  \n459                      0.000566  \n429                      0.000566  \n412                      0.002781  \n501                      0.002781  \n698                      0.003314  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>is_near_duplicate_issue</th>\n      <th>near_duplicate_score</th>\n      <th>near_duplicate_sets</th>\n      <th>distance_to_nearest_neighbor</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>459</th>\n      <td>True</td>\n      <td>0.009549</td>\n      <td>[429]</td>\n      <td>0.000566</td>\n    </tr>\n    <tr>\n      <th>429</th>\n      <td>True</td>\n      <td>0.009549</td>\n      <td>[459]</td>\n      <td>0.000566</td>\n    </tr>\n    <tr>\n      <th>412</th>\n      <td>True</td>\n      <td>0.046045</td>\n      <td>[501]</td>\n      <td>0.002781</td>\n    </tr>\n    <tr>\n      <th>501</th>\n      <td>True</td>\n      <td>0.046045</td>\n      <td>[412, 517]</td>\n      <td>0.002781</td>\n    </tr>\n    <tr>\n      <th>698</th>\n      <td>True</td>\n      <td>0.054626</td>\n      <td>[607]</td>\n      <td>0.003314</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data.iloc[[459, 429]]","metadata":{"execution":{"iopub.status.busy":"2024-06-02T17:32:18.889616Z","iopub.execute_input":"2024-06-02T17:32:18.890361Z","iopub.status.idle":"2024-06-02T17:32:18.899966Z","shell.execute_reply.started":"2024-06-02T17:32:18.890331Z","shell.execute_reply":"2024-06-02T17:32:18.898922Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"                                                                            text  \\\n459    I purchased something abroad and the incorrect exchange rate was applied.   \n429  I purchased something overseas and the incorrect exchange rate was applied.   \n\n     label  \n459     17  \n429     17  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>459</th>\n      <td>I purchased something abroad and the incorrect exchange rate was applied.</td>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>429</th>\n      <td>I purchased something overseas and the incorrect exchange rate was applied.</td>\n      <td>17</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data.iloc[[501, 412]]","metadata":{"execution":{"iopub.status.busy":"2024-06-02T17:32:28.563840Z","iopub.execute_input":"2024-06-02T17:32:28.564547Z","iopub.status.idle":"2024-06-02T17:32:28.574218Z","shell.execute_reply.started":"2024-06-02T17:32:28.564515Z","shell.execute_reply":"2024-06-02T17:32:28.573113Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"                                                                                                  text  \\\n501  The exchange rate you are using is really bad.This can't be the official interbank exchange rate.   \n412         The exchange rate you are using is bad.This can't be the official interbank exchange rate.   \n\n     label  \n501     17  \n412     17  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>501</th>\n      <td>The exchange rate you are using is really bad.This can't be the official interbank exchange rate.</td>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>412</th>\n      <td>The exchange rate you are using is bad.This can't be the official interbank exchange rate.</td>\n      <td>17</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]}]}