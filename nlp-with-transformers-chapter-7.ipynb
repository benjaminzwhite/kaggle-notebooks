{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Natural Language Processing with Transformers\n\n## Chapter 7 - Question Answering\n\n- we are doing EXTRACTIVE QA here (lists other examples like community QA, long form QA etc)\n\n## Building a review based QA system\n\n### Dataset - SubjQA\n\n- customer reviews in english about products and services in 6 domains: tripadvisor, restaurants, movies etc.\n- each review is associated with a question that can be answersd using one or more sentences in the review\n- the Q and A are subjective ie depend on the users experience/preference etc (**so more difficult than factual QA like what is capital of UK etc**)\n\n\n\n","metadata":{}},{"cell_type":"code","source":"from datasets import get_dataset_config_names\n\ndomains = get_dataset_config_names(\"subjqa\")\n\ndomains","metadata":{"execution":{"iopub.status.busy":"2024-05-13T22:02:17.144653Z","iopub.execute_input":"2024-05-13T22:02:17.144978Z","iopub.status.idle":"2024-05-13T22:02:21.346286Z","shell.execute_reply.started":"2024-05-13T22:02:17.144941Z","shell.execute_reply":"2024-05-13T22:02:21.345335Z"},"trusted":true},"execution_count":1,"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"['books', 'electronics', 'grocery', 'movies', 'restaurants', 'tripadvisor']"},"metadata":{}}]},{"cell_type":"markdown","source":"**we focus on just ELECTRONICS for this chapter**","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\n\nsubjqa = load_dataset(\"subjqa\", name=\"electronics\")","metadata":{"execution":{"iopub.status.busy":"2024-05-13T22:02:21.347381Z","iopub.execute_input":"2024-05-13T22:02:21.347813Z","iopub.status.idle":"2024-05-13T22:02:25.368280Z","shell.execute_reply.started":"2024-05-13T22:02:21.347772Z","shell.execute_reply":"2024-05-13T22:02:25.367010Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"subjqa[\"train\"]","metadata":{"execution":{"iopub.status.busy":"2024-05-13T22:02:25.369659Z","iopub.execute_input":"2024-05-13T22:02:25.370251Z","iopub.status.idle":"2024-05-13T22:02:25.376302Z","shell.execute_reply.started":"2024-05-13T22:02:25.370214Z","shell.execute_reply":"2024-05-13T22:02:25.375371Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['domain', 'nn_mod', 'nn_asp', 'query_mod', 'query_asp', 'q_reviews_id', 'question_subj_level', 'ques_subj_score', 'is_ques_subjective', 'review_id', 'id', 'title', 'context', 'question', 'answers'],\n    num_rows: 1295\n})"},"metadata":{}}]},{"cell_type":"code","source":"print(subjqa[\"train\"][\"context\"][1], subjqa[\"train\"][\"question\"][1], subjqa[\"train\"][\"answers\"][1], sep='\\n\\n\\n')","metadata":{"execution":{"iopub.status.busy":"2024-05-13T22:02:25.378847Z","iopub.execute_input":"2024-05-13T22:02:25.379486Z","iopub.status.idle":"2024-05-13T22:02:25.429653Z","shell.execute_reply.started":"2024-05-13T22:02:25.379459Z","shell.execute_reply":"2024-05-13T22:02:25.428821Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"To anyone who hasn't tried all the various types of headphones, it is important to remember exactly what these are: cheap portable on-ear headphones. They give a totally different sound then in-ears or closed design phones, but for what they are I would say they're good. I currently own six pairs of phones, from stock apple earbuds to Sennheiser HD 518s. Gave my Portapros a run on both my computer's sound card and mp3 player, using 256 kbps mp3s or better. The clarity is good and they're very lightweight. The folding design is simple but effective. The look is certainly retro and unique, although I didn't find it as comfortable as many have claimed. Earpads are *very* thin and made my ears sore after 30 minutes of listening, although this can be remedied to a point by adjusting the \"comfort zone\" feature (tightening the temple pads while loosening the ear pads). The cord seems to be an average thickness, but I wouldn't get too rough with these. The steel headband adjusts smoothly and easily, just watch out that the slider doesn't catch your hair. Despite the sore ears, the phones are very lightweight overall.Back to the sound: as you would expect, it's good for a portable phone, but hardly earth shattering. At flat EQ the clarity is good, although the highs can sometimes be harsh. Bass is weak as expected, even with EQ adjusted up. To be fair, a portable on-ear would have a tough time comparing to the bass of an in-ear with a good seal or a pair with larger drivers. No sound isolation offered if you're into that sort of thing. Cool 80s phones, though I've certainly owned better portable on-ears (Sony makes excellent phones in this category). Soundstage is very narrow and lacks body. A good value if you can get them for under thirty, otherwise I'd rather invest in a nicer pair of phones. If we're talking about value, they're a good buy compared to new stock apple buds. If you're trying to compare the sound quality of this product to serious headphones, there's really no comparison at all.Update: After 100 hours of burn-in time the sound has not been affected in any appreciable way. Highs are still harsh, and bass is still underwhelming. I sometimes use these as a convenience but they have been largely replaced in my collection.\n\n\nIs this music song have a goo bass?\n\n\n{'text': ['Bass is weak as expected', 'Bass is weak as expected, even with EQ adjusted up'], 'answer_start': [1302, 1302], 'answer_subj_level': [1, 1], 'ans_subj_score': [0.5083333253860474, 0.5083333253860474], 'is_ans_subjective': [True, True]}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Like other question answering datasets on the Hub, SubjQA stores the answers to\neach question as a nested dictionary. For example, if we inspect one of the rows in the\nanswers column we can see that the answers are stored in a text field, while the starting character\nindices are provided in answer_start. To explore the dataset more easily, we’ll flatten these nested columns with the flatten() method and convert each split to a Pandas\nDataFrame as follows","metadata":{}},{"cell_type":"code","source":"import pandas as pd\ndfs = {split: dset.to_pandas() for split, dset in subjqa.flatten().items()}\n\nfor split, df in dfs.items():\n    print(f\"Number of questions in {split}: {df['id'].nunique()}\")","metadata":{"execution":{"iopub.status.busy":"2024-05-13T22:02:25.430630Z","iopub.execute_input":"2024-05-13T22:02:25.430913Z","iopub.status.idle":"2024-05-13T22:02:25.474518Z","shell.execute_reply.started":"2024-05-13T22:02:25.430889Z","shell.execute_reply":"2024-05-13T22:02:25.473706Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Number of questions in train: 1295\nNumber of questions in test: 358\nNumber of questions in validation: 255\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**interesting columns:**\n\n- title (amazon id of product)\n- question\n- answer text, start\n- context (customer review itself)\n\nNOTE:\n\n- **an empty answers.text entry denotes “unanswerable” questions whose answer cannot be found in the review**\n","metadata":{}},{"cell_type":"code","source":"qa_cols = [\"title\", \"question\", \"answers.text\",\n\"answers.answer_start\", \"context\"]\nsample_df = dfs[\"train\"][qa_cols].sample(2, random_state=7)\nsample_df","metadata":{"execution":{"iopub.status.busy":"2024-05-13T22:02:25.475461Z","iopub.execute_input":"2024-05-13T22:02:25.475764Z","iopub.status.idle":"2024-05-13T22:02:25.493169Z","shell.execute_reply.started":"2024-05-13T22:02:25.475730Z","shell.execute_reply":"2024-05-13T22:02:25.492210Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"           title                        question                answers.text  \\\n791   B005DKZTMG  Does the keyboard lightweight?  [this keyboard is compact]   \n1159  B00AAIPT76             How is the battery?                          []   \n\n     answers.answer_start                                            context  \n791                 [215]  I really like this keyboard.  I give it 4 star...  \n1159                   []  I bought this after the first spare gopro batt...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>question</th>\n      <th>answers.text</th>\n      <th>answers.answer_start</th>\n      <th>context</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>791</th>\n      <td>B005DKZTMG</td>\n      <td>Does the keyboard lightweight?</td>\n      <td>[this keyboard is compact]</td>\n      <td>[215]</td>\n      <td>I really like this keyboard.  I give it 4 star...</td>\n    </tr>\n    <tr>\n      <th>1159</th>\n      <td>B00AAIPT76</td>\n      <td>How is the battery?</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>I bought this after the first spare gopro batt...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"### EDA ideas cont.\n\nNext, let’s get a feel for what types of questions are in the training set by counting the\nquestions that begin with a few common starting words:","metadata":{}},{"cell_type":"code","source":"from matplotlib import pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2024-05-13T22:02:25.494213Z","iopub.execute_input":"2024-05-13T22:02:25.494480Z","iopub.status.idle":"2024-05-13T22:02:25.498624Z","shell.execute_reply.started":"2024-05-13T22:02:25.494456Z","shell.execute_reply":"2024-05-13T22:02:25.497629Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"counts = {}\nquestion_types = [\"What\", \"How\", \"Is\", \"Does\", \"Do\", \"Was\", \"Where\", \"Why\"]\n\nfor q in question_types:\n    counts[q] = dfs[\"train\"][\"question\"].str.startswith(q).value_counts()[True]\n\npd.Series(counts).sort_values().plot.barh()\n\nplt.title(\"Frequency of Question Types\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-13T22:02:25.499751Z","iopub.execute_input":"2024-05-13T22:02:25.500064Z","iopub.status.idle":"2024-05-13T22:02:25.795425Z","shell.execute_reply.started":"2024-05-13T22:02:25.500039Z","shell.execute_reply":"2024-05-13T22:02:25.794470Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"markdown","source":"**comment about SubjQA:** \n\n- says that the format (question, review, answer_sentences) was pioneered by SQaAD dataset\n- SQuAD 2.0 has adverserial examples (questions that are relevant to a given passage but cant be answered from text alone)\n\nSOTA on Squad 2 surpasses human performance but:\n\nHowever, this superhuman performance does not appear to reflect genuine reading\ncomprehension, since answers to the “unanswerable” questions can usually be identified through patterns in the passages like antonyms. To address these problems Goo‐\ngle released the Natural Questions (NQ) dataset,7 which involves fact-seeking\nquestions obtained from Google Search users. The answers in NQ are much longer\nthan in SQuAD and present a more challenging benchmark.\n\n---\n\n## How do transformers extract answers from text?\n\nThe first thing we’ll need for our QA system is to find a way to identify a potential\nanswer as a span of text in a customer review. For example, if a we have a question\nlike “Is it waterproof?” and the review passage is “This watch is waterproof at 30m\ndepth”, then the model should output “waterproof at 30m”. To do this we’ll need to\nunderstand how to:\n\n1. Frame the supervised learning problem.\n2. Tokenize and encode text for QA tasks.\n3. Deal with long passages that exceed a model’s maximum context size\n\n---\n\n## 1 - Framing as SPAN CLASSIFICATION task\n\n- the start and the end token of an answer span will act as the labels that the model needs to predict (see p173 of book for illustration)\n\n**NOTE: TODO: confirm this is correct - from the picture it seems that you send `CLS question SEP full text` ie the question and text-to-search are one big sequence, with a separator**\n\nWe start with a LM that has already been finetuned on large scale QA\n\n(NOTE THAT unlike previous cases, where we had to finetune as e.g. number of classes we wanted was different, here the structure of the \"labels\" remaisn the same across QA datasets (start and end position))\n\nGood models (book 2020) are: \n\n- miniLM\n- roberta-base\n- albert-xxl\n\nWe use miniLM for this examples (fast to train)\n\n### tokenizing text for QA task","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\nmodel_ckpt = \"deepset/minilm-uncased-squad2\"\n\ntokenizer = AutoTokenizer.from_pretrained(model_ckpt)","metadata":{"execution":{"iopub.status.busy":"2024-05-13T22:02:25.796543Z","iopub.execute_input":"2024-05-13T22:02:25.796855Z","iopub.status.idle":"2024-05-13T22:02:28.619519Z","shell.execute_reply.started":"2024-05-13T22:02:25.796828Z","shell.execute_reply":"2024-05-13T22:02:28.618545Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"To see the model in action, let’s first try to extract an answer from a short passage of\ntext. In extractive QA tasks, the inputs are provided as (question, context) pairs, so we\npass them both to the tokenizer as follows:\n\n**REMEMBER: tokenizer can accept lists of sentences etc**","metadata":{}},{"cell_type":"code","source":"question = \"How much music can this hold?\"\ncontext = \"\"\"An MP3 is about 1 MB/minute, so about 6000 hours depending on \\\nfile size.\"\"\"\ninputs = tokenizer(question, context, return_tensors=\"pt\")\n","metadata":{"execution":{"iopub.status.busy":"2024-05-13T22:02:28.620899Z","iopub.execute_input":"2024-05-13T22:02:28.621750Z","iopub.status.idle":"2024-05-13T22:02:28.627381Z","shell.execute_reply.started":"2024-05-13T22:02:28.621715Z","shell.execute_reply":"2024-05-13T22:02:28.626500Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"inputs","metadata":{"execution":{"iopub.status.busy":"2024-05-13T22:02:28.628544Z","iopub.execute_input":"2024-05-13T22:02:28.628885Z","iopub.status.idle":"2024-05-13T22:02:28.640494Z","shell.execute_reply.started":"2024-05-13T22:02:28.628853Z","shell.execute_reply":"2024-05-13T22:02:28.639549Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"{'input_ids': tensor([[  101,  2129,  2172,  2189,  2064,  2023,  2907,  1029,   102,  2019,\n         23378,  2003,  2055,  1015, 16914,  1013,  3371,  1010,  2061,  2055,\n         25961,  2847,  5834,  2006,  5371,  2946,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1]])}"},"metadata":{}}]},{"cell_type":"markdown","source":"we can see the familiar input_ids and attention_mask tensors, while the\ntoken_type_ids tensor indicates which part of the inputs corresponds to the question and context (a 0 indicates a question token, a 1 indicates a context token\n\nTo understand how the tokenizer formats the inputs for QA tasks, let’s decode the\ninput_ids tensor","metadata":{}},{"cell_type":"code","source":"print(tokenizer.decode(inputs[\"input_ids\"][0]))","metadata":{"execution":{"iopub.status.busy":"2024-05-13T22:02:28.641720Z","iopub.execute_input":"2024-05-13T22:02:28.642377Z","iopub.status.idle":"2024-05-13T22:02:28.647702Z","shell.execute_reply.started":"2024-05-13T22:02:28.642346Z","shell.execute_reply":"2024-05-13T22:02:28.646741Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"[CLS] how much music can this hold? [SEP] an mp3 is about 1 mb / minute, so about 6000 hours depending on file size. [SEP]\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom transformers import AutoModelForQuestionAnswering\n\nmodel = AutoModelForQuestionAnswering.from_pretrained(model_ckpt)\n\nwith torch.no_grad():\n    outputs = model(**inputs)\n\nprint(outputs)","metadata":{"execution":{"iopub.status.busy":"2024-05-13T22:02:28.651509Z","iopub.execute_input":"2024-05-13T22:02:28.651820Z","iopub.status.idle":"2024-05-13T22:02:29.715507Z","shell.execute_reply.started":"2024-05-13T22:02:28.651789Z","shell.execute_reply":"2024-05-13T22:02:29.714569Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at deepset/minilm-uncased-squad2 were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"},{"name":"stdout","text":"QuestionAnsweringModelOutput(loss=None, start_logits=tensor([[-0.9862, -4.7750, -5.4025, -5.2378, -5.2863, -5.5117, -4.9819, -6.1880,\n         -0.9862,  0.2596, -0.2144, -1.7136,  3.7806,  4.8561, -1.0546, -3.9097,\n         -1.7374, -4.5944, -1.4278,  3.9949,  5.0391, -0.2018, -3.0193, -4.8549,\n         -2.3107, -3.5110, -3.5713, -0.9862]]), end_logits=tensor([[-0.9623, -5.4733, -5.0326, -5.1639, -5.4278, -5.5151, -5.1749, -4.6233,\n         -0.9623, -3.7855, -0.8715, -3.7745, -3.0162, -1.1780,  0.1758, -2.7365,\n          4.8934,  0.3046, -3.1761, -3.2762,  0.8937,  5.6606, -0.3623, -4.9554,\n         -3.2531, -0.0914,  1.6211, -0.9623]]), hidden_states=None, attentions=None)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Here we can see that we get a QuestionAnsweringModelOutput object as the output of\nthe QA head. As illustrated in Figure 7-4 (**p173 of book**), the QA head corresponds to a linear layer\nthat takes the hidden states from the encoder and computes the logits for the start\nand end spans. This means that we treat QA as a form of token classification, similar\nto what we encountered for named entity recognition in Chapter 4. To convert the\noutputs into an answer span, we first need to get the logits for the start and end\ntokens:\n\n**NOTE: TODO - check/confirm that logically the location of the start and end span is RESTRICTED TO LIE IN THE \"context / text\" PART AND CANNOT BE IN THE EARLIER \"question\" PART** would be stupid otherwise\n\n**ALSO: that the max end logit always occurs after the start logit ??? how is this ensured???**","metadata":{}},{"cell_type":"code","source":"start_logits = outputs.start_logits\nend_logits = outputs.end_logits\n\nprint(f\"Input IDs shape: {inputs.input_ids.size()}\")\nprint(f\"Start logits shape: {start_logits.size()}\")\nprint(f\"End logits shape: {end_logits.size()}\")","metadata":{"execution":{"iopub.status.busy":"2024-05-13T22:02:29.716691Z","iopub.execute_input":"2024-05-13T22:02:29.717253Z","iopub.status.idle":"2024-05-13T22:02:29.723232Z","shell.execute_reply.started":"2024-05-13T22:02:29.717225Z","shell.execute_reply":"2024-05-13T22:02:29.722251Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Input IDs shape: torch.Size([1, 28])\nStart logits shape: torch.Size([1, 28])\nEnd logits shape: torch.Size([1, 28])\n","output_type":"stream"}]},{"cell_type":"code","source":"# get the argmax over the start and end logits, then get the corresponding span for these start:end positions\n\nstart_idx = torch.argmax(start_logits)\nend_idx = torch.argmax(end_logits) + 1\n\nanswer_span = inputs[\"input_ids\"][0][start_idx:end_idx]\nanswer = tokenizer.decode(answer_span)\n\nprint(f\"Question: {question}\")\nprint(f\"Answer: {answer}\")","metadata":{"execution":{"iopub.status.busy":"2024-05-13T22:02:29.724552Z","iopub.execute_input":"2024-05-13T22:02:29.724886Z","iopub.status.idle":"2024-05-13T22:02:29.733730Z","shell.execute_reply.started":"2024-05-13T22:02:29.724856Z","shell.execute_reply":"2024-05-13T22:02:29.732858Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Question: How much music can this hold?\nAnswer: 6000 hours\n","output_type":"stream"}]},{"cell_type":"markdown","source":"All of these preprocessing and postprocessing\nsteps are conveniently wrapped in a dedicated pipeline. We can instantiate the pipeline by passing our tokenizer and fine-tuned model as follows:\n\n**NOTE: TODO: notice there is a topk / top_k option - understand how it works - is it taking top_k over the PAIRS (start,end) ???? so an `n^2` comparison for all possible start and end offsets taking the max prob of the sum for ex??**","metadata":{}},{"cell_type":"code","source":"from transformers import pipeline\n\npipe = pipeline(\"question-answering\", model=model, tokenizer=tokenizer)\n\npipe(question=question, context=context, topk=3)","metadata":{"execution":{"iopub.status.busy":"2024-05-13T22:02:29.734716Z","iopub.execute_input":"2024-05-13T22:02:29.735022Z","iopub.status.idle":"2024-05-13T22:02:32.548594Z","shell.execute_reply.started":"2024-05-13T22:02:29.734999Z","shell.execute_reply":"2024-05-13T22:02:32.547658Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"2024-05-13 22:02:30.073838: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-13 22:02:30.073895: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-13 22:02:30.075317: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n/opt/conda/lib/python3.10/site-packages/transformers/pipelines/question_answering.py:326: UserWarning: topk parameter is deprecated, use top_k instead\n  warnings.warn(\"topk parameter is deprecated, use top_k instead\", UserWarning)\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.2651631534099579, 'start': 38, 'end': 48, 'answer': '6000 hours'},\n {'score': 0.22082939743995667,\n  'start': 16,\n  'end': 48,\n  'answer': '1 MB/minute, so about 6000 hours'},\n {'score': 0.10253427177667618,\n  'start': 16,\n  'end': 27,\n  'answer': '1 MB/minute'}]"},"metadata":{}}]},{"cell_type":"markdown","source":"**IMPORTANT: comment**\n\nIn addition to the answer, the pipeline also returns the model’s probability estimate in\nthe score field (obtained by taking a softmax over the logits). This is handy when we\nwant to compare multiple answers within a single context. We’ve also shown that we\ncan have the model predict multiple answers by specifying the topk parameter. Sometimes, it is possible to have questions for which no answer is possible, like the empty\nanswers.answer_start examples in SubjQA. In these cases the model will assign a\nhigh start and end score to the [CLS] token, and the pipeline maps this output to an\nempty string:","metadata":{}},{"cell_type":"code","source":"pipe(question=\"Why is there no data?\", context=context, handle_impossible_answer=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-13T22:02:32.549910Z","iopub.execute_input":"2024-05-13T22:02:32.550982Z","iopub.status.idle":"2024-05-13T22:02:32.597746Z","shell.execute_reply.started":"2024-05-13T22:02:32.550938Z","shell.execute_reply":"2024-05-13T22:02:32.596849Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"{'score': 0.906841516494751, 'start': 0, 'end': 0, 'answer': ''}"},"metadata":{}}]},{"cell_type":"markdown","source":"### NOTE: answer to one of my earlier questions\n\nIn our simple example, we obtained the start and end indices by\ntaking the argmax of the corresponding logits. However, this heuristic can produce out-of-scope answers by selecting tokens that\nbelong to the question instead of the context. In practice, the pipeline computes the best combination of start and end indices subject\nto various constraints such as being in-scope, requiring the start\nindices to precede the end indices, and so on.\n\n\n---\n\n## Dealing with long passages\n\n- for QA, the context (ie the text queried) is often much larger than the max seq length of the model (miniLM = 512 tokens for example)\n- in some tasks you can just truncate (eg text classif) since the \"beginning is representative\" but for QA the answer might lie in the final part of the text, so can't just truncate\n- one standard way is to use a sliding window: **create multiple question-context pairs for long documents**\n\nin HF you can use `return_overflowing_tokens=True` in the tokenizer to enable the sliding window\n\nThe size of the sliding window is controlled by the `max_seq_length` argument, and the size of the stride is controlled by `doc_stride`.","metadata":{}},{"cell_type":"code","source":"example = dfs[\"train\"].iloc[0][[\"question\", \"context\"]]\ntokenized_example = tokenizer(example[\"question\"], example[\"context\"],return_overflowing_tokens=True, max_length=100,stride=25)","metadata":{"execution":{"iopub.status.busy":"2024-05-13T22:02:32.598933Z","iopub.execute_input":"2024-05-13T22:02:32.599290Z","iopub.status.idle":"2024-05-13T22:02:32.607620Z","shell.execute_reply.started":"2024-05-13T22:02:32.599258Z","shell.execute_reply":"2024-05-13T22:02:32.606681Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","output_type":"stream"}]},{"cell_type":"code","source":"for idx, window in enumerate(tokenized_example[\"input_ids\"]):\n    print(f\"Window #{idx} has {len(window)} tokens\")","metadata":{"execution":{"iopub.status.busy":"2024-05-13T22:02:32.608841Z","iopub.execute_input":"2024-05-13T22:02:32.609201Z","iopub.status.idle":"2024-05-13T22:02:32.615292Z","shell.execute_reply.started":"2024-05-13T22:02:32.609170Z","shell.execute_reply":"2024-05-13T22:02:32.614313Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Window #0 has 100 tokens\nWindow #1 has 88 tokens\n","output_type":"stream"}]},{"cell_type":"code","source":"# example to see roughly at where the overlap is between 2 windows:\n\nfor window in tokenized_example[\"input_ids\"]:\n    print(f\"{tokenizer.decode(window)} \\n\")","metadata":{"execution":{"iopub.status.busy":"2024-05-13T22:02:32.616750Z","iopub.execute_input":"2024-05-13T22:02:32.617029Z","iopub.status.idle":"2024-05-13T22:02:32.632249Z","shell.execute_reply.started":"2024-05-13T22:02:32.617008Z","shell.execute_reply":"2024-05-13T22:02:32.631214Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"[CLS] how is the bass? [SEP] i have had koss headphones in the past, pro 4aa and qz - 99. the koss portapro is portable and has great bass response. the work great with my android phone and can be \" rolled up \" to be carried in my motorcycle jacket or computer bag without getting crunched. they are very light and do not feel heavy or bear down on your ears even after listening to music with them on all day. the sound is [SEP] \n\n[CLS] how is the bass? [SEP] and do not feel heavy or bear down on your ears even after listening to music with them on all day. the sound is night and day better than any ear - bud could be and are almost as good as the pro 4aa. they are \" open air \" headphones so you cannot match the bass to the sealed types, but it comes close. for $ 32, you cannot go wrong. [SEP] \n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Using Haystack to build a QA pipeline\n\nLet's look at the other components needed (we have seen how to extract answers from text) for a QA system\n\n- in example so far, we provided the Question AND THE CONTEXT to the model\n- but in reality, users will only provide Question so we need to select relevant passages to CREATE THE CONTEXT\n- in this specific case for ex, we could e.g. concatenate ALL the reviews for a given product and give it to model as a single context, **but this produces huge documents/latency etc**\n\nTo handle this modern QA typically is based on the **retriever-reader** architecture:\n\n### Retriever\n\nRetrieve relevant documents for a given query:\n\n- sparse vs dense: sparse use word frequencies to represent each document and query. Dense use encoders like transformers to represent documents and queries as contextualized embeddings\n\n### Reader\n\nResponsible for extracting an answer from the documents provided by the retriever\n\n---\n\nThere can be other additions to this simple model - for example **reranking** to eliminate noisy results etc, postprocessing of results from several disjointed documents etc\n\n---\n\nTo build this QA system we use **Haystack** library. We will also need to use a **document store** (database to store documents and metadata, used by the retriever for queries)\n\n## Creating a document store\n\nHaystack has options for document stores: Elasticsearch, Faiss, Milvus\n\nand also for retrivers: sparse {TFIDF, BM-25}, dense {embedding, DPR}\n\n**we will use `ElasticsearchDocumentStore`, which is compatible with both retriever types**","metadata":{}},{"cell_type":"code","source":"url = \"\"\"https://artifacts.elastic.co/downloads/elasticsearch/\\\nelasticsearch-7.9.2-linux-x86_64.tar.gz\"\"\"\n\n!wget -nc -q {url}\n!tar -xzf elasticsearch-7.9.2-linux-x86_64.tar.gz","metadata":{"execution":{"iopub.status.busy":"2024-05-13T22:02:32.633241Z","iopub.execute_input":"2024-05-13T22:02:32.633495Z","iopub.status.idle":"2024-05-13T22:02:39.019679Z","shell.execute_reply.started":"2024-05-13T22:02:32.633474Z","shell.execute_reply":"2024-05-13T22:02:39.018540Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"import os\nfrom subprocess import Popen, PIPE, STDOUT\n# Run Elasticsearch as a background process\n!chown -R daemon:daemon elasticsearch-7.9.2\nes_server = Popen(args=['elasticsearch-7.9.2/bin/elasticsearch'], stdout=PIPE, stderr=STDOUT, preexec_fn=lambda: os.setuid(1))\n# Wait until Elasticsearch has started\n!sleep 30","metadata":{"execution":{"iopub.status.busy":"2024-05-13T22:02:39.021240Z","iopub.execute_input":"2024-05-13T22:02:39.021579Z","iopub.status.idle":"2024-05-13T22:03:11.093952Z","shell.execute_reply.started":"2024-05-13T22:02:39.021548Z","shell.execute_reply":"2024-05-13T22:03:11.092627Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"!curl -X GET \"localhost:9200/?pretty\"","metadata":{"execution":{"iopub.status.busy":"2024-05-13T22:03:11.095422Z","iopub.execute_input":"2024-05-13T22:03:11.095738Z","iopub.status.idle":"2024-05-13T22:03:12.124579Z","shell.execute_reply.started":"2024-05-13T22:03:11.095710Z","shell.execute_reply":"2024-05-13T22:03:12.123533Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"{\n  \"name\" : \"ea58dc71893c\",\n  \"cluster_name\" : \"elasticsearch\",\n  \"cluster_uuid\" : \"ag9sVHn2TG6QBM4egCgkxg\",\n  \"version\" : {\n    \"number\" : \"7.9.2\",\n    \"build_flavor\" : \"default\",\n    \"build_type\" : \"tar\",\n    \"build_hash\" : \"d34da0ea4a966c4e49417f2da2f244e3e97b4e6e\",\n    \"build_date\" : \"2020-09-23T00:45:33.626720Z\",\n    \"build_snapshot\" : false,\n    \"lucene_version\" : \"8.6.2\",\n    \"minimum_wire_compatibility_version\" : \"6.8.0\",\n    \"minimum_index_compatibility_version\" : \"6.0.0-beta1\"\n  },\n  \"tagline\" : \"You Know, for Search\"\n}\n","output_type":"stream"}]},{"cell_type":"code","source":"#!pip install haystack","metadata":{"execution":{"iopub.status.busy":"2024-05-13T22:03:12.126029Z","iopub.execute_input":"2024-05-13T22:03:12.126357Z","iopub.status.idle":"2024-05-13T22:03:12.131660Z","shell.execute_reply.started":"2024-05-13T22:03:12.126317Z","shell.execute_reply":"2024-05-13T22:03:12.130833Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"#!pip uninstall haystack","metadata":{"execution":{"iopub.status.busy":"2024-05-13T22:03:12.132619Z","iopub.execute_input":"2024-05-13T22:03:12.132915Z","iopub.status.idle":"2024-05-13T22:03:12.140593Z","shell.execute_reply.started":"2024-05-13T22:03:12.132883Z","shell.execute_reply":"2024-05-13T22:03:12.139807Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"#!pip install farm-haystack","metadata":{"execution":{"iopub.status.busy":"2024-05-13T22:03:12.141608Z","iopub.execute_input":"2024-05-13T22:03:12.141931Z","iopub.status.idle":"2024-05-13T22:03:12.151206Z","shell.execute_reply.started":"2024-05-13T22:03:12.141906Z","shell.execute_reply":"2024-05-13T22:03:12.150343Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"!pip install farm-haystack[all]","metadata":{"execution":{"iopub.status.busy":"2024-05-13T22:03:12.152312Z","iopub.execute_input":"2024-05-13T22:03:12.152636Z","iopub.status.idle":"2024-05-13T22:03:27.427762Z","shell.execute_reply.started":"2024-05-13T22:03:12.152606Z","shell.execute_reply":"2024-05-13T22:03:27.426566Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Requirement already satisfied: farm-haystack[all] in /opt/conda/lib/python3.10/site-packages (1.25.5)\nRequirement already satisfied: boilerpy3 in /opt/conda/lib/python3.10/site-packages (from farm-haystack[all]) (1.0.7)\nRequirement already satisfied: events in /opt/conda/lib/python3.10/site-packages (from farm-haystack[all]) (0.5)\nRequirement already satisfied: httpx in /opt/conda/lib/python3.10/site-packages (from farm-haystack[all]) (0.27.0)\nRequirement already satisfied: jsonschema in /opt/conda/lib/python3.10/site-packages (from farm-haystack[all]) (4.20.0)\nRequirement already satisfied: lazy-imports==0.3.1 in /opt/conda/lib/python3.10/site-packages (from farm-haystack[all]) (0.3.1)\nRequirement already satisfied: more-itertools in /opt/conda/lib/python3.10/site-packages (from farm-haystack[all]) (10.2.0)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from farm-haystack[all]) (3.2.1)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from farm-haystack[all]) (2.1.4)\nRequirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (from farm-haystack[all]) (9.5.0)\nRequirement already satisfied: platformdirs in /opt/conda/lib/python3.10/site-packages (from farm-haystack[all]) (4.2.0)\nRequirement already satisfied: posthog in /opt/conda/lib/python3.10/site-packages (from farm-haystack[all]) (3.5.0)\nRequirement already satisfied: prompthub-py==4.0.0 in /opt/conda/lib/python3.10/site-packages (from farm-haystack[all]) (4.0.0)\nRequirement already satisfied: pydantic<2 in /opt/conda/lib/python3.10/site-packages (from farm-haystack[all]) (1.10.15)\nRequirement already satisfied: quantulum3 in /opt/conda/lib/python3.10/site-packages (from farm-haystack[all]) (0.9.1)\nRequirement already satisfied: rank-bm25 in /opt/conda/lib/python3.10/site-packages (from farm-haystack[all]) (0.2.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from farm-haystack[all]) (2.31.0)\nRequirement already satisfied: requests-cache<1.0.0 in /opt/conda/lib/python3.10/site-packages (from farm-haystack[all]) (0.9.8)\nRequirement already satisfied: scikit-learn>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from farm-haystack[all]) (1.4.2)\nRequirement already satisfied: sseclient-py in /opt/conda/lib/python3.10/site-packages (from farm-haystack[all]) (1.8.0)\nRequirement already satisfied: tenacity in /opt/conda/lib/python3.10/site-packages (from farm-haystack[all]) (8.2.3)\nRequirement already satisfied: tiktoken>=0.5.1 in /opt/conda/lib/python3.10/site-packages (from farm-haystack[all]) (0.7.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from farm-haystack[all]) (4.66.1)\nRequirement already satisfied: transformers==4.39.3 in /opt/conda/lib/python3.10/site-packages (from farm-haystack[all]) (4.39.3)\nRequirement already satisfied: azure-ai-formrecognizer>=3.2.0b2 in /opt/conda/lib/python3.10/site-packages (from farm-haystack[all]) (3.3.3)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from farm-haystack[all]) (4.12.2)\nRequirement already satisfied: boto3>=1.28.57 in /opt/conda/lib/python3.10/site-packages (from farm-haystack[all]) (1.34.104)\nRequirement already satisfied: elastic-transport<8 in /opt/conda/lib/python3.10/site-packages (from farm-haystack[all]) (7.16.0)\nRequirement already satisfied: elasticsearch<8,>=7.17 in /opt/conda/lib/python3.10/site-packages (from farm-haystack[all]) (7.17.9)\nRequirement already satisfied: faiss-cpu<=1.7.2,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from farm-haystack[all]) (1.7.2)\nRequirement already satisfied: huggingface-hub>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from farm-haystack[all]) (0.22.2)\nRequirement already satisfied: langdetect in /opt/conda/lib/python3.10/site-packages (from farm-haystack[all]) (1.0.9)\nRequirement already satisfied: markdown in /opt/conda/lib/python3.10/site-packages (from farm-haystack[all]) (3.5.2)\nRequirement already satisfied: mlflow in /opt/conda/lib/python3.10/site-packages (from farm-haystack[all]) (2.12.2)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from farm-haystack[all]) (3.2.4)\nRequirement already satisfied: openai-whisper>=20231106 in /opt/conda/lib/python3.10/site-packages (from farm-haystack[all]) (20231117)\nRequirement already satisfied: opensearch-py>=2 in /opt/conda/lib/python3.10/site-packages (from farm-haystack[all]) (2.5.0)\nRequirement already satisfied: pdf2image>1.14 in /opt/conda/lib/python3.10/site-packages (from farm-haystack[all]) (1.17.0)\nRequirement already satisfied: pinecone-client<3,>=2.0.11 in /opt/conda/lib/python3.10/site-packages (from farm-haystack[all]) (2.2.4)\nRequirement already satisfied: psycopg2-binary in /opt/conda/lib/python3.10/site-packages (from farm-haystack[all]) (2.9.9)\nRequirement already satisfied: pymongo>=4.6 in /opt/conda/lib/python3.10/site-packages (from farm-haystack[all]) (4.7.2)\nRequirement already satisfied: pymupdf>=1.18.16 in /opt/conda/lib/python3.10/site-packages (from farm-haystack[all]) (1.24.3)\nRequirement already satisfied: pytesseract>0.3.7 in /opt/conda/lib/python3.10/site-packages (from farm-haystack[all]) (0.3.10)\nRequirement already satisfied: python-docx in /opt/conda/lib/python3.10/site-packages (from farm-haystack[all]) (1.1.2)\nRequirement already satisfied: python-frontmatter in /opt/conda/lib/python3.10/site-packages (from farm-haystack[all]) (1.1.0)\nRequirement already satisfied: python-magic in /opt/conda/lib/python3.10/site-packages (from farm-haystack[all]) (0.4.27)\nRequirement already satisfied: python-pptx in /opt/conda/lib/python3.10/site-packages (from farm-haystack[all]) (0.6.23)\nRequirement already satisfied: rapidfuzz<2.8.0,>=2.0.15 in /opt/conda/lib/python3.10/site-packages (from farm-haystack[all]) (2.7.0)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from farm-haystack[all]) (1.11.4)\nRequirement already satisfied: selenium>=4.11.0 in /opt/conda/lib/python3.10/site-packages (from farm-haystack[all]) (4.20.0)\nRequirement already satisfied: sentence-transformers>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from farm-haystack[all]) (2.7.0)\nRequirement already satisfied: seqeval in /opt/conda/lib/python3.10/site-packages (from farm-haystack[all]) (1.2.2)\nRequirement already satisfied: sqlalchemy-utils in /opt/conda/lib/python3.10/site-packages (from farm-haystack[all]) (0.41.2)\nRequirement already satisfied: sqlalchemy<2,>=1.4.2 in /opt/conda/lib/python3.10/site-packages (from farm-haystack[all]) (1.4.52)\nRequirement already satisfied: tika in /opt/conda/lib/python3.10/site-packages (from farm-haystack[all]) (2.6.0)\nRequirement already satisfied: weaviate-client>2 in /opt/conda/lib/python3.10/site-packages (from farm-haystack[all]) (3.26.2)\nRequirement already satisfied: pyyaml<7.0,>=6.0 in /opt/conda/lib/python3.10/site-packages (from prompthub-py==4.0.0->farm-haystack[all]) (6.0.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.39.3->farm-haystack[all]) (3.13.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.39.3->farm-haystack[all]) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.39.3->farm-haystack[all]) (21.3)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.39.3->farm-haystack[all]) (2023.12.25)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers==4.39.3->farm-haystack[all]) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.39.3->farm-haystack[all]) (0.4.3)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece,torch]==4.39.3; extra == \"all\"->farm-haystack[all]) (2.1.2)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece,torch]==4.39.3; extra == \"all\"->farm-haystack[all]) (0.29.3)\nRequirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece,torch]==4.39.3; extra == \"all\"->farm-haystack[all]) (0.2.0)\nRequirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece,torch]==4.39.3; extra == \"all\"->farm-haystack[all]) (3.20.3)\nRequirement already satisfied: azure-core>=1.23.0 in /opt/conda/lib/python3.10/site-packages (from azure-ai-formrecognizer>=3.2.0b2->farm-haystack[all]) (1.30.1)\nRequirement already satisfied: msrest>=0.6.21 in /opt/conda/lib/python3.10/site-packages (from azure-ai-formrecognizer>=3.2.0b2->farm-haystack[all]) (0.7.1)\nRequirement already satisfied: azure-common>=1.1 in /opt/conda/lib/python3.10/site-packages (from azure-ai-formrecognizer>=3.2.0b2->farm-haystack[all]) (1.1.28)\nRequirement already satisfied: typing-extensions>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from azure-ai-formrecognizer>=3.2.0b2->farm-haystack[all]) (4.9.0)\nRequirement already satisfied: botocore<1.35.0,>=1.34.104 in /opt/conda/lib/python3.10/site-packages (from boto3>=1.28.57->farm-haystack[all]) (1.34.104)\nRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3>=1.28.57->farm-haystack[all]) (1.0.1)\nRequirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from boto3>=1.28.57->farm-haystack[all]) (0.10.1)\nRequirement already satisfied: urllib3<2,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from elastic-transport<8->farm-haystack[all]) (1.26.18)\nRequirement already satisfied: six>=1.12 in /opt/conda/lib/python3.10/site-packages (from elastic-transport<8->farm-haystack[all]) (1.16.0)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from elastic-transport<8->farm-haystack[all]) (2024.2.2)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.5.0->farm-haystack[all]) (2024.2.0)\nRequirement already satisfied: triton<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from openai-whisper>=20231106->farm-haystack[all]) (2.3.0)\nRequirement already satisfied: numba in /opt/conda/lib/python3.10/site-packages (from openai-whisper>=20231106->farm-haystack[all]) (0.58.1)\nRequirement already satisfied: python-dateutil in /opt/conda/lib/python3.10/site-packages (from opensearch-py>=2->farm-haystack[all]) (2.9.0.post0)\nRequirement already satisfied: loguru>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from pinecone-client<3,>=2.0.11->farm-haystack[all]) (0.7.2)\nRequirement already satisfied: dnspython>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from pinecone-client<3,>=2.0.11->farm-haystack[all]) (2.6.1)\nRequirement already satisfied: PyMuPDFb==1.24.3 in /opt/conda/lib/python3.10/site-packages (from pymupdf>=1.18.16->farm-haystack[all]) (1.24.3)\nRequirement already satisfied: jarowinkler<2.0.0,>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from rapidfuzz<2.8.0,>=2.0.15->farm-haystack[all]) (1.2.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->farm-haystack[all]) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->farm-haystack[all]) (3.6)\nRequirement already satisfied: appdirs>=1.4.4 in /opt/conda/lib/python3.10/site-packages (from requests-cache<1.0.0->farm-haystack[all]) (1.4.4)\nRequirement already satisfied: attrs>=21.2 in /opt/conda/lib/python3.10/site-packages (from requests-cache<1.0.0->farm-haystack[all]) (23.2.0)\nRequirement already satisfied: cattrs>=22.2 in /opt/conda/lib/python3.10/site-packages (from requests-cache<1.0.0->farm-haystack[all]) (23.2.3)\nRequirement already satisfied: url-normalize>=1.4 in /opt/conda/lib/python3.10/site-packages (from requests-cache<1.0.0->farm-haystack[all]) (1.4.3)\nRequirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=1.3.0->farm-haystack[all]) (1.4.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=1.3.0->farm-haystack[all]) (3.2.0)\nRequirement already satisfied: trio~=0.17 in /opt/conda/lib/python3.10/site-packages (from selenium>=4.11.0->farm-haystack[all]) (0.25.0)\nRequirement already satisfied: trio-websocket~=0.9 in /opt/conda/lib/python3.10/site-packages (from selenium>=4.11.0->farm-haystack[all]) (0.11.1)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy<2,>=1.4.2->farm-haystack[all]) (3.0.3)\nRequirement already satisfied: validators<1.0.0,>=0.21.2 in /opt/conda/lib/python3.10/site-packages (from weaviate-client>2->farm-haystack[all]) (0.28.1)\nRequirement already satisfied: authlib<2.0.0,>=1.2.1 in /opt/conda/lib/python3.10/site-packages (from weaviate-client>2->farm-haystack[all]) (1.3.0)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->farm-haystack[all]) (2.5)\nRequirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx->farm-haystack[all]) (4.2.0)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx->farm-haystack[all]) (1.0.5)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx->farm-haystack[all]) (1.3.0)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx->farm-haystack[all]) (0.14.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema->farm-haystack[all]) (2023.12.1)\nRequirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema->farm-haystack[all]) (0.32.1)\nRequirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema->farm-haystack[all]) (0.16.2)\nRequirement already satisfied: Flask<4 in /opt/conda/lib/python3.10/site-packages (from mlflow->farm-haystack[all]) (3.0.3)\nRequirement already satisfied: alembic!=1.10.0,<2 in /opt/conda/lib/python3.10/site-packages (from mlflow->farm-haystack[all]) (1.13.1)\nRequirement already satisfied: click<9,>=7.0 in /opt/conda/lib/python3.10/site-packages (from mlflow->farm-haystack[all]) (8.1.7)\nRequirement already satisfied: cloudpickle<4 in /opt/conda/lib/python3.10/site-packages (from mlflow->farm-haystack[all]) (2.2.1)\nRequirement already satisfied: docker<8,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from mlflow->farm-haystack[all]) (7.0.0)\nRequirement already satisfied: entrypoints<1 in /opt/conda/lib/python3.10/site-packages (from mlflow->farm-haystack[all]) (0.4)\nRequirement already satisfied: gitpython<4,>=3.1.9 in /opt/conda/lib/python3.10/site-packages (from mlflow->farm-haystack[all]) (3.1.41)\nRequirement already satisfied: graphene<4 in /opt/conda/lib/python3.10/site-packages (from mlflow->farm-haystack[all]) (3.3)\nRequirement already satisfied: importlib-metadata!=4.7.0,<8,>=3.7.0 in /opt/conda/lib/python3.10/site-packages (from mlflow->farm-haystack[all]) (6.11.0)\nRequirement already satisfied: matplotlib<4 in /opt/conda/lib/python3.10/site-packages (from mlflow->farm-haystack[all]) (3.7.5)\nRequirement already satisfied: pyarrow<16,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from mlflow->farm-haystack[all]) (15.0.2)\nRequirement already satisfied: pytz<2025 in /opt/conda/lib/python3.10/site-packages (from mlflow->farm-haystack[all]) (2023.3.post1)\nRequirement already satisfied: querystring-parser<2 in /opt/conda/lib/python3.10/site-packages (from mlflow->farm-haystack[all]) (1.2.4)\nRequirement already satisfied: sqlparse<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from mlflow->farm-haystack[all]) (0.4.4)\nRequirement already satisfied: Jinja2<4,>=2.11 in /opt/conda/lib/python3.10/site-packages (from mlflow->farm-haystack[all]) (3.1.2)\nRequirement already satisfied: gunicorn<23 in /opt/conda/lib/python3.10/site-packages (from mlflow->farm-haystack[all]) (22.0.0)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->farm-haystack[all]) (2023.4)\nRequirement already satisfied: monotonic>=1.5 in /opt/conda/lib/python3.10/site-packages (from posthog->farm-haystack[all]) (1.6)\nRequirement already satisfied: backoff>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from posthog->farm-haystack[all]) (2.2.1)\nRequirement already satisfied: lxml>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from python-docx->farm-haystack[all]) (5.2.1)\nRequirement already satisfied: XlsxWriter>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from python-pptx->farm-haystack[all]) (3.2.0)\nRequirement already satisfied: inflect in /opt/conda/lib/python3.10/site-packages (from quantulum3->farm-haystack[all]) (7.2.1)\nRequirement already satisfied: num2words in /opt/conda/lib/python3.10/site-packages (from quantulum3->farm-haystack[all]) (0.5.13)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tika->farm-haystack[all]) (69.0.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.21.0->transformers[sentencepiece,torch]==4.39.3; extra == \"all\"->farm-haystack[all]) (5.9.3)\nRequirement already satisfied: Mako in /opt/conda/lib/python3.10/site-packages (from alembic!=1.10.0,<2->mlflow->farm-haystack[all]) (1.3.3)\nRequirement already satisfied: cryptography in /opt/conda/lib/python3.10/site-packages (from authlib<2.0.0,>=1.2.1->weaviate-client>2->farm-haystack[all]) (41.0.7)\nRequirement already satisfied: exceptiongroup>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from cattrs>=22.2->requests-cache<1.0.0->farm-haystack[all]) (1.2.0)\nRequirement already satisfied: Werkzeug>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from Flask<4->mlflow->farm-haystack[all]) (3.0.2)\nRequirement already satisfied: itsdangerous>=2.1.2 in /opt/conda/lib/python3.10/site-packages (from Flask<4->mlflow->farm-haystack[all]) (2.2.0)\nRequirement already satisfied: blinker>=1.6.2 in /opt/conda/lib/python3.10/site-packages (from Flask<4->mlflow->farm-haystack[all]) (1.7.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython<4,>=3.1.9->mlflow->farm-haystack[all]) (4.0.11)\nRequirement already satisfied: graphql-core<3.3,>=3.1 in /opt/conda/lib/python3.10/site-packages (from graphene<4->mlflow->farm-haystack[all]) (3.2.3)\nRequirement already satisfied: graphql-relay<3.3,>=3.1 in /opt/conda/lib/python3.10/site-packages (from graphene<4->mlflow->farm-haystack[all]) (3.2.0)\nRequirement already satisfied: aniso8601<10,>=8 in /opt/conda/lib/python3.10/site-packages (from graphene<4->mlflow->farm-haystack[all]) (9.0.1)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata!=4.7.0,<8,>=3.7.0->mlflow->farm-haystack[all]) (3.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from Jinja2<4,>=2.11->mlflow->farm-haystack[all]) (2.1.3)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow->farm-haystack[all]) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow->farm-haystack[all]) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow->farm-haystack[all]) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow->farm-haystack[all]) (1.4.5)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow->farm-haystack[all]) (3.1.1)\nRequirement already satisfied: isodate>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from msrest>=0.6.21->azure-ai-formrecognizer>=3.2.0b2->farm-haystack[all]) (0.6.1)\nRequirement already satisfied: requests-oauthlib>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from msrest>=0.6.21->azure-ai-formrecognizer>=3.2.0b2->farm-haystack[all]) (1.3.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->transformers[sentencepiece,torch]==4.39.3; extra == \"all\"->farm-haystack[all]) (1.12)\nRequirement already satisfied: sortedcontainers in /opt/conda/lib/python3.10/site-packages (from trio~=0.17->selenium>=4.11.0->farm-haystack[all]) (2.4.0)\nRequirement already satisfied: outcome in /opt/conda/lib/python3.10/site-packages (from trio~=0.17->selenium>=4.11.0->farm-haystack[all]) (1.3.0.post0)\nRequirement already satisfied: wsproto>=0.14 in /opt/conda/lib/python3.10/site-packages (from trio-websocket~=0.9->selenium>=4.11.0->farm-haystack[all]) (1.2.0)\nRequirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from urllib3[socks]<3,>=1.26->selenium>=4.11.0->farm-haystack[all]) (1.7.1)\nRequirement already satisfied: typeguard>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from inflect->quantulum3->farm-haystack[all]) (4.1.5)\nRequirement already satisfied: docopt>=0.6.2 in /opt/conda/lib/python3.10/site-packages (from num2words->quantulum3->farm-haystack[all]) (0.6.2)\nRequirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba->openai-whisper>=20231106->farm-haystack[all]) (0.41.1)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow->farm-haystack[all]) (5.0.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.21->azure-ai-formrecognizer>=3.2.0b2->farm-haystack[all]) (3.2.2)\nRequirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.10/site-packages (from cryptography->authlib<2.0.0,>=1.2.1->weaviate-client>2->farm-haystack[all]) (1.16.0)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->transformers[sentencepiece,torch]==4.39.3; extra == \"all\"->farm-haystack[all]) (1.3.0)\nRequirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.12->cryptography->authlib<2.0.0,>=1.2.1->weaviate-client>2->farm-haystack[all]) (2.21)\n","output_type":"stream"}]},{"cell_type":"code","source":"#from haystack.document_store.elasticsearch import ElasticsearchDocumentStore\nfrom haystack.document_stores import ElasticsearchDocumentStore\n\n# Return the document embedding for later use with dense retriever\ndocument_store = ElasticsearchDocumentStore(return_embedding=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-13T22:03:27.429230Z","iopub.execute_input":"2024-05-13T22:03:27.429542Z","iopub.status.idle":"2024-05-13T22:03:34.375337Z","shell.execute_reply.started":"2024-05-13T22:03:27.429513Z","shell.execute_reply":"2024-05-13T22:03:34.374301Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stderr","text":"2024-05-13 22:03:33,150\tINFO util.py:124 -- Outdated packages:\n  ipywidgets==7.7.1 found, needs ipywidgets>=8\nRun `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**p185 of book:** shows expected layout for Haystack document stores, how to add metadata to each document:","metadata":{}},{"cell_type":"code","source":"for split, df in dfs.items():\n    # Exclude duplicate reviews\n    docs = [{\"text\": row[\"context\"],\n             \"meta\":{\"item_id\": row[\"title\"], \"question_id\": row[\"id\"],\"split\": split}}\n            for _,row in df.drop_duplicates(subset=\"context\").iterrows()]\n    \n    document_store.write_documents(docs, index=\"document\")\n\nprint(f\"Loaded {document_store.get_document_count()} documents\")","metadata":{"execution":{"iopub.status.busy":"2024-05-13T22:06:56.986647Z","iopub.execute_input":"2024-05-13T22:06:56.987665Z","iopub.status.idle":"2024-05-13T22:06:58.360134Z","shell.execute_reply.started":"2024-05-13T22:06:56.987629Z","shell.execute_reply":"2024-05-13T22:06:58.358720Z"},"trusted":true},"execution_count":29,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[29], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m split, df \u001b[38;5;129;01min\u001b[39;00m dfs\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# Exclude duplicate reviews\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     docs \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      4\u001b[0m              \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta\u001b[39m\u001b[38;5;124m\"\u001b[39m:{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mitem_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m],\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplit\u001b[39m\u001b[38;5;124m\"\u001b[39m: split}}\n\u001b[1;32m      5\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m _,row \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mdrop_duplicates(subset\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39miterrows()]\n\u001b[0;32m----> 6\u001b[0m     \u001b[43mdocument_store\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdocument\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoaded \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdocument_store\u001b[38;5;241m.\u001b[39mget_document_count()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m documents\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/haystack/document_stores/search_engine.py:421\u001b[0m, in \u001b[0;36mSearchEngineDocumentStore.write_documents\u001b[0;34m(self, documents, index, batch_size, duplicate_documents, headers)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m    417\u001b[0m     duplicate_documents \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mduplicate_documents_options\n\u001b[1;32m    418\u001b[0m ), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mduplicate_documents parameter must be \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mduplicate_documents_options)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    420\u001b[0m field_map \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_document_field_map()\n\u001b[0;32m--> 421\u001b[0m document_objects \u001b[38;5;241m=\u001b[39m [Document\u001b[38;5;241m.\u001b[39mfrom_dict(d, field_map\u001b[38;5;241m=\u001b[39mfield_map) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(d, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m d \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[1;32m    422\u001b[0m document_objects \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_duplicate_documents(\n\u001b[1;32m    423\u001b[0m     documents\u001b[38;5;241m=\u001b[39mdocument_objects, index\u001b[38;5;241m=\u001b[39mindex, duplicate_documents\u001b[38;5;241m=\u001b[39mduplicate_documents, headers\u001b[38;5;241m=\u001b[39mheaders\n\u001b[1;32m    424\u001b[0m )\n\u001b[1;32m    425\u001b[0m documents_to_index \u001b[38;5;241m=\u001b[39m []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/haystack/document_stores/search_engine.py:421\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m    417\u001b[0m     duplicate_documents \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mduplicate_documents_options\n\u001b[1;32m    418\u001b[0m ), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mduplicate_documents parameter must be \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mduplicate_documents_options)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    420\u001b[0m field_map \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_document_field_map()\n\u001b[0;32m--> 421\u001b[0m document_objects \u001b[38;5;241m=\u001b[39m [\u001b[43mDocument\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfield_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfield_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(d, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m d \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[1;32m    422\u001b[0m document_objects \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_duplicate_documents(\n\u001b[1;32m    423\u001b[0m     documents\u001b[38;5;241m=\u001b[39mdocument_objects, index\u001b[38;5;241m=\u001b[39mindex, duplicate_documents\u001b[38;5;241m=\u001b[39mduplicate_documents, headers\u001b[38;5;241m=\u001b[39mheaders\n\u001b[1;32m    424\u001b[0m )\n\u001b[1;32m    425\u001b[0m documents_to_index \u001b[38;5;241m=\u001b[39m []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/haystack/schema.py:235\u001b[0m, in \u001b[0;36mDocument.from_dict\u001b[0;34m(cls, dict, field_map)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _new_doc\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent_type\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtable\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(_new_doc[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    233\u001b[0m     _new_doc[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m dataframe_from_list(_new_doc[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m--> 235\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_new_doc\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pydantic/dataclasses.py:329\u001b[0m, in \u001b[0;36mpydantic.dataclasses._add_pydantic_validation_attributes.new_init\u001b[0;34m()\u001b[0m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pydantic/dataclasses.py:293\u001b[0m, in \u001b[0;36mpydantic.dataclasses._add_pydantic_validation_attributes.handle_extra_init\u001b[0;34m()\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: Document.__init__() missing 1 required positional argument: 'content'"],"ename":"TypeError","evalue":"Document.__init__() missing 1 required positional argument: 'content'","output_type":"error"}]},{"cell_type":"markdown","source":"# TODO: loads of errors - looked up online seems Haystack has major changes - either read their tutorials or just build using Pinecone wor","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}