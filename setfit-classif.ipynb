{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install setfit","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T09:21:17.307243Z","iopub.execute_input":"2024-12-15T09:21:17.307547Z","iopub.status.idle":"2024-12-15T09:21:25.721831Z","shell.execute_reply.started":"2024-12-15T09:21:17.307519Z","shell.execute_reply":"2024-12-15T09:21:25.720983Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# SETFIT ERROR as of December 2024\n# AttributeError: 'CallbackHandler' object has no attribute 'tokenizer'\n# https://github.com/huggingface/setfit/issues/564\n# solution is to install older version of transformers\n!pip install transformers==4.45.2","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from setfit import SetFitModel\n\nmodel = SetFitModel.from_pretrained(\"BAAI/bge-small-en-v1.5\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T09:21:25.723095Z","iopub.execute_input":"2024-12-15T09:21:25.723421Z","iopub.status.idle":"2024-12-15T09:21:34.500657Z","shell.execute_reply.started":"2024-12-15T09:21:25.723392Z","shell.execute_reply":"2024-12-15T09:21:34.500015Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from datasets import load_dataset\n\ndataset = load_dataset(\"data-is-better-together/10k_prompts_ranked\")\n\ndataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T12:08:43.747045Z","iopub.execute_input":"2024-12-15T12:08:43.747304Z","iopub.status.idle":"2024-12-15T12:08:47.687499Z","shell.execute_reply.started":"2024-12-15T12:08:43.747264Z","shell.execute_reply":"2024-12-15T12:08:47.686847Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/11.4k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a9ac7e6ec60a4d7fbf6303015a3a83e2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/3.58M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"905ea123876044f89cfd107431659b96"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/10331 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6610c762f7e549a1988d82392a6a44f6"}},"metadata":{}},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['prompt', 'quality', 'metadata', 'avg_rating', 'num_responses', 'agreement_ratio', 'raw_responses', 'kind', 'cluster_description', 'topic'],\n        num_rows: 10331\n    })\n})"},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"dataset_tt = dataset[\"train\"].train_test_split(test_size=0.5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T12:08:47.688811Z","iopub.execute_input":"2024-12-15T12:08:47.689199Z","iopub.status.idle":"2024-12-15T12:08:47.712014Z","shell.execute_reply.started":"2024-12-15T12:08:47.689172Z","shell.execute_reply":"2024-12-15T12:08:47.711329Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"dataset_tt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T09:21:36.212438Z","iopub.execute_input":"2024-12-15T09:21:36.212685Z","iopub.status.idle":"2024-12-15T09:21:36.218411Z","shell.execute_reply.started":"2024-12-15T09:21:36.212660Z","shell.execute_reply":"2024-12-15T09:21:36.217754Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from setfit import sample_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T09:21:36.219430Z","iopub.execute_input":"2024-12-15T09:21:36.220113Z","iopub.status.idle":"2024-12-15T09:21:36.232306Z","shell.execute_reply.started":"2024-12-15T09:21:36.220073Z","shell.execute_reply":"2024-12-15T09:21:36.231640Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Mimic only having a few labeled examples from each class\n\n- here i'm taking 20 of each class (`topic` is the `label` in our current dataset, will rename later)\n- so `sample_dataset` from setfit should take 20 **of each possible label** so we should see 20 * 10 = 200 samples in train dataset below (since there are 10 labels in this dataset)\n\n## Update\n\ndoing 20 samples for all 10 classes, with 500 steps, i get accuracy of 0.505 after 20 mins\n\n- the advice is that you get better results with more data, so i'll try 100 samples of each now","metadata":{}},{"cell_type":"code","source":"#train_dataset = sample_dataset(dataset_tt[\"train\"], label_column=\"topic\", num_samples=20) # get 0.505 accuracy with 500 steps\n\ntrain_dataset = sample_dataset(dataset_tt[\"train\"], label_column=\"topic\", num_samples=100) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T09:21:48.427135Z","iopub.execute_input":"2024-12-15T09:21:48.427583Z","iopub.status.idle":"2024-12-15T09:21:48.595235Z","shell.execute_reply.started":"2024-12-15T09:21:48.427529Z","shell.execute_reply":"2024-12-15T09:21:48.594346Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T09:21:48.596928Z","iopub.execute_input":"2024-12-15T09:21:48.597251Z","iopub.status.idle":"2024-12-15T09:21:48.602595Z","shell.execute_reply.started":"2024-12-15T09:21:48.597223Z","shell.execute_reply":"2024-12-15T09:21:48.601644Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_dataset = dataset_tt[\"test\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T09:21:48.603558Z","iopub.execute_input":"2024-12-15T09:21:48.603805Z","iopub.status.idle":"2024-12-15T09:21:48.613153Z","shell.execute_reply.started":"2024-12-15T09:21:48.603782Z","shell.execute_reply":"2024-12-15T09:21:48.612283Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T09:21:48.614960Z","iopub.execute_input":"2024-12-15T09:21:48.615243Z","iopub.status.idle":"2024-12-15T09:21:48.627104Z","shell.execute_reply.started":"2024-12-15T09:21:48.615205Z","shell.execute_reply":"2024-12-15T09:21:48.626177Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from setfit import TrainingArguments\n\nargs = TrainingArguments(\n    batch_size=32,\n    #num_epochs=1, # adjusted down from 10\n    max_steps=500, # get 40% accuracy at 50 steps on the test dataset, tried small number to make sure it works\n    report_to=\"none\",\n)\n\n\"\"\"\nThe num_epochs and max_steps arguments are frequently used to increase and decrease the number of total training steps. Consider that with SetFit, better performance is reached with more data, not more training! Don’t be afraid to train for less than 1 epoch if you have a lot of data.\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T09:21:48.627908Z","iopub.execute_input":"2024-12-15T09:21:48.628136Z","iopub.status.idle":"2024-12-15T09:21:48.640052Z","shell.execute_reply.started":"2024-12-15T09:21:48.628113Z","shell.execute_reply":"2024-12-15T09:21:48.639337Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from setfit import Trainer\n\ntrainer = Trainer(\n    model=model,\n    args=args,\n    train_dataset=train_dataset,\n    column_mapping={\"prompt\":\"text\", \"topic\":\"label\"} # <--- SETFIT EXPECTS text AND label RESPECTIVELY\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T09:21:48.640873Z","iopub.execute_input":"2024-12-15T09:21:48.641077Z","iopub.status.idle":"2024-12-15T09:21:49.479245Z","shell.execute_reply.started":"2024-12-15T09:21:48.641056Z","shell.execute_reply":"2024-12-15T09:21:49.478624Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nos.environ[\"WANDB_DISABLED\"] = \"true\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T12:08:47.716048Z","iopub.execute_input":"2024-12-15T12:08:47.716452Z","iopub.status.idle":"2024-12-15T12:08:47.722859Z","shell.execute_reply.started":"2024-12-15T12:08:47.716414Z","shell.execute_reply":"2024-12-15T12:08:47.722207Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import wandb\nwandb.init(mode=\"disabled\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T09:21:49.485115Z","iopub.execute_input":"2024-12-15T09:21:49.485377Z","iopub.status.idle":"2024-12-15T09:21:50.013006Z","shell.execute_reply.started":"2024-12-15T09:21:49.485354Z","shell.execute_reply":"2024-12-15T09:21:50.012253Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T09:21:50.013841Z","iopub.execute_input":"2024-12-15T09:21:50.014373Z","iopub.status.idle":"2024-12-15T09:42:01.155723Z","shell.execute_reply.started":"2024-12-15T09:21:50.014346Z","shell.execute_reply":"2024-12-15T09:42:01.154336Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.evaluate(test_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T09:42:01.164252Z","iopub.execute_input":"2024-12-15T09:42:01.164792Z","iopub.status.idle":"2024-12-15T09:42:17.363031Z","shell.execute_reply.started":"2024-12-15T09:42:01.164733Z","shell.execute_reply":"2024-12-15T09:42:17.362122Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.predict([\"write a new novel for me\", \"what is the best place to go to visit in italy?\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T09:42:17.364199Z","iopub.execute_input":"2024-12-15T09:42:17.364582Z","iopub.status.idle":"2024-12-15T09:42:17.396157Z","shell.execute_reply.started":"2024-12-15T09:42:17.364532Z","shell.execute_reply":"2024-12-15T09:42:17.395324Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Summary\n\n- with 20 samples and 500 training steps, get 50.5 % accuracy (not shown in notebook, deleted test run)\n- with 100 samples from each class, and 500 training steps, get 56.4 % accuracy\n\n## Try much larger number of samples, then will compare with finetuning a BERT type model\n\n- use 200 samples from each class","metadata":{}},{"cell_type":"code","source":"train_dataset2 = sample_dataset(dataset_tt[\"train\"], label_column=\"topic\", num_samples=200) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T09:52:26.121949Z","iopub.execute_input":"2024-12-15T09:52:26.122263Z","iopub.status.idle":"2024-12-15T09:52:26.271771Z","shell.execute_reply.started":"2024-12-15T09:52:26.122237Z","shell.execute_reply":"2024-12-15T09:52:26.271116Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"args2 = TrainingArguments(\n    batch_size=32,\n    #num_epochs=1, # adjusted down from 10\n    max_steps=500, # get 40% accuracy at 50 steps on the test dataset, tried small number to make sure it works\n    report_to=\"none\",\n)\n\ntrainer2 = Trainer(\n    model=model,\n    args=args2,\n    train_dataset=train_dataset2,\n    column_mapping={\"prompt\":\"text\", \"topic\":\"label\"} # <--- SETFIT EXPECTS text AND label RESPECTIVELY\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T09:52:55.728184Z","iopub.execute_input":"2024-12-15T09:52:55.728534Z","iopub.status.idle":"2024-12-15T09:52:56.403161Z","shell.execute_reply.started":"2024-12-15T09:52:55.728507Z","shell.execute_reply":"2024-12-15T09:52:56.402540Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer2.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T09:53:08.921658Z","iopub.execute_input":"2024-12-15T09:53:08.922013Z","iopub.status.idle":"2024-12-15T10:13:28.931811Z","shell.execute_reply.started":"2024-12-15T09:53:08.921986Z","shell.execute_reply":"2024-12-15T10:13:28.930588Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer2.evaluate(test_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T10:17:49.970372Z","iopub.execute_input":"2024-12-15T10:17:49.971064Z","iopub.status.idle":"2024-12-15T10:18:05.332441Z","shell.execute_reply.started":"2024-12-15T10:17:49.971029Z","shell.execute_reply":"2024-12-15T10:18:05.331477Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Comments\n\n- 56.8 with way more samples compared to 56.4 with 100 samples per label","metadata":{}},{"cell_type":"markdown","source":"# Do a trained distilBERT comparison","metadata":{}},{"cell_type":"code","source":"dataset_tt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T10:48:51.540323Z","iopub.execute_input":"2024-12-15T10:48:51.541181Z","iopub.status.idle":"2024-12-15T10:48:51.546415Z","shell.execute_reply.started":"2024-12-15T10:48:51.541143Z","shell.execute_reply":"2024-12-15T10:48:51.545586Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset_tt[\"train\"].features","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T10:42:57.375372Z","iopub.execute_input":"2024-12-15T10:42:57.375728Z","iopub.status.idle":"2024-12-15T10:42:57.382248Z","shell.execute_reply.started":"2024-12-15T10:42:57.375696Z","shell.execute_reply":"2024-12-15T10:42:57.381340Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install evaluate accelerate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T10:22:54.135497Z","iopub.execute_input":"2024-12-15T10:22:54.135836Z","iopub.status.idle":"2024-12-15T10:23:02.347950Z","shell.execute_reply.started":"2024-12-15T10:22:54.135810Z","shell.execute_reply":"2024-12-15T10:23:02.347039Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"MODEL_NAME = \"distilbert/distilbert-base-uncased\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T10:53:32.445246Z","iopub.execute_input":"2024-12-15T10:53:32.445646Z","iopub.status.idle":"2024-12-15T10:53:32.449825Z","shell.execute_reply.started":"2024-12-15T10:53:32.445615Z","shell.execute_reply":"2024-12-15T10:53:32.448788Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T10:53:29.576555Z","iopub.execute_input":"2024-12-15T10:53:29.577440Z","iopub.status.idle":"2024-12-15T10:53:29.714055Z","shell.execute_reply.started":"2024-12-15T10:53:29.577394Z","shell.execute_reply":"2024-12-15T10:53:29.713403Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset_tt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T10:49:23.648542Z","iopub.execute_input":"2024-12-15T10:49:23.648865Z","iopub.status.idle":"2024-12-15T10:49:23.654493Z","shell.execute_reply.started":"2024-12-15T10:49:23.648838Z","shell.execute_reply":"2024-12-15T10:49:23.653582Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset_tt = dataset_tt.rename_column(\"prompt\",\"text\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T10:44:21.579063Z","iopub.execute_input":"2024-12-15T10:44:21.579449Z","iopub.status.idle":"2024-12-15T10:44:21.960694Z","shell.execute_reply.started":"2024-12-15T10:44:21.579414Z","shell.execute_reply":"2024-12-15T10:44:21.959509Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset_tt = dataset_tt.rename_column(\"topic\",\"label\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T10:44:39.823640Z","iopub.execute_input":"2024-12-15T10:44:39.823985Z","iopub.status.idle":"2024-12-15T10:44:39.884396Z","shell.execute_reply.started":"2024-12-15T10:44:39.823953Z","shell.execute_reply":"2024-12-15T10:44:39.883313Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset_tt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T10:44:43.977346Z","iopub.execute_input":"2024-12-15T10:44:43.977700Z","iopub.status.idle":"2024-12-15T10:44:43.983163Z","shell.execute_reply.started":"2024-12-15T10:44:43.977669Z","shell.execute_reply":"2024-12-15T10:44:43.982232Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset_tt = dataset_tt.remove_columns(['quality', 'metadata', 'avg_rating', 'num_responses', 'agreement_ratio', 'raw_responses', 'kind', 'cluster_description'])\n\ndataset_tt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T10:45:07.829743Z","iopub.execute_input":"2024-12-15T10:45:07.830555Z","iopub.status.idle":"2024-12-15T10:45:07.840376Z","shell.execute_reply.started":"2024-12-15T10:45:07.830519Z","shell.execute_reply":"2024-12-15T10:45:07.839597Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def preprocess_function(examples):\n    return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\") # adding padding = \"max_length\" here","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T10:53:03.440553Z","iopub.execute_input":"2024-12-15T10:53:03.441251Z","iopub.status.idle":"2024-12-15T10:53:03.445135Z","shell.execute_reply.started":"2024-12-15T10:53:03.441219Z","shell.execute_reply":"2024-12-15T10:53:03.444353Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tokenized_ds = dataset_tt.map(preprocess_function, batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T10:53:05.224257Z","iopub.execute_input":"2024-12-15T10:53:05.224620Z","iopub.status.idle":"2024-12-15T10:53:08.505024Z","shell.execute_reply.started":"2024-12-15T10:53:05.224591Z","shell.execute_reply":"2024-12-15T10:53:08.504143Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# deleted data collator, causing bugs i can't understand why (it's literally the docs on HF site)","metadata":{}},{"cell_type":"code","source":"import evaluate\n\naccuracy = evaluate.load(\"accuracy\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T10:53:11.306605Z","iopub.execute_input":"2024-12-15T10:53:11.307341Z","iopub.status.idle":"2024-12-15T10:53:11.753549Z","shell.execute_reply.started":"2024-12-15T10:53:11.307298Z","shell.execute_reply":"2024-12-15T10:53:11.752659Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\n\n\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    predictions = np.argmax(predictions, axis=1)\n    return accuracy.compute(predictions=predictions, references=labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T10:53:12.505119Z","iopub.execute_input":"2024-12-15T10:53:12.505466Z","iopub.status.idle":"2024-12-15T10:53:12.510036Z","shell.execute_reply.started":"2024-12-15T10:53:12.505431Z","shell.execute_reply":"2024-12-15T10:53:12.509116Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Get labels, they don't seem to be accessible in dataset itseflf","metadata":{}},{"cell_type":"code","source":"TVT_KEYS = (\"train\",\"test\")\nALL_LABELS_NAMES = set()\n\nfor key in TVT_KEYS:\n    for sample in dataset_tt[key]:\n        ALL_LABELS_NAMES.add(sample[\"label\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T10:53:15.336576Z","iopub.execute_input":"2024-12-15T10:53:15.336918Z","iopub.status.idle":"2024-12-15T10:53:15.897501Z","shell.execute_reply.started":"2024-12-15T10:53:15.336885Z","shell.execute_reply":"2024-12-15T10:53:15.896605Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ALL_LABELS_NAMES = sorted(ALL_LABELS_NAMES)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T10:53:15.898865Z","iopub.execute_input":"2024-12-15T10:53:15.899137Z","iopub.status.idle":"2024-12-15T10:53:15.903025Z","shell.execute_reply.started":"2024-12-15T10:53:15.899113Z","shell.execute_reply":"2024-12-15T10:53:15.901986Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(ALL_LABELS_NAMES, len(ALL_LABELS_NAMES))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T10:53:15.904047Z","iopub.execute_input":"2024-12-15T10:53:15.904341Z","iopub.status.idle":"2024-12-15T10:53:15.914092Z","shell.execute_reply.started":"2024-12-15T10:53:15.904304Z","shell.execute_reply":"2024-12-15T10:53:15.913280Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"label2id = {label_name:idx for idx,label_name in enumerate(ALL_LABELS_NAMES)}\n\nprint(label2id)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T10:53:17.177331Z","iopub.execute_input":"2024-12-15T10:53:17.178219Z","iopub.status.idle":"2024-12-15T10:53:17.182779Z","shell.execute_reply.started":"2024-12-15T10:53:17.178180Z","shell.execute_reply":"2024-12-15T10:53:17.181863Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"id2label = {idx:label_name for label_name,idx in label2id.items()}\n\nprint(id2label)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T10:53:17.320735Z","iopub.execute_input":"2024-12-15T10:53:17.321002Z","iopub.status.idle":"2024-12-15T10:53:17.326226Z","shell.execute_reply.started":"2024-12-15T10:53:17.320975Z","shell.execute_reply":"2024-12-15T10:53:17.325422Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"NUM_LABELS = len(label2id)\n\nprint(NUM_LABELS)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T10:53:17.504795Z","iopub.execute_input":"2024-12-15T10:53:17.505052Z","iopub.status.idle":"2024-12-15T10:53:17.509111Z","shell.execute_reply.started":"2024-12-15T10:53:17.505025Z","shell.execute_reply":"2024-12-15T10:53:17.508283Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import DistilBertForSequenceClassification, TrainingArguments, Trainer\n\nmodel = DistilBertForSequenceClassification.from_pretrained(\n    MODEL_NAME, num_labels=NUM_LABELS, id2label=id2label, label2id=label2id\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T10:54:07.180344Z","iopub.execute_input":"2024-12-15T10:54:07.180693Z","iopub.status.idle":"2024-12-15T10:54:07.401240Z","shell.execute_reply.started":"2024-12-15T10:54:07.180662Z","shell.execute_reply":"2024-12-15T10:54:07.400631Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tokenized_ds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T10:54:13.401399Z","iopub.execute_input":"2024-12-15T10:54:13.401726Z","iopub.status.idle":"2024-12-15T10:54:13.407574Z","shell.execute_reply.started":"2024-12-15T10:54:13.401698Z","shell.execute_reply":"2024-12-15T10:54:13.406739Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#tokenized_ds = tokenized_ds.remove_columns(tokenized_ds[\"train\"].column_names)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T10:40:38.948617Z","iopub.execute_input":"2024-12-15T10:40:38.949640Z","iopub.status.idle":"2024-12-15T10:40:38.959140Z","shell.execute_reply.started":"2024-12-15T10:40:38.949578Z","shell.execute_reply":"2024-12-15T10:40:38.958264Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tokenized_ds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T10:47:09.020734Z","iopub.execute_input":"2024-12-15T10:47:09.021374Z","iopub.status.idle":"2024-12-15T10:47:09.026785Z","shell.execute_reply.started":"2024-12-15T10:47:09.021326Z","shell.execute_reply":"2024-12-15T10:47:09.025811Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, padding=\"max_length\", truncation=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T10:54:30.085291Z","iopub.execute_input":"2024-12-15T10:54:30.085649Z","iopub.status.idle":"2024-12-15T10:54:30.221079Z","shell.execute_reply.started":"2024-12-15T10:54:30.085618Z","shell.execute_reply":"2024-12-15T10:54:30.220458Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tokenized_ds[\"train\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T10:54:34.162432Z","iopub.execute_input":"2024-12-15T10:54:34.162777Z","iopub.status.idle":"2024-12-15T10:54:34.168229Z","shell.execute_reply.started":"2024-12-15T10:54:34.162746Z","shell.execute_reply":"2024-12-15T10:54:34.167423Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tokenized_ds[\"train\"][0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T10:54:59.009322Z","iopub.execute_input":"2024-12-15T10:54:59.009689Z","iopub.status.idle":"2024-12-15T10:54:59.025122Z","shell.execute_reply.started":"2024-12-15T10:54:59.009659Z","shell.execute_reply":"2024-12-15T10:54:59.024143Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=\"finetuned-prompt-classifier\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    num_train_epochs=2,\n    weight_decay=0.01,\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    load_best_model_at_end=True,\n    push_to_hub=False,\n    report_to=\"none\"\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_ds[\"train\"],\n    eval_dataset=tokenized_ds[\"test\"],\n    tokenizer=tokenizer,\n    #data_collator=data_collator, # <--- deleted during debug, doesn't work and answers are unclear on HF github\n    compute_metrics=compute_metrics,\n)\n\ntraining_metrics = trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T10:54:41.480299Z","iopub.execute_input":"2024-12-15T10:54:41.481111Z","iopub.status.idle":"2024-12-15T10:54:42.059538Z","shell.execute_reply.started":"2024-12-15T10:54:41.481075Z","shell.execute_reply":"2024-12-15T10:54:42.058142Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Update - maybe the label field needs to be the INTEGER value not the string (so unclear)","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\n\ndataset = load_dataset(\"data-is-better-together/10k_prompts_ranked\")\n\ndataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T12:10:09.222232Z","iopub.execute_input":"2024-12-15T12:10:09.222606Z","iopub.status.idle":"2024-12-15T12:10:09.832931Z","shell.execute_reply.started":"2024-12-15T12:10:09.222574Z","shell.execute_reply":"2024-12-15T12:10:09.832064Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['prompt', 'quality', 'metadata', 'avg_rating', 'num_responses', 'agreement_ratio', 'raw_responses', 'kind', 'cluster_description', 'topic'],\n        num_rows: 10331\n    })\n})"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"dataset_tt = dataset[\"train\"].train_test_split(test_size=0.5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T12:10:10.759407Z","iopub.execute_input":"2024-12-15T12:10:10.760216Z","iopub.status.idle":"2024-12-15T12:10:10.777002Z","shell.execute_reply.started":"2024-12-15T12:10:10.760175Z","shell.execute_reply":"2024-12-15T12:10:10.776116Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"dataset_tt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T12:10:14.849565Z","iopub.execute_input":"2024-12-15T12:10:14.849892Z","iopub.status.idle":"2024-12-15T12:10:14.855828Z","shell.execute_reply.started":"2024-12-15T12:10:14.849865Z","shell.execute_reply":"2024-12-15T12:10:14.854857Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['prompt', 'quality', 'metadata', 'avg_rating', 'num_responses', 'agreement_ratio', 'raw_responses', 'kind', 'cluster_description', 'topic'],\n        num_rows: 5165\n    })\n    test: Dataset({\n        features: ['prompt', 'quality', 'metadata', 'avg_rating', 'num_responses', 'agreement_ratio', 'raw_responses', 'kind', 'cluster_description', 'topic'],\n        num_rows: 5166\n    })\n})"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"!pip install evaluate accelerate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T12:10:42.052896Z","iopub.execute_input":"2024-12-15T12:10:42.053712Z","iopub.status.idle":"2024-12-15T12:10:51.701166Z","shell.execute_reply.started":"2024-12-15T12:10:42.053676Z","shell.execute_reply":"2024-12-15T12:10:51.700026Z"}},"outputs":[{"name":"stdout","text":"Collecting evaluate\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (1.1.1)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.1.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.2.3)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.26.2)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.2)\nRequirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.5)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.4.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.15.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (17.0.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.5)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.6.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\nDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.3\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"MODEL_NAME = \"distilbert/distilbert-base-uncased\"\n\nfrom transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n\ndataset_tt = dataset_tt.rename_column(\"prompt\",\"text\")\n\ndataset_tt = dataset_tt.rename_column(\"topic\",\"label_STRING\")\n\ndataset_tt = dataset_tt.remove_columns(['quality', 'metadata', 'avg_rating', 'num_responses', 'agreement_ratio', 'raw_responses', 'kind', 'cluster_description'])\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T12:13:25.826156Z","iopub.execute_input":"2024-12-15T12:13:25.826591Z","iopub.status.idle":"2024-12-15T12:13:30.173212Z","shell.execute_reply.started":"2024-12-15T12:13:25.826553Z","shell.execute_reply":"2024-12-15T12:13:30.172490Z"}},"outputs":[{"name":"stderr","text":"The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b9841b356564d6096162e8184fc3d68"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a1c4ee7244d4c1391830496d998b3bd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e8b0ab94a83e43bd9f2e92e65173c42d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"777f03fbbb29445eb7b77ee4e16ca1a8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"faf9039e923545b197f89fd454c1fc47"}},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"TVT_KEYS = (\"train\",\"test\")\nALL_LABELS_NAMES = set()\n\nfor key in TVT_KEYS:\n    for sample in dataset_tt[key]:\n        ALL_LABELS_NAMES.add(sample[\"label_STRING\"])\n\nALL_LABELS_NAMES = sorted(ALL_LABELS_NAMES)\n\nlabel2id = {label_name:idx for idx,label_name in enumerate(ALL_LABELS_NAMES)}\n\n\nid2label = {idx:label_name for label_name,idx in label2id.items()}\n\n\nNUM_LABELS = len(label2id)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T12:15:36.577268Z","iopub.execute_input":"2024-12-15T12:15:36.578151Z","iopub.status.idle":"2024-12-15T12:15:37.136228Z","shell.execute_reply.started":"2024-12-15T12:15:36.578113Z","shell.execute_reply":"2024-12-15T12:15:37.135583Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"dataset_tt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T12:19:16.862735Z","iopub.execute_input":"2024-12-15T12:19:16.863072Z","iopub.status.idle":"2024-12-15T12:19:16.868832Z","shell.execute_reply.started":"2024-12-15T12:19:16.863040Z","shell.execute_reply":"2024-12-15T12:19:16.867937Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['text', 'label_STRING'],\n        num_rows: 5165\n    })\n    test: Dataset({\n        features: ['text', 'label_STRING'],\n        num_rows: 5166\n    })\n})"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"def convert_to_id(example):\n    example[\"label\"] = label2id[ example[\"label_STRING\"] ]\n    return example\n\ndataset_tt = dataset_tt.map(convert_to_id)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T12:20:50.249288Z","iopub.execute_input":"2024-12-15T12:20:50.249913Z","iopub.status.idle":"2024-12-15T12:20:51.341857Z","shell.execute_reply.started":"2024-12-15T12:20:50.249877Z","shell.execute_reply":"2024-12-15T12:20:51.341009Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/5165 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0809365f558e486492a586ac6ebe1a85"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/5166 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47cee2e246154ac989e1ab92924e212f"}},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"dataset_tt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T12:20:53.615479Z","iopub.execute_input":"2024-12-15T12:20:53.616169Z","iopub.status.idle":"2024-12-15T12:20:53.621563Z","shell.execute_reply.started":"2024-12-15T12:20:53.616135Z","shell.execute_reply":"2024-12-15T12:20:53.620582Z"}},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['text', 'label_STRING', 'label'],\n        num_rows: 5165\n    })\n    test: Dataset({\n        features: ['text', 'label_STRING', 'label'],\n        num_rows: 5166\n    })\n})"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"dataset_tt = dataset_tt.remove_columns(\"label_STRING\")\n\ndataset_tt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T12:21:19.596087Z","iopub.execute_input":"2024-12-15T12:21:19.596841Z","iopub.status.idle":"2024-12-15T12:21:19.606375Z","shell.execute_reply.started":"2024-12-15T12:21:19.596801Z","shell.execute_reply":"2024-12-15T12:21:19.605252Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['text', 'label'],\n        num_rows: 5165\n    })\n    test: Dataset({\n        features: ['text', 'label'],\n        num_rows: 5166\n    })\n})"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"def preprocess_function(examples):\n    return tokenizer(examples[\"text\"], truncation=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T12:21:52.032089Z","iopub.execute_input":"2024-12-15T12:21:52.032768Z","iopub.status.idle":"2024-12-15T12:21:52.036988Z","shell.execute_reply.started":"2024-12-15T12:21:52.032731Z","shell.execute_reply":"2024-12-15T12:21:52.036017Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"from transformers import DataCollatorWithPadding\n\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n\ntokenized_ds = dataset_tt.map(preprocess_function, batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T12:21:54.679464Z","iopub.execute_input":"2024-12-15T12:21:54.679865Z","iopub.status.idle":"2024-12-15T12:21:56.613464Z","shell.execute_reply.started":"2024-12-15T12:21:54.679834Z","shell.execute_reply":"2024-12-15T12:21:56.612625Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/5165 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"921ccf12c3ac4d9db0a50a6903d43f68"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/5166 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d5acadc5edd342d2b354bccdac2032b7"}},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"from transformers import DistilBertForSequenceClassification, TrainingArguments, Trainer\n\nmodel = DistilBertForSequenceClassification.from_pretrained(\n    MODEL_NAME, num_labels=NUM_LABELS, id2label=id2label, label2id=label2id\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T12:22:14.889734Z","iopub.execute_input":"2024-12-15T12:22:14.890491Z","iopub.status.idle":"2024-12-15T12:22:18.446541Z","shell.execute_reply.started":"2024-12-15T12:22:14.890458Z","shell.execute_reply":"2024-12-15T12:22:18.445572Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"136a9aaf6bfb44069db591264c040dfd"}},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"import evaluate\n\n\n\naccuracy = evaluate.load(\"accuracy\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T12:22:53.420443Z","iopub.execute_input":"2024-12-15T12:22:53.421328Z","iopub.status.idle":"2024-12-15T12:22:53.942807Z","shell.execute_reply.started":"2024-12-15T12:22:53.421279Z","shell.execute_reply":"2024-12-15T12:22:53.942023Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c97a78e90a88430b96760dc7c2cfdc7e"}},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"import numpy as np\n\n\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    predictions = np.argmax(predictions, axis=1)\n    return accuracy.compute(predictions=predictions, references=labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T12:23:05.775937Z","iopub.execute_input":"2024-12-15T12:23:05.776267Z","iopub.status.idle":"2024-12-15T12:23:05.780838Z","shell.execute_reply.started":"2024-12-15T12:23:05.776237Z","shell.execute_reply":"2024-12-15T12:23:05.779922Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=\"finetuned-prompt-classifier\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    num_train_epochs=2,\n    weight_decay=0.01,\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    load_best_model_at_end=True,\n    push_to_hub=False,\n    report_to=\"none\"\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_ds[\"train\"],\n    eval_dataset=tokenized_ds[\"test\"],\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n)\n\ntraining_metrics = trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T12:23:41.955234Z","iopub.execute_input":"2024-12-15T12:23:41.955634Z","iopub.status.idle":"2024-12-15T12:29:29.235136Z","shell.execute_reply.started":"2024-12-15T12:23:41.955600Z","shell.execute_reply":"2024-12-15T12:29:29.234457Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_23/3769499833.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='324' max='324' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [324/324 05:44, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>1.439651</td>\n      <td>0.554007</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>1.335148</td>\n      <td>0.577623</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"print(training_metrics)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T12:42:47.500541Z","iopub.execute_input":"2024-12-15T12:42:47.500906Z","iopub.status.idle":"2024-12-15T12:42:47.505968Z","shell.execute_reply.started":"2024-12-15T12:42:47.500876Z","shell.execute_reply":"2024-12-15T12:42:47.505011Z"}},"outputs":[{"name":"stdout","text":"TrainOutput(global_step=324, training_loss=1.5420913696289062, metrics={'train_runtime': 346.3371, 'train_samples_per_second': 29.826, 'train_steps_per_second': 0.936, 'total_flos': 1291514725825200.0, 'train_loss': 1.5420913696289062, 'epoch': 2.0})\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"trainer.evaluate(tokenized_ds[\"test\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T12:43:07.233793Z","iopub.execute_input":"2024-12-15T12:43:07.234141Z","iopub.status.idle":"2024-12-15T12:43:54.558962Z","shell.execute_reply.started":"2024-12-15T12:43:07.234111Z","shell.execute_reply":"2024-12-15T12:43:54.558236Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='162' max='162' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [162/162 00:46]\n    </div>\n    "},"metadata":{}},{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 1.3351483345031738,\n 'eval_accuracy': 0.5776229190863337,\n 'eval_runtime': 47.3161,\n 'eval_samples_per_second': 109.181,\n 'eval_steps_per_second': 3.424,\n 'epoch': 2.0}"},"metadata":{}}],"execution_count":31},{"cell_type":"markdown","source":"# BERT training\n\n- 57.7 accuracy vs 56.8 with the SetFit faster approach\n\nNeed to comparge larger embedding models maybe\n\nNot sure why this dataset is so difficult also?","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}