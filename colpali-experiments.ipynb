{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Setup ColPali\n\n- early experiments trying model\n- accepted Gemma / PaliGemma Google licence\n\n---\n\n**so far: unclear how to do inference myself - maybe read (https://github.com/ManuelFay/colpali/blob/main/demo/app.py)[https://github.com/ManuelFay/colpali/blob/main/demo/app.py] page which is the HF demo** i.e. (https://huggingface.co/spaces/manu/ColPali-demo)[https://huggingface.co/spaces/manu/ColPali-demo]","metadata":{}},{"cell_type":"code","source":"!pip install git+https://github.com/ManuelFay/colpali","metadata":{"execution":{"iopub.status.busy":"2024-07-14T21:18:54.615586Z","iopub.execute_input":"2024-07-14T21:18:54.616329Z","iopub.status.idle":"2024-07-14T21:21:29.681465Z","shell.execute_reply.started":"2024-07-14T21:18:54.616302Z","shell.execute_reply":"2024-07-14T21:21:29.680161Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting git+https://github.com/ManuelFay/colpali\n  Cloning https://github.com/ManuelFay/colpali to /tmp/pip-req-build-0801jj43\n  Running command git clone --filter=blob:none --quiet https://github.com/ManuelFay/colpali /tmp/pip-req-build-0801jj43\n  Resolved https://github.com/ManuelFay/colpali to commit dec4f1c032ed93f19e3445a3ccd0cfe7649bd557\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hCollecting torch>=2.2.0 (from colpali_engine==0.0.1)\n  Downloading torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\nRequirement already satisfied: transformers>=4.41.1 in /opt/conda/lib/python3.10/site-packages (from colpali_engine==0.0.1) (4.42.3)\nCollecting mteb>=1.12.22 (from colpali_engine==0.0.1)\n  Downloading mteb-1.12.79-py3-none-any.whl.metadata (25 kB)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from colpali_engine==0.0.1) (2.32.3)\nCollecting GPUtil (from colpali_engine==0.0.1)\n  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting peft<0.12.0,>=0.11.0 (from colpali_engine==0.0.1)\n  Downloading peft-0.11.1-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: datasets>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from mteb>=1.12.22->colpali_engine==0.0.1) (2.20.0)\nRequirement already satisfied: numpy<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from mteb>=1.12.22->colpali_engine==0.0.1) (1.26.4)\nRequirement already satisfied: scikit-learn>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from mteb>=1.12.22->colpali_engine==0.0.1) (1.2.2)\nRequirement already satisfied: scipy>=0.0.0 in /opt/conda/lib/python3.10/site-packages (from mteb>=1.12.22->colpali_engine==0.0.1) (1.11.4)\nCollecting sentence-transformers>=3.0.0 (from mteb>=1.12.22->colpali_engine==0.0.1)\n  Downloading sentence_transformers-3.0.1-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: tqdm>1.0.0 in /opt/conda/lib/python3.10/site-packages (from mteb>=1.12.22->colpali_engine==0.0.1) (4.66.4)\nRequirement already satisfied: rich>=0.0.0 in /opt/conda/lib/python3.10/site-packages (from mteb>=1.12.22->colpali_engine==0.0.1) (13.7.0)\nCollecting pytrec-eval-terrier>=0.5.6 (from mteb>=1.12.22->colpali_engine==0.0.1)\n  Downloading pytrec_eval_terrier-0.5.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (777 bytes)\nRequirement already satisfied: pydantic>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from mteb>=1.12.22->colpali_engine==0.0.1) (2.5.3)\nRequirement already satisfied: typing-extensions>=0.0.0 in /opt/conda/lib/python3.10/site-packages (from mteb>=1.12.22->colpali_engine==0.0.1) (4.9.0)\nCollecting eval-type-backport>=0.0.0 (from mteb>=1.12.22->colpali_engine==0.0.1)\n  Downloading eval_type_backport-0.2.0-py3-none-any.whl.metadata (2.2 kB)\nRequirement already satisfied: polars>=0.20.22 in /opt/conda/lib/python3.10/site-packages (from mteb>=1.12.22->colpali_engine==0.0.1) (1.1.0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft<0.12.0,>=0.11.0->colpali_engine==0.0.1) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft<0.12.0,>=0.11.0->colpali_engine==0.0.1) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft<0.12.0,>=0.11.0->colpali_engine==0.0.1) (6.0.1)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft<0.12.0,>=0.11.0->colpali_engine==0.0.1) (0.32.1)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft<0.12.0,>=0.11.0->colpali_engine==0.0.1) (0.4.3)\nRequirement already satisfied: huggingface-hub>=0.17.0 in /opt/conda/lib/python3.10/site-packages (from peft<0.12.0,>=0.11.0->colpali_engine==0.0.1) (0.23.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->colpali_engine==0.0.1) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->colpali_engine==0.0.1) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->colpali_engine==0.0.1) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->colpali_engine==0.0.1) (2024.7.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=2.2.0->colpali_engine==0.0.1) (3.13.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=2.2.0->colpali_engine==0.0.1) (1.13.0)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=2.2.0->colpali_engine==0.0.1) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=2.2.0->colpali_engine==0.0.1) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=2.2.0->colpali_engine==0.0.1) (2024.5.0)\nCollecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=2.2.0->colpali_engine==0.0.1)\n  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=2.2.0->colpali_engine==0.0.1)\n  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=2.2.0->colpali_engine==0.0.1)\n  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=2.2.0->colpali_engine==0.0.1)\n  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.1.3.1 (from torch>=2.2.0->colpali_engine==0.0.1)\n  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>=2.2.0->colpali_engine==0.0.1)\n  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=2.2.0->colpali_engine==0.0.1)\n  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=2.2.0->colpali_engine==0.0.1)\n  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=2.2.0->colpali_engine==0.0.1)\n  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-nccl-cu12==2.20.5 (from torch>=2.2.0->colpali_engine==0.0.1)\n  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvtx-cu12==12.1.105 (from torch>=2.2.0->colpali_engine==0.0.1)\n  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\nCollecting triton==2.3.1 (from torch>=2.2.0->colpali_engine==0.0.1)\n  Downloading triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\nCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.2.0->colpali_engine==0.0.1)\n  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.41.1->colpali_engine==0.0.1) (2023.12.25)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.41.1->colpali_engine==0.0.1) (0.19.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.19.0->mteb>=1.12.22->colpali_engine==0.0.1) (16.1.0)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets>=2.19.0->mteb>=1.12.22->colpali_engine==0.0.1) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.19.0->mteb>=1.12.22->colpali_engine==0.0.1) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets>=2.19.0->mteb>=1.12.22->colpali_engine==0.0.1) (2.2.2)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets>=2.19.0->mteb>=1.12.22->colpali_engine==0.0.1) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets>=2.19.0->mteb>=1.12.22->colpali_engine==0.0.1) (0.70.16)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.19.0->mteb>=1.12.22->colpali_engine==0.0.1) (3.9.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft<0.12.0,>=0.11.0->colpali_engine==0.0.1) (3.1.1)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.0.0->mteb>=1.12.22->colpali_engine==0.0.1) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.0.0->mteb>=1.12.22->colpali_engine==0.0.1) (2.14.6)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=0.0.0->mteb>=1.12.22->colpali_engine==0.0.1) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=0.0.0->mteb>=1.12.22->colpali_engine==0.0.1) (2.17.2)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=1.0.2->mteb>=1.12.22->colpali_engine==0.0.1) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=1.0.2->mteb>=1.12.22->colpali_engine==0.0.1) (3.2.0)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers>=3.0.0->mteb>=1.12.22->colpali_engine==0.0.1) (9.5.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=2.2.0->colpali_engine==0.0.1) (2.1.3)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=2.2.0->colpali_engine==0.0.1) (1.3.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.19.0->mteb>=1.12.22->colpali_engine==0.0.1) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.19.0->mteb>=1.12.22->colpali_engine==0.0.1) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.19.0->mteb>=1.12.22->colpali_engine==0.0.1) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.19.0->mteb>=1.12.22->colpali_engine==0.0.1) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.19.0->mteb>=1.12.22->colpali_engine==0.0.1) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.19.0->mteb>=1.12.22->colpali_engine==0.0.1) (4.0.3)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=0.0.0->mteb>=1.12.22->colpali_engine==0.0.1) (0.1.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets>=2.19.0->mteb>=1.12.22->colpali_engine==0.0.1) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets>=2.19.0->mteb>=1.12.22->colpali_engine==0.0.1) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets>=2.19.0->mteb>=1.12.22->colpali_engine==0.0.1) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.19.0->mteb>=1.12.22->colpali_engine==0.0.1) (1.16.0)\nDownloading mteb-1.12.79-py3-none-any.whl (4.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading peft-0.11.1-py3-none-any.whl (251 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.6/251.6 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl (779.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m84.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m70.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading eval_type_backport-0.2.0-py3-none-any.whl (5.9 kB)\nDownloading pytrec_eval_terrier-0.5.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (287 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.4/287.4 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m74.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: colpali_engine, GPUtil\n  Building wheel for colpali_engine (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for colpali_engine: filename=colpali_engine-0.0.1-py3-none-any.whl size=34163 sha256=140ba3fdc20960636ed17290d2ff786645a570e5b99eef6be3e5d6cec24be6be\n  Stored in directory: /tmp/pip-ephem-wheel-cache-vbiain72/wheels/2b/59/20/97614fcadc61cf2ee0951608919af1895eb2a93806065f34fe\n  Building wheel for GPUtil (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for GPUtil: filename=GPUtil-1.4.0-py3-none-any.whl size=7393 sha256=ab12dd2be14824d90292018e2635f787116f9a313e434e47700cbc4dbd2f68c7\n  Stored in directory: /root/.cache/pip/wheels/a9/8a/bd/81082387151853ab8b6b3ef33426e98f5cbfebc3c397a9d4d0\nSuccessfully built colpali_engine GPUtil\nInstalling collected packages: GPUtil, triton, pytrec-eval-terrier, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, eval-type-backport, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, sentence-transformers, peft, mteb, colpali_engine\n  Attempting uninstall: torch\n    Found existing installation: torch 2.1.2\n    Uninstalling torch-2.1.2:\n      Successfully uninstalled torch-2.1.2\nSuccessfully installed GPUtil-1.4.0 colpali_engine-0.0.1 eval-type-backport-0.2.0 mteb-1.12.79 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 peft-0.11.1 pytrec-eval-terrier-0.5.6 sentence-transformers-3.0.1 torch-2.3.1 triton-2.3.1\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\n#import typer\nfrom torch.utils.data import DataLoader\nfrom tqdm import tqdm\nfrom transformers import AutoProcessor\nfrom PIL import Image\n\nfrom colpali_engine.models.paligemma_colbert_architecture import ColPali\nfrom colpali_engine.trainer.retrieval_evaluator import CustomEvaluator\nfrom colpali_engine.utils.colpali_processing_utils import process_images, process_queries\nfrom colpali_engine.utils.image_from_page_utils import load_from_dataset","metadata":{"execution":{"iopub.status.busy":"2024-07-14T21:22:12.798615Z","iopub.execute_input":"2024-07-14T21:22:12.799455Z","iopub.status.idle":"2024-07-14T21:22:32.518231Z","shell.execute_reply.started":"2024-07-14T21:22:12.799409Z","shell.execute_reply":"2024-07-14T21:22:32.517248Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n  warn(\n2024-07-14 21:22:18.589884: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-14 21:22:18.590024: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-14 21:22:18.735423: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"from huggingface_hub import notebook_login","metadata":{"execution":{"iopub.status.busy":"2024-07-14T21:35:33.919589Z","iopub.execute_input":"2024-07-14T21:35:33.920278Z","iopub.status.idle":"2024-07-14T21:35:33.929437Z","shell.execute_reply.started":"2024-07-14T21:35:33.920202Z","shell.execute_reply":"2024-07-14T21:35:33.928596Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"notebook_login()","metadata":{"execution":{"iopub.status.busy":"2024-07-14T21:35:41.691606Z","iopub.execute_input":"2024-07-14T21:35:41.692304Z","iopub.status.idle":"2024-07-14T21:35:41.713467Z","shell.execute_reply.started":"2024-07-14T21:35:41.692274Z","shell.execute_reply":"2024-07-14T21:35:41.712565Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"329a25f61cf345b3ada7a0faf647ed0a"}},"metadata":{}}]},{"cell_type":"code","source":"\"\"\"Example script to run inference with ColPali\"\"\"\n# Load model\nmodel_name = \"vidore/colpali\"\nmodel = ColPali.from_pretrained(\"google/paligemma-3b-mix-448\", torch_dtype=torch.bfloat16, device_map=\"cuda\").eval()\nmodel.load_adapter(model_name)\nprocessor = AutoProcessor.from_pretrained(model_name)\n\n# select images -> load_from_pdf(<pdf_path>),  load_from_image_urls([\"<url_1>\"]), load_from_dataset(<path>)\nimages = load_from_dataset(\"vidore/docvqa_test_subsampled\")\nqueries = [\"From which university does James V. Fiorca come ?\", \"Who is the japanese prime minister?\"]\n\n# run inference - docs\ndataloader = DataLoader(\n    images,\n    batch_size=4,\n    shuffle=False,\n    collate_fn=lambda x: process_images(processor, x),\n)\nds = []\nfor batch_doc in tqdm(dataloader):\n    with torch.no_grad():\n        batch_doc = {k: v.to(model.device) for k, v in batch_doc.items()}\n        embeddings_doc = model(**batch_doc)\n    ds.extend(list(torch.unbind(embeddings_doc.to(\"cpu\"))))\n\n# run inference - queries\ndataloader = DataLoader(\n    queries,\n    batch_size=4,\n    shuffle=False,\n    collate_fn=lambda x: process_queries(processor, x, Image.new(\"RGB\", (448, 448), (255, 255, 255))),\n)\n\nqs = []\nfor batch_query in dataloader:\n    with torch.no_grad():\n        batch_query = {k: v.to(model.device) for k, v in batch_query.items()}\n        embeddings_query = model(**batch_query)\n    qs.extend(list(torch.unbind(embeddings_query.to(\"cpu\"))))\n\n# run evaluation\nretriever_evaluator = CustomEvaluator(is_multi_vector=True)\nscores = retriever_evaluator.evaluate(qs, ds)\nprint(scores.argmax(axis=1))","metadata":{"execution":{"iopub.status.busy":"2024-07-14T21:36:20.918647Z","iopub.execute_input":"2024-07-14T21:36:20.919335Z","iopub.status.idle":"2024-07-14T21:49:16.741840Z","shell.execute_reply.started":"2024-07-14T21:36:20.919301Z","shell.execute_reply":"2024-07-14T21:49:16.740835Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.05k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"34267ba7aa7a4cf38d74aea782d68b2c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/62.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f922c9ad8814ba4ae13d27dee5ebbaa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bec9845905e042d9af76b6f23d64f0ea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00003.safetensors:   0%|          | 0.00/4.96G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00c7da85381a4043844729227da688ec"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5960795841964ced8f137fd3d7613984"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00003.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d96a44b73cda4d6990a2f043fe89622c"}},"metadata":{}},{"name":"stderr","text":"`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.\nGemma's activation function will be set to `gelu_pytorch_tanh`. Please, use\n`config.hidden_activation` if you want to override this behaviour.\nSee https://github.com/huggingface/transformers/pull/29402 for more details.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d29ce0f4536c40a3a5eea555373149ad"}},"metadata":{}},{"name":"stderr","text":"Some weights of ColPali were not initialized from the model checkpoint at google/paligemma-3b-mix-448 and are newly initialized: ['custom_text_proj.bias', 'custom_text_proj.weight', 'language_model.lm_head.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"adapter_config.json:   0%|          | 0.00/746 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53bad364407a4fef9a856e3ca58e3cfe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/78.6M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab889b4604c54fb5b463a45abcf40ea1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/700 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa7d393404c247e790d2e06838ef5f93"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/243k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18eba82a202648cbb81e4a729e3fef1a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/4.26M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee0544ade9ed4420a566ea1b2ccc187c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.8M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db7e34d10a5241c48f96c861dd1c90a5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/24.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f26c94fb56b4281a07860250d4b443d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/733 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1cffa1a4fab4dd987e6cfe3fd4f2c65"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/2.45k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eae4b0dc7d694a4cac0001652807fef1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/292M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e13608ad16b403d938fcf1e788dde30"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21a4126d20964737ba7e70491bbdcdfa"}},"metadata":{}},{"name":"stderr","text":"100%|██████████| 125/125 [10:34<00:00,  5.08s/it]\n","output_type":"stream"},{"name":"stdout","text":"tensor([226, 214])\nTop 1 Accuracy (verif): 0.0\n[226 214]\n","output_type":"stream"}]},{"cell_type":"code","source":"import requests","metadata":{"execution":{"iopub.status.busy":"2024-07-14T22:00:39.909570Z","iopub.execute_input":"2024-07-14T22:00:39.910232Z","iopub.status.idle":"2024-07-14T22:00:39.914519Z","shell.execute_reply.started":"2024-07-14T22:00:39.910196Z","shell.execute_reply":"2024-07-14T22:00:39.913372Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"input_text = \"What color is the flower that bee is standing on?\"\nimg_url = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/bee.JPG?download=true\"\ninput_image = Image.open(requests.get(img_url, stream=True).raw)","metadata":{"execution":{"iopub.status.busy":"2024-07-14T22:00:42.111494Z","iopub.execute_input":"2024-07-14T22:00:42.112343Z","iopub.status.idle":"2024-07-14T22:00:42.359305Z","shell.execute_reply.started":"2024-07-14T22:00:42.112312Z","shell.execute_reply":"2024-07-14T22:00:42.358545Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ninputs = processor(text=input_text, images=input_image,\n                  padding=\"longest\", do_convert_rgb=True, return_tensors=\"pt\").to(\"cuda\")\nmodel.to(device)\ninputs = inputs.to(dtype=model.dtype)","metadata":{"execution":{"iopub.status.busy":"2024-07-14T22:01:09.589607Z","iopub.execute_input":"2024-07-14T22:01:09.590315Z","iopub.status.idle":"2024-07-14T22:01:09.923762Z","shell.execute_reply.started":"2024-07-14T22:01:09.590280Z","shell.execute_reply":"2024-07-14T22:01:09.922860Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"with torch.no_grad():\n  output = model.generate(**inputs, max_length=496)\n\nprint(processor.decode(output[0], skip_special_tokens=True))","metadata":{"execution":{"iopub.status.busy":"2024-07-14T22:01:40.136322Z","iopub.execute_input":"2024-07-14T22:01:40.137153Z","iopub.status.idle":"2024-07-14T22:01:40.623825Z","shell.execute_reply.started":"2024-07-14T22:01:40.137121Z","shell.execute_reply":"2024-07-14T22:01:40.622650Z"},"trusted":true},"execution_count":15,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m----> 2\u001b[0m   output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m496\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(processor\u001b[38;5;241m.\u001b[39mdecode(output[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1637\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1553\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1554\u001b[0m \n\u001b[1;32m   1555\u001b[0m \u001b[38;5;124;03mGenerates sequences of token ids for models with a language modeling head.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1634\u001b[0m \u001b[38;5;124;03m            - [`~generation.GenerateBeamEncoderDecoderOutput`]\u001b[39;00m\n\u001b[1;32m   1635\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1636\u001b[0m \u001b[38;5;66;03m# 1. Handle `generation_config` and kwargs that might update it, and validate the `.generate()` call\u001b[39;00m\n\u001b[0;32m-> 1637\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_model_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1638\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# Pull this out first, we only use it for stopping criteria\u001b[39;00m\n\u001b[1;32m   1639\u001b[0m generation_config, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_generation_config(generation_config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1162\u001b[0m, in \u001b[0;36mGenerationMixin._validate_model_class\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m generate_compatible_classes:\n\u001b[1;32m   1161\u001b[0m     exception_message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Please use one of the following classes instead: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgenerate_compatible_classes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1162\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(exception_message)\n","\u001b[0;31mTypeError\u001b[0m: The current model class (ColPali) is not compatible with `.generate()`, as it doesn't have a language model head. Please use one of the following classes instead: {'PaliGemmaForConditionalGeneration'}"],"ename":"TypeError","evalue":"The current model class (ColPali) is not compatible with `.generate()`, as it doesn't have a language model head. Please use one of the following classes instead: {'PaliGemmaForConditionalGeneration'}","output_type":"error"}]}]}