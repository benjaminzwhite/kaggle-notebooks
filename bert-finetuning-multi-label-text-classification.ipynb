{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30703,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# BERT finetuning for multi-label text classification\n\n## Niels Rogge Transformers Tutorials\n\n[https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/BERT/Fine_tuning_BERT_(and_friends)_for_multi_label_text_classification.ipynb#scrollTo=i4ENBTdulBEI](https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/BERT/Fine_tuning_BERT_(and_friends)_for_multi_label_text_classification.ipynb#scrollTo=i4ENBTdulBEI)","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\n\ndataset = load_dataset(\"sem_eval_2018_task_1\", \"subtask5.english\")","metadata":{"execution":{"iopub.status.busy":"2024-04-22T20:56:59.495435Z","iopub.execute_input":"2024-04-22T20:56:59.495786Z","iopub.status.idle":"2024-04-22T20:57:10.641351Z","shell.execute_reply.started":"2024-04-22T20:56:59.495759Z","shell.execute_reply":"2024-04-22T20:57:10.640464Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"Downloading data: 100%|██████████| 605k/605k [00:00<00:00, 2.10MB/s]\nDownloading data: 100%|██████████| 291k/291k [00:00<00:00, 1.29MB/s]\nDownloading data: 100%|██████████| 81.3k/81.3k [00:00<00:00, 370kB/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/6838 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"662b39d933434a938513dcba9dad5a52"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/3259 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a54121bd28eb481498ff8bdd095e8d46"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/886 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9f3f50955e3406dbe8e222d1023b64c"}},"metadata":{}}]},{"cell_type":"code","source":"dataset","metadata":{"execution":{"iopub.status.busy":"2024-04-22T20:58:54.227066Z","iopub.execute_input":"2024-04-22T20:58:54.228003Z","iopub.status.idle":"2024-04-22T20:58:54.234757Z","shell.execute_reply.started":"2024-04-22T20:58:54.227966Z","shell.execute_reply":"2024-04-22T20:58:54.233837Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['ID', 'Tweet', 'anger', 'anticipation', 'disgust', 'fear', 'joy', 'love', 'optimism', 'pessimism', 'sadness', 'surprise', 'trust'],\n        num_rows: 6838\n    })\n    test: Dataset({\n        features: ['ID', 'Tweet', 'anger', 'anticipation', 'disgust', 'fear', 'joy', 'love', 'optimism', 'pessimism', 'sadness', 'surprise', 'trust'],\n        num_rows: 3259\n    })\n    validation: Dataset({\n        features: ['ID', 'Tweet', 'anger', 'anticipation', 'disgust', 'fear', 'joy', 'love', 'optimism', 'pessimism', 'sadness', 'surprise', 'trust'],\n        num_rows: 886\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"example = dataset['train'][0]\nexample","metadata":{"execution":{"iopub.status.busy":"2024-04-22T20:59:00.959953Z","iopub.execute_input":"2024-04-22T20:59:00.960655Z","iopub.status.idle":"2024-04-22T20:59:00.969491Z","shell.execute_reply.started":"2024-04-22T20:59:00.960626Z","shell.execute_reply":"2024-04-22T20:59:00.968520Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"{'ID': '2017-En-21441',\n 'Tweet': \"“Worry is a down payment on a problem you may never have'. \\xa0Joyce Meyer.  #motivation #leadership #worry\",\n 'anger': False,\n 'anticipation': True,\n 'disgust': False,\n 'fear': False,\n 'joy': False,\n 'love': False,\n 'optimism': True,\n 'pessimism': False,\n 'sadness': False,\n 'surprise': False,\n 'trust': True}"},"metadata":{}}]},{"cell_type":"code","source":"labels = [label for label in dataset['train'].features.keys() if label not in ['ID', 'Tweet']]\nid2label = {idx:label for idx, label in enumerate(labels)}\nlabel2id = {label:idx for idx, label in enumerate(labels)}\nlabels","metadata":{"execution":{"iopub.status.busy":"2024-04-22T20:59:27.732289Z","iopub.execute_input":"2024-04-22T20:59:27.733044Z","iopub.status.idle":"2024-04-22T20:59:27.740935Z","shell.execute_reply.started":"2024-04-22T20:59:27.733013Z","shell.execute_reply":"2024-04-22T20:59:27.739924Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"['anger',\n 'anticipation',\n 'disgust',\n 'fear',\n 'joy',\n 'love',\n 'optimism',\n 'pessimism',\n 'sadness',\n 'surprise',\n 'trust']"},"metadata":{}}]},{"cell_type":"markdown","source":"## Preprocessing data\n\nAs models like BERT don't expect text as direct input, but rather input_ids, etc., we tokenize the text using the tokenizer. Here I'm using the AutoTokenizer API, which will automatically load the appropriate tokenizer based on the checkpoint on the hub.\n\nWhat's a bit tricky is that we also need to provide labels to the model. For multi-label text classification, this is a matrix of shape (batch_size, num_labels). Also important: this should be a tensor of floats rather than integers, otherwise PyTorch' BCEWithLogitsLoss (which the model will use) will complain","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer\nimport numpy as np\n\ntokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n\ndef preprocess_data(examples):\n  # take a batch of texts\n  text = examples[\"Tweet\"]\n  # encode them\n  encoding = tokenizer(text, padding=\"max_length\", truncation=True, max_length=128)\n  # add labels\n  labels_batch = {k: examples[k] for k in examples.keys() if k in labels}\n  # create numpy array of shape (batch_size, num_labels)\n  labels_matrix = np.zeros((len(text), len(labels)))\n  # fill numpy array\n  for idx, label in enumerate(labels):\n    labels_matrix[:, idx] = labels_batch[label]\n\n  encoding[\"labels\"] = labels_matrix.tolist()\n  \n  return encoding","metadata":{"execution":{"iopub.status.busy":"2024-04-22T21:03:30.046798Z","iopub.execute_input":"2024-04-22T21:03:30.047921Z","iopub.status.idle":"2024-04-22T21:03:38.215371Z","shell.execute_reply.started":"2024-04-22T21:03:30.047858Z","shell.execute_reply":"2024-04-22T21:03:38.214565Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"26546a63888348619b5934acf6a64a65"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"176d9abc32f14fce81cc6e0dd0199885"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12263ff26241472c993623ee6aab7ba6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b07154c0c90458f963aa58f5016e8b8"}},"metadata":{}}]},{"cell_type":"code","source":"encoded_dataset = dataset.map(preprocess_data, batched=True, remove_columns=dataset['train'].column_names)","metadata":{"execution":{"iopub.status.busy":"2024-04-22T21:03:48.899310Z","iopub.execute_input":"2024-04-22T21:03:48.900312Z","iopub.status.idle":"2024-04-22T21:03:50.625652Z","shell.execute_reply.started":"2024-04-22T21:03:48.900278Z","shell.execute_reply":"2024-04-22T21:03:50.624755Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/6838 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"edae221ed6034663a89b905b1403d1b8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3259 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c7a7c7c1cb2a408c80f998cf801fa65a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/886 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7083fff3cab64dd29566cceb7f6c77b6"}},"metadata":{}}]},{"cell_type":"code","source":"example = encoded_dataset['train'][0]\nprint(example.keys())","metadata":{"execution":{"iopub.status.busy":"2024-04-22T21:03:59.499656Z","iopub.execute_input":"2024-04-22T21:03:59.500028Z","iopub.status.idle":"2024-04-22T21:03:59.507579Z","shell.execute_reply.started":"2024-04-22T21:03:59.499999Z","shell.execute_reply":"2024-04-22T21:03:59.506666Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n","output_type":"stream"}]},{"cell_type":"code","source":"print(example)","metadata":{"execution":{"iopub.status.busy":"2024-04-22T21:04:07.072505Z","iopub.execute_input":"2024-04-22T21:04:07.073346Z","iopub.status.idle":"2024-04-22T21:04:07.077848Z","shell.execute_reply.started":"2024-04-22T21:04:07.073313Z","shell.execute_reply":"2024-04-22T21:04:07.077010Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"{'input_ids': [101, 1523, 4737, 2003, 1037, 2091, 7909, 2006, 1037, 3291, 2017, 2089, 2196, 2031, 1005, 1012, 11830, 11527, 1012, 1001, 14354, 1001, 4105, 1001, 4737, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0]}\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenizer.decode(example['input_ids'])","metadata":{"execution":{"iopub.status.busy":"2024-04-22T21:04:46.758613Z","iopub.execute_input":"2024-04-22T21:04:46.758991Z","iopub.status.idle":"2024-04-22T21:04:56.405038Z","shell.execute_reply.started":"2024-04-22T21:04:46.758960Z","shell.execute_reply":"2024-04-22T21:04:56.404157Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"2024-04-22 21:04:48.547934: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-22 21:04:48.548035: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-22 21:04:48.679545: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"\"[CLS] “ worry is a down payment on a problem you may never have '. joyce meyer. # motivation # leadership # worry [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\""},"metadata":{}}]},{"cell_type":"code","source":"[id2label[idx] for idx, label in enumerate(example['labels']) if label == 1.0]","metadata":{"execution":{"iopub.status.busy":"2024-04-22T21:05:07.375316Z","iopub.execute_input":"2024-04-22T21:05:07.376551Z","iopub.status.idle":"2024-04-22T21:05:07.382794Z","shell.execute_reply.started":"2024-04-22T21:05:07.376518Z","shell.execute_reply":"2024-04-22T21:05:07.381943Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"['anticipation', 'optimism', 'trust']"},"metadata":{}}]},{"cell_type":"markdown","source":"Finally, we set the format of our data to PyTorch tensors. This will turn the training, validation and test sets into standard PyTorch datasets.","metadata":{}},{"cell_type":"code","source":"encoded_dataset.set_format(\"torch\")","metadata":{"execution":{"iopub.status.busy":"2024-04-22T21:10:24.910335Z","iopub.execute_input":"2024-04-22T21:10:24.911229Z","iopub.status.idle":"2024-04-22T21:10:24.916644Z","shell.execute_reply.started":"2024-04-22T21:10:24.911196Z","shell.execute_reply":"2024-04-22T21:10:24.915746Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"## Define model","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification\n\nmodel = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", \n                                                           problem_type=\"multi_label_classification\", \n                                                           num_labels=len(labels),\n                                                           id2label=id2label,\n                                                           label2id=label2id)","metadata":{"execution":{"iopub.status.busy":"2024-04-22T21:21:56.565439Z","iopub.execute_input":"2024-04-22T21:21:56.565815Z","iopub.status.idle":"2024-04-22T21:22:08.840093Z","shell.execute_reply.started":"2024-04-22T21:21:56.565786Z","shell.execute_reply":"2024-04-22T21:22:08.839166Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"977db4f8fd77402a919d5e660d55ea66"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Train model","metadata":{}},{"cell_type":"code","source":"batch_size = 8\nmetric_name = \"f1\"","metadata":{"execution":{"iopub.status.busy":"2024-04-22T21:22:40.193334Z","iopub.execute_input":"2024-04-22T21:22:40.194042Z","iopub.status.idle":"2024-04-22T21:22:40.197928Z","shell.execute_reply.started":"2024-04-22T21:22:40.194007Z","shell.execute_reply":"2024-04-22T21:22:40.197110Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer\n\nargs = TrainingArguments(\n    \"bert-finetuned-sem_eval-english\",\n    evaluation_strategy = \"epoch\",\n    save_strategy = \"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    num_train_epochs=5,\n    weight_decay=0.01,\n    load_best_model_at_end=True,\n    metric_for_best_model=metric_name,\n    push_to_hub=False,\n    report_to=[\"tensorboard\"],\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-22T21:36:15.739127Z","iopub.execute_input":"2024-04-22T21:36:15.739508Z","iopub.status.idle":"2024-04-22T21:36:16.678257Z","shell.execute_reply.started":"2024-04-22T21:36:15.739477Z","shell.execute_reply":"2024-04-22T21:36:16.677223Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\nfrom transformers import EvalPrediction\nimport torch\n    \n# source: https://jesusleal.io/2021/04/21/Longformer-multilabel-classification/\ndef multi_label_metrics(predictions, labels, threshold=0.5):\n    # first, apply sigmoid on predictions which are of shape (batch_size, num_labels)\n    sigmoid = torch.nn.Sigmoid()\n    probs = sigmoid(torch.Tensor(predictions))\n    # next, use threshold to turn them into integer predictions\n    y_pred = np.zeros(probs.shape)\n    y_pred[np.where(probs >= threshold)] = 1\n    # finally, compute metrics\n    y_true = labels\n    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='micro')\n    roc_auc = roc_auc_score(y_true, y_pred, average = 'micro')\n    accuracy = accuracy_score(y_true, y_pred)\n    # return as dictionary\n    metrics = {'f1': f1_micro_average,\n               'roc_auc': roc_auc,\n               'accuracy': accuracy}\n    return metrics\n\ndef compute_metrics(p: EvalPrediction):\n    preds = p.predictions[0] if isinstance(p.predictions, \n            tuple) else p.predictions\n    result = multi_label_metrics(\n        predictions=preds, \n        labels=p.label_ids)\n    return result","metadata":{"execution":{"iopub.status.busy":"2024-04-22T21:47:01.899767Z","iopub.execute_input":"2024-04-22T21:47:01.900724Z","iopub.status.idle":"2024-04-22T21:47:01.912107Z","shell.execute_reply.started":"2024-04-22T21:47:01.900681Z","shell.execute_reply":"2024-04-22T21:47:01.911015Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"Let's verify a batch as well as a forward pass:","metadata":{}},{"cell_type":"code","source":"encoded_dataset['train'][0]['labels'].type()","metadata":{"execution":{"iopub.status.busy":"2024-04-22T21:47:18.656563Z","iopub.execute_input":"2024-04-22T21:47:18.656950Z","iopub.status.idle":"2024-04-22T21:47:18.671435Z","shell.execute_reply.started":"2024-04-22T21:47:18.656923Z","shell.execute_reply":"2024-04-22T21:47:18.670413Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"'torch.FloatTensor'"},"metadata":{}}]},{"cell_type":"code","source":"encoded_dataset['train']['input_ids'][0]","metadata":{"execution":{"iopub.status.busy":"2024-04-22T21:47:26.681186Z","iopub.execute_input":"2024-04-22T21:47:26.681859Z","iopub.status.idle":"2024-04-22T21:47:26.713981Z","shell.execute_reply.started":"2024-04-22T21:47:26.681828Z","shell.execute_reply":"2024-04-22T21:47:26.712992Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"tensor([  101,  1523,  4737,  2003,  1037,  2091,  7909,  2006,  1037,  3291,\n         2017,  2089,  2196,  2031,  1005,  1012, 11830, 11527,  1012,  1001,\n        14354,  1001,  4105,  1001,  4737,   102,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0])"},"metadata":{}}]},{"cell_type":"code","source":"#forward pass\noutputs = model(input_ids=encoded_dataset['train']['input_ids'][0].unsqueeze(0), labels=encoded_dataset['train'][0]['labels'].unsqueeze(0))\noutputs","metadata":{"execution":{"iopub.status.busy":"2024-04-22T21:47:56.677457Z","iopub.execute_input":"2024-04-22T21:47:56.677814Z","iopub.status.idle":"2024-04-22T21:47:57.020123Z","shell.execute_reply.started":"2024-04-22T21:47:56.677787Z","shell.execute_reply":"2024-04-22T21:47:57.019191Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n","output_type":"stream"},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"SequenceClassifierOutput(loss=tensor(0.6850, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), logits=tensor([[ 0.4580, -0.0066,  0.0079, -0.3149,  0.1511, -0.0814, -0.0104, -0.1161,\n          0.1086, -0.6406, -0.0390]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"},"metadata":{}}]},{"cell_type":"markdown","source":"## Start training","metadata":{}},{"cell_type":"code","source":"trainer = Trainer(\n    model,\n    args,\n    train_dataset=encoded_dataset[\"train\"],\n    eval_dataset=encoded_dataset[\"validation\"],\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-22T21:48:36.868234Z","iopub.execute_input":"2024-04-22T21:48:36.868606Z","iopub.status.idle":"2024-04-22T21:48:37.144869Z","shell.execute_reply.started":"2024-04-22T21:48:36.868578Z","shell.execute_reply":"2024-04-22T21:48:37.144079Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \ndataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-04-22T21:49:16.702581Z","iopub.execute_input":"2024-04-22T21:49:16.703207Z","iopub.status.idle":"2024-04-22T21:58:35.143587Z","shell.execute_reply.started":"2024-04-22T21:49:16.703174Z","shell.execute_reply":"2024-04-22T21:58:35.142557Z"},"trusted":true},"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='4275' max='4275' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [4275/4275 09:17, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>F1</th>\n      <th>Roc Auc</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.407900</td>\n      <td>0.318377</td>\n      <td>0.685109</td>\n      <td>0.781390</td>\n      <td>0.285553</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.283400</td>\n      <td>0.302301</td>\n      <td>0.693264</td>\n      <td>0.785782</td>\n      <td>0.270880</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.240100</td>\n      <td>0.311669</td>\n      <td>0.707263</td>\n      <td>0.802794</td>\n      <td>0.267494</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.211700</td>\n      <td>0.313934</td>\n      <td>0.701833</td>\n      <td>0.797534</td>\n      <td>0.259594</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.191700</td>\n      <td>0.313781</td>\n      <td>0.705738</td>\n      <td>0.800775</td>\n      <td>0.266366</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=4275, training_loss=0.2599719978912532, metrics={'train_runtime': 558.1215, 'train_samples_per_second': 61.259, 'train_steps_per_second': 7.66, 'total_flos': 2249123476753920.0, 'train_loss': 0.2599719978912532, 'epoch': 5.0})"},"metadata":{}}]},{"cell_type":"markdown","source":"## Evaluate model","metadata":{}},{"cell_type":"code","source":"trainer.evaluate()","metadata":{"execution":{"iopub.status.busy":"2024-04-22T22:00:03.314134Z","iopub.execute_input":"2024-04-22T22:00:03.315049Z","iopub.status.idle":"2024-04-22T22:00:07.434398Z","shell.execute_reply.started":"2024-04-22T22:00:03.315014Z","shell.execute_reply":"2024-04-22T22:00:07.433326Z"},"trusted":true},"execution_count":23,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='111' max='111' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [111/111 00:04]\n    </div>\n    "},"metadata":{}},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 0.31166890263557434,\n 'eval_f1': 0.7072633895818049,\n 'eval_roc_auc': 0.8027940932885571,\n 'eval_accuracy': 0.26749435665914223,\n 'eval_runtime': 4.1082,\n 'eval_samples_per_second': 215.665,\n 'eval_steps_per_second': 27.019,\n 'epoch': 5.0}"},"metadata":{}}]},{"cell_type":"markdown","source":"## Inference on test sentences","metadata":{}},{"cell_type":"code","source":"text = \"I'm happy I can finally train a model for multi-label classification\"\n\nencoding = tokenizer(text, return_tensors=\"pt\")\nprint(encoding)\nencoding = {k: v.to(trainer.model.device) for k,v in encoding.items()}\nprint(encoding) # so this is just sending everything to cuda:0 device\n\noutputs = trainer.model(**encoding)\nprint(outputs)","metadata":{"execution":{"iopub.status.busy":"2024-04-22T22:01:10.815699Z","iopub.execute_input":"2024-04-22T22:01:10.816636Z","iopub.status.idle":"2024-04-22T22:01:10.933975Z","shell.execute_reply.started":"2024-04-22T22:01:10.816602Z","shell.execute_reply":"2024-04-22T22:01:10.933032Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"{'input_ids': tensor([[ 101, 1045, 1005, 1049, 3407, 1045, 2064, 2633, 3345, 1037, 2944, 2005,\n         4800, 1011, 3830, 5579,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n{'input_ids': tensor([[ 101, 1045, 1005, 1049, 3407, 1045, 2064, 2633, 3345, 1037, 2944, 2005,\n         4800, 1011, 3830, 5579,  102]], device='cuda:0'), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}\nSequenceClassifierOutput(loss=None, logits=tensor([[-3.9367, -2.1257, -4.1532, -4.5787,  3.8944, -0.5418,  1.7528, -4.2243,\n         -3.5997, -2.7327, -1.8761]], device='cuda:0',\n       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"The logits that come out of the model are of shape (batch_size, num_labels). As we are only forwarding a single sentence through the model, the batch_size equals 1. The logits is a tensor that contains the (unnormalized) scores for every individual label.","metadata":{}},{"cell_type":"code","source":"logits = outputs.logits\nprint(logits)\nprint(logits.shape)","metadata":{"execution":{"iopub.status.busy":"2024-04-22T22:03:06.876866Z","iopub.execute_input":"2024-04-22T22:03:06.877398Z","iopub.status.idle":"2024-04-22T22:03:06.884718Z","shell.execute_reply.started":"2024-04-22T22:03:06.877359Z","shell.execute_reply":"2024-04-22T22:03:06.883724Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"tensor([[-3.9367, -2.1257, -4.1532, -4.5787,  3.8944, -0.5418,  1.7528, -4.2243,\n         -3.5997, -2.7327, -1.8761]], device='cuda:0',\n       grad_fn=<AddmmBackward0>)\ntorch.Size([1, 11])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"To turn them into actual predicted labels, we first apply a sigmoid function independently to every score, such that every score is turned into a number between 0 and 1, that can be interpreted as a \"probability\" for how certain the model is that a given class belongs to the input text.\n\nNext, we use a threshold (typically, 0.5) to turn every probability into either a 1 (which means, we predict the label for the given example) or a 0 (which means, we don't predict the label for the given example).","metadata":{}},{"cell_type":"code","source":"# apply sigmoid + threshold\nsigmoid = torch.nn.Sigmoid()\nprobs = sigmoid(logits.squeeze().cpu())\npredictions = np.zeros(probs.shape)\npredictions[np.where(probs >= 0.5)] = 1\n# turn predicted id's into actual label names\npredicted_labels = [id2label[idx] for idx, label in enumerate(predictions) if label == 1.0]\nprint(predicted_labels)","metadata":{"execution":{"iopub.status.busy":"2024-04-22T22:04:05.334807Z","iopub.execute_input":"2024-04-22T22:04:05.335347Z","iopub.status.idle":"2024-04-22T22:04:05.342903Z","shell.execute_reply.started":"2024-04-22T22:04:05.335311Z","shell.execute_reply":"2024-04-22T22:04:05.341924Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"['joy', 'optimism']\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}