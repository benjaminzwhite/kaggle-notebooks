{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Source\n\nWorking through the BERT part of:\n\nhttps://www.kaggle.com/code/datafan07/disaster-tweets-nlp-eda-bert-with-transformers/notebook\n        \n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import f1_score, accuracy_score\nimport torch\nfrom transformers import BertTokenizer, BertForSequenceClassification, AdamW, BertConfig, get_linear_schedule_with_warmup\nfrom torch.utils.data import TensorDataset, random_split, DataLoader, RandomSampler, SequentialSampler\n\nimport random\nseed_val = 42\nrandom.seed(seed_val)\nnp.random.seed(seed_val)\ntorch.manual_seed(seed_val)\ntorch.cuda.manual_seed_all(seed_val)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-21T21:50:51.425774Z","iopub.execute_input":"2024-02-21T21:50:51.426132Z","iopub.status.idle":"2024-02-21T21:51:00.269808Z","shell.execute_reply.started":"2024-02-21T21:50:51.426101Z","shell.execute_reply":"2024-02-21T21:51:00.269051Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/natural-language-processing-with-disaster-tweets/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/natural-language-processing-with-disaster-tweets/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-02-21T22:32:10.298130Z","iopub.execute_input":"2024-02-21T22:32:10.298826Z","iopub.status.idle":"2024-02-21T22:32:10.382852Z","shell.execute_reply.started":"2024-02-21T22:32:10.298792Z","shell.execute_reply":"2024-02-21T22:32:10.381801Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# GPU\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device, torch.cuda.device_count(),  torch.cuda.get_device_name(0))","metadata":{"execution":{"iopub.status.busy":"2024-02-21T22:32:25.013477Z","iopub.execute_input":"2024-02-21T22:32:25.014278Z","iopub.status.idle":"2024-02-21T22:32:25.019424Z","shell.execute_reply.started":"2024-02-21T22:32:25.014247Z","shell.execute_reply":"2024-02-21T22:32:25.018560Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"cuda 1 Tesla P100-PCIE-16GB\n","output_type":"stream"}]},{"cell_type":"code","source":"print(f'Number of training tweets: {train.shape[0]}\\n')\nprint(f'Number of training tweets: {test.shape[0]}\\n')\n\ndisplay(train.sample(10))","metadata":{"execution":{"iopub.status.busy":"2024-02-21T22:32:26.197348Z","iopub.execute_input":"2024-02-21T22:32:26.197689Z","iopub.status.idle":"2024-02-21T22:32:26.220940Z","shell.execute_reply.started":"2024-02-21T22:32:26.197664Z","shell.execute_reply":"2024-02-21T22:32:26.220059Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Number of training tweets: 7613\n\nNumber of training tweets: 3263\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"        id      keyword               location  \\\n2644  3796  destruction                    NaN   \n2227  3185       deluge                    NaN   \n5448  7769       police                     UK   \n132    191   aftershock                    NaN   \n6845  9810       trauma  Montgomery County, MD   \n5559  7934    rainstorm                    NaN   \n1765  2538    collision                    NaN   \n1817  2611      crashed                    NaN   \n6810  9756      tragedy        Los Angeles, CA   \n4398  6254    hijacking          Athens,Greece   \n\n                                                   text  target  \n2644  So you have a new weapon that can cause un-ima...       1  \n2227  The f$&amp;@ing things I do for #GISHWHES Just...       0  \n5448  DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...       1  \n132   Aftershock back to school kick off was great. ...       0  \n6845  in response to trauma Children of Addicts deve...       0  \n5559  @Calum5SOS you look like you got caught in a r...       0  \n1765  my favorite lady came to our volunteer meeting...       1  \n1817  @brianroemmele UX fail of EMV - people want to...       1  \n6810  Can't find my ariana grande shirt  this is a f...       0  \n4398  The Murderous Story Of AmericaÛªs First Hijac...       1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2644</th>\n      <td>3796</td>\n      <td>destruction</td>\n      <td>NaN</td>\n      <td>So you have a new weapon that can cause un-ima...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2227</th>\n      <td>3185</td>\n      <td>deluge</td>\n      <td>NaN</td>\n      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5448</th>\n      <td>7769</td>\n      <td>police</td>\n      <td>UK</td>\n      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>132</th>\n      <td>191</td>\n      <td>aftershock</td>\n      <td>NaN</td>\n      <td>Aftershock back to school kick off was great. ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6845</th>\n      <td>9810</td>\n      <td>trauma</td>\n      <td>Montgomery County, MD</td>\n      <td>in response to trauma Children of Addicts deve...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5559</th>\n      <td>7934</td>\n      <td>rainstorm</td>\n      <td>NaN</td>\n      <td>@Calum5SOS you look like you got caught in a r...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1765</th>\n      <td>2538</td>\n      <td>collision</td>\n      <td>NaN</td>\n      <td>my favorite lady came to our volunteer meeting...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1817</th>\n      <td>2611</td>\n      <td>crashed</td>\n      <td>NaN</td>\n      <td>@brianroemmele UX fail of EMV - people want to...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6810</th>\n      <td>9756</td>\n      <td>tragedy</td>\n      <td>Los Angeles, CA</td>\n      <td>Can't find my ariana grande shirt  this is a f...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4398</th>\n      <td>6254</td>\n      <td>hijacking</td>\n      <td>Athens,Greece</td>\n      <td>The Murderous Story Of AmericaÛªs First Hijac...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Setting target variables, creating combined data and saving index for dividing combined data later.\n\nlabels = train['target'].values\nidx = len(labels)\ncombined = pd.concat([train, test])\ncombined = combined.text.values","metadata":{"execution":{"iopub.status.busy":"2024-02-21T22:33:53.207890Z","iopub.execute_input":"2024-02-21T22:33:53.208262Z","iopub.status.idle":"2024-02-21T22:33:53.218944Z","shell.execute_reply.started":"2024-02-21T22:33:53.208234Z","shell.execute_reply":"2024-02-21T22:33:53.218092Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Tokenizing the combined text data using bert tokenizer.\n\ntokenizer = BertTokenizer.from_pretrained('bert-large-uncased', do_lower_case=True)","metadata":{"execution":{"iopub.status.busy":"2024-02-21T22:35:19.130479Z","iopub.execute_input":"2024-02-21T22:35:19.131378Z","iopub.status.idle":"2024-02-21T22:35:20.623661Z","shell.execute_reply.started":"2024-02-21T22:35:19.131342Z","shell.execute_reply":"2024-02-21T22:35:20.622751Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a35d4d66d28487faac9b584fa8b8da7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"38b5cf88d50f47988ebb29ef1dc687e2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa016f9b4c0f4ee6a83d08b4b4aa3506"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a071817e0734981bc9b18850f007af3"}},"metadata":{}}]},{"cell_type":"code","source":"def tokenize_map(sentence,labs=None):\n    \n    \"\"\"A function for tokenize all of the sentences and map the tokens to their word IDs.\"\"\"\n    \n    global labels\n    \n    input_ids = []\n    attention_masks = []\n\n    # For every sentence...\n    \n    for text in sentence:\n        #   \"encode_plus\" will:\n        \n        #   (1) Tokenize the sentence.\n        #   (2) Prepend the `[CLS]` token to the start.\n        #   (3) Append the `[SEP]` token to the end.\n        #   (4) Map tokens to their IDs.\n        #   (5) Pad or truncate the sentence to `max_length`\n        #   (6) Create attention masks for [PAD] tokens.\n        \n        encoded_dict = tokenizer.encode_plus(\n                            text,                      # Sentence to encode.\n                            add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n                            truncation='longest_first', # Activate and control truncation\n                            max_length = 84,           # Max length according to our text data.\n                            pad_to_max_length = True, # Pad & truncate all sentences.\n                            return_attention_mask = True,   # Construct attn. masks.\n                            return_tensors = 'pt',     # Return pytorch tensors.\n                       )\n\n        # Add the encoded sentence to the id list. \n        \n        input_ids.append(encoded_dict['input_ids'])\n\n        # And its attention mask (simply differentiates padding from non-padding).\n        \n        attention_masks.append(encoded_dict['attention_mask'])\n\n    # Convert the lists into tensors.\n    \n    input_ids = torch.cat(input_ids, dim=0)\n    attention_masks = torch.cat(attention_masks, dim=0)\n    \n    if labs is not None: # Setting this for using this definition for both train and test data so labels won't be a problem in our outputs.\n        labels = torch.tensor(labels)\n        return input_ids, attention_masks, labels\n    else:\n        return input_ids, attention_masks","metadata":{"execution":{"iopub.status.busy":"2024-02-21T22:43:55.688503Z","iopub.execute_input":"2024-02-21T22:43:55.688873Z","iopub.status.idle":"2024-02-21T22:43:55.697363Z","shell.execute_reply.started":"2024-02-21T22:43:55.688843Z","shell.execute_reply":"2024-02-21T22:43:55.696390Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"train= combined[:idx]\ntest = combined[idx:]\ntrain.shape","metadata":{"execution":{"iopub.status.busy":"2024-02-21T22:45:37.470947Z","iopub.execute_input":"2024-02-21T22:45:37.471323Z","iopub.status.idle":"2024-02-21T22:45:37.477506Z","shell.execute_reply.started":"2024-02-21T22:45:37.471292Z","shell.execute_reply":"2024-02-21T22:45:37.476544Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"(7613,)"},"metadata":{}}]},{"cell_type":"code","source":"# Tokenizing all of the train test sentences and mapping the tokens to their word IDs.\n\ninput_ids, attention_masks, labels = tokenize_map(train, labels)\ntest_input_ids, test_attention_masks= tokenize_map(test)","metadata":{"execution":{"iopub.status.busy":"2024-02-21T22:45:39.466789Z","iopub.execute_input":"2024-02-21T22:45:39.467173Z","iopub.status.idle":"2024-02-21T22:45:49.855310Z","shell.execute_reply.started":"2024-02-21T22:45:39.467140Z","shell.execute_reply":"2024-02-21T22:45:49.854492Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2619: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  warnings.warn(\n/tmp/ipykernel_34/2744878672.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  labels = torch.tensor(labels)\n","output_type":"stream"}]},{"cell_type":"code","source":"print(input_ids.shape, attention_masks.shape, labels.shape)","metadata":{"execution":{"iopub.status.busy":"2024-02-21T22:45:54.689831Z","iopub.execute_input":"2024-02-21T22:45:54.690661Z","iopub.status.idle":"2024-02-21T22:45:54.695188Z","shell.execute_reply.started":"2024-02-21T22:45:54.690630Z","shell.execute_reply":"2024-02-21T22:45:54.694221Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"torch.Size([7613, 84]) torch.Size([7613, 84]) torch.Size([7613])\n","output_type":"stream"}]},{"cell_type":"code","source":"# Combine the training inputs into a TensorDataset.\n\ndataset = TensorDataset(input_ids, attention_masks, labels)\n\n# Create a 80-20 train-validation split.\n\n# Calculate the number of samples to include in each set.\n\ntrain_size = int(0.8 * len(dataset))\nval_size = len(dataset) - train_size\n\n# Divide the dataset by randomly selecting samples.\n\ntrain_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n\nprint('{:>5,} training samples'.format(train_size))\nprint('{:>5,} validation samples'.format(val_size))","metadata":{"execution":{"iopub.status.busy":"2024-02-21T22:45:57.325781Z","iopub.execute_input":"2024-02-21T22:45:57.326146Z","iopub.status.idle":"2024-02-21T22:45:57.338445Z","shell.execute_reply.started":"2024-02-21T22:45:57.326118Z","shell.execute_reply":"2024-02-21T22:45:57.337355Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"6,090 training samples\n1,523 validation samples\n","output_type":"stream"}]},{"cell_type":"code","source":"# The DataLoader needs to know our batch size for training, so we specify it here. For fine-tuning BERT on a specific task, the authors recommend a batch size of 16 or 32.\n\nbatch_size = 32\n\n# Create the DataLoaders for our training and validation sets.\n# We'll take training samples in random order. \n\ntrain_dataloader = DataLoader(\n            train_dataset,  # The training samples.\n            sampler = RandomSampler(train_dataset), # Select batches randomly\n            batch_size = batch_size # Trains with this batch size.\n        )\n\n# For validation the order doesn't matter, so we'll just read them sequentially.\n\nvalidation_dataloader = DataLoader(\n            val_dataset, # The validation samples.\n            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n            batch_size = batch_size # Evaluate with this batch size.\n        )","metadata":{"execution":{"iopub.status.busy":"2024-02-21T22:46:52.100127Z","iopub.execute_input":"2024-02-21T22:46:52.100899Z","iopub.status.idle":"2024-02-21T22:46:52.106454Z","shell.execute_reply.started":"2024-02-21T22:46:52.100867Z","shell.execute_reply":"2024-02-21T22:46:52.105591Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"prediction_data = TensorDataset(test_input_ids, test_attention_masks)\nprediction_sampler = SequentialSampler(prediction_data)\nprediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-02-21T22:47:19.329655Z","iopub.execute_input":"2024-02-21T22:47:19.330235Z","iopub.status.idle":"2024-02-21T22:47:19.334945Z","shell.execute_reply.started":"2024-02-21T22:47:19.330201Z","shell.execute_reply":"2024-02-21T22:47:19.333984Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# Load BertForSequenceClassification, the pretrained BERT model with a single linear classification layer on top. \n\nmodel = BertForSequenceClassification.from_pretrained(\n    'bert-large-uncased', # Use the 124-layer, 1024-hidden, 16-heads, 340M parameters BERT model with an uncased vocab.\n    num_labels = 2, # The number of output labels--2 for binary classification. You can increase this for multi-class tasks.   \n    output_attentions = False, # Whether the model returns attentions weights.\n    output_hidden_states = False, # Whether the model returns all hidden-states.\n)\n\n# !!!\n# Tell pytorch to run this model on the device which we set GPU in our case.\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-02-21T22:52:47.002702Z","iopub.execute_input":"2024-02-21T22:52:47.003555Z","iopub.status.idle":"2024-02-21T22:52:53.222332Z","shell.execute_reply.started":"2024-02-21T22:52:47.003518Z","shell.execute_reply":"2024-02-21T22:52:53.221438Z"},"trusted":true},"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3357d4452e4642e381b427add457d263"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"BertForSequenceClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n      (position_embeddings): Embedding(512, 1024)\n      (token_type_embeddings): Embedding(2, 1024)\n      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-23): 24 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=1024, out_features=2, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"# Get all of the model's parameters as a list of tuples:\n\nparams = list(model.named_parameters())\n\nprint('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n\nprint('==== Embedding Layer ====\\n')\n\nfor p in params[0:5]:\n    print('{:<55} {:>12}'.format(p[0], str(tuple(p[1].size()))))\n\nprint('\\n==== First Transformer ====\\n')\n\nfor p in params[5:21]:\n    print('{:<55} {:>12}'.format(p[0], str(tuple(p[1].size()))))\n\nprint('\\n==== Output Layer ====\\n')\n\nfor p in params[-4:]:\n    print('{:<55} {:>12}'.format(p[0], str(tuple(p[1].size()))))","metadata":{"execution":{"iopub.status.busy":"2024-02-21T23:07:24.852916Z","iopub.execute_input":"2024-02-21T23:07:24.853314Z","iopub.status.idle":"2024-02-21T23:07:24.863620Z","shell.execute_reply.started":"2024-02-21T23:07:24.853283Z","shell.execute_reply":"2024-02-21T23:07:24.862668Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"The BERT model has 393 different named parameters.\n\n==== Embedding Layer ====\n\nbert.embeddings.word_embeddings.weight                  (30522, 1024)\nbert.embeddings.position_embeddings.weight               (512, 1024)\nbert.embeddings.token_type_embeddings.weight               (2, 1024)\nbert.embeddings.LayerNorm.weight                             (1024,)\nbert.embeddings.LayerNorm.bias                               (1024,)\n\n==== First Transformer ====\n\nbert.encoder.layer.0.attention.self.query.weight        (1024, 1024)\nbert.encoder.layer.0.attention.self.query.bias               (1024,)\nbert.encoder.layer.0.attention.self.key.weight          (1024, 1024)\nbert.encoder.layer.0.attention.self.key.bias                 (1024,)\nbert.encoder.layer.0.attention.self.value.weight        (1024, 1024)\nbert.encoder.layer.0.attention.self.value.bias               (1024,)\nbert.encoder.layer.0.attention.output.dense.weight      (1024, 1024)\nbert.encoder.layer.0.attention.output.dense.bias             (1024,)\nbert.encoder.layer.0.attention.output.LayerNorm.weight       (1024,)\nbert.encoder.layer.0.attention.output.LayerNorm.bias         (1024,)\nbert.encoder.layer.0.intermediate.dense.weight          (4096, 1024)\nbert.encoder.layer.0.intermediate.dense.bias                 (4096,)\nbert.encoder.layer.0.output.dense.weight                (1024, 4096)\nbert.encoder.layer.0.output.dense.bias                       (1024,)\nbert.encoder.layer.0.output.LayerNorm.weight                 (1024,)\nbert.encoder.layer.0.output.LayerNorm.bias                   (1024,)\n\n==== Output Layer ====\n\nbert.pooler.dense.weight                                (1024, 1024)\nbert.pooler.dense.bias                                       (1024,)\nclassifier.weight                                          (2, 1024)\nclassifier.bias                                                 (2,)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Note: AdamW is a class from the huggingface library (as opposed to pytorch).\n\"\"\"\noptimizer = AdamW(model.parameters(),\n                  lr = 6e-6, # args.learning_rate\n                  eps = 1e-8 # args.adam_epsilon\n                )\n\n\"\"\"\n\n# SEE WARNING BELOW","metadata":{"execution":{"iopub.status.busy":"2024-02-21T23:08:53.894618Z","iopub.execute_input":"2024-02-21T23:08:53.895288Z","iopub.status.idle":"2024-02-21T23:08:53.910138Z","shell.execute_reply.started":"2024-02-21T23:08:53.895250Z","shell.execute_reply":"2024-02-21T23:08:53.909079Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"optimizer = torch.optim.AdamW(model.parameters(),\n                             lr = 6e-6,\n                             eps = 1e-8)","metadata":{"execution":{"iopub.status.busy":"2024-02-21T23:09:46.199927Z","iopub.execute_input":"2024-02-21T23:09:46.200783Z","iopub.status.idle":"2024-02-21T23:09:46.207727Z","shell.execute_reply.started":"2024-02-21T23:09:46.200753Z","shell.execute_reply":"2024-02-21T23:09:46.206787Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# Number of training epochs. The BERT authors recommend between 2 and 4. \n# We chose to run for 3, but we'll see later that this may be over-fitting the training data.\nepochs = 3\n\n# Total number of training steps is [number of batches] x [number of epochs] (Note that this is not the same as the number of training samples).\ntotal_steps = len(train_dataloader) * epochs\n\n# Create the learning rate scheduler.\nscheduler = get_linear_schedule_with_warmup(optimizer, \n                                            num_warmup_steps = 0, # Default value in run_glue.py\n                                            num_training_steps = total_steps)","metadata":{"execution":{"iopub.status.busy":"2024-02-21T23:10:49.810257Z","iopub.execute_input":"2024-02-21T23:10:49.811213Z","iopub.status.idle":"2024-02-21T23:10:49.815982Z","shell.execute_reply.started":"2024-02-21T23:10:49.811179Z","shell.execute_reply":"2024-02-21T23:10:49.815020Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"Training:\n\n* Unpack our data inputs and labels\n* Load data onto the GPU for acceleration,\n* Clear out the gradients calculated in the previous pass,\n* In pytorch the gradients accumulate by default (useful for things like RNNs) unless you explicitly clear them out,\n* Forward pass (feed input data through the network),\n* Backward pass (backpropagation),\n* Tell the network to update parameters with optimizer.step(),\n* Track variables for monitoring progress.\n\nEvalution:\n\n* Unpack our data inputs and labels,\n* Load data onto the GPU for acceleration,\n* Forward pass (feed input data through the network),\n* Compute loss on our validation data and track variables for monitoring progress.","metadata":{}},{"cell_type":"code","source":"# -- helper functions --\n\ndef flat_accuracy(preds, labels):\n    \n    \"\"\"A function for calculating accuracy scores\"\"\"\n    \n    pred_flat = np.argmax(preds, axis=1).flatten()\n    labels_flat = labels.flatten()\n    \n    return accuracy_score(labels_flat, pred_flat)\n\ndef flat_f1(preds, labels):\n    \n    \"\"\"A function for calculating f1 scores\"\"\"\n    \n    pred_flat = np.argmax(preds, axis=1).flatten()\n    labels_flat = labels.flatten()\n    \n    return f1_score(labels_flat, pred_flat)\n\ndef format_time(elapsed):    \n    \n    \"\"\"A function that takes a time in seconds and returns a string hh:mm:ss\"\"\"\n    \n    # Round to the nearest second.\n    elapsed_rounded = int(round((elapsed)))\n    \n    # Format as hh:mm:ss\n    return str(datetime.timedelta(seconds=elapsed_rounded))\n\nimport time\n","metadata":{"execution":{"iopub.status.busy":"2024-02-21T23:15:36.338351Z","iopub.execute_input":"2024-02-21T23:15:36.338957Z","iopub.status.idle":"2024-02-21T23:15:36.346309Z","shell.execute_reply.started":"2024-02-21T23:15:36.338926Z","shell.execute_reply":"2024-02-21T23:15:36.345218Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"import warnings\nimport time\nimport datetime","metadata":{"execution":{"iopub.status.busy":"2024-02-21T23:20:39.282679Z","iopub.execute_input":"2024-02-21T23:20:39.283079Z","iopub.status.idle":"2024-02-21T23:20:39.287297Z","shell.execute_reply.started":"2024-02-21T23:20:39.283047Z","shell.execute_reply":"2024-02-21T23:20:39.286412Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"# This training code is based on the `run_glue.py` script here:\n\n# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n\n\n# We'll store a number of quantities such as training and validation loss, validation accuracy, f1 score and timings.\n\ntraining_stats = []\n\n# Measure the total training time for the whole run.\n\ntotal_t0 = time.time()\n\n# For each epoch...\nfor epoch_i in range(0, epochs):\n    \n    # ========================================\n    #               Training\n    # ========================================\n    \n    # Perform one full pass over the training set.\n\n    print('')\n    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n    print('Training...')\n\n    # Measure how long the training epoch takes:\n    \n    t0 = time.time()\n\n    # Reset the total loss for this epoch.\n    \n    total_train_loss = 0\n\n    # Put the model into training mode. Don't be mislead--the call to `train` just changes the *mode*, it doesn't *perform* the training.\n    \n    # `dropout` and `batchnorm` layers behave differently during training vs. test ,\n    # source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch\n    \n    model.train()\n\n    # For each batch of training data...\n    \n    for step, batch in enumerate(train_dataloader):\n\n        # Progress update every 50 batches.\n        if step % 50 == 0 and not step == 0:\n            # Calculate elapsed time in minutes.\n            elapsed = format_time(time.time() - t0)\n            \n            # Report progress.\n            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n\n        # Unpack this training batch from our dataloader. \n        #\n        # As we unpack the batch, we'll also copy each tensor to the device(gpu in our case) using the `to` method.\n        #\n        # `batch` contains three pytorch tensors:\n        #   [0]: input ids \n        #   [1]: attention masks\n        #   [2]: labels \n        \n        b_input_ids = batch[0].to(device).to(torch.int64)\n        b_input_mask = batch[1].to(device).to(torch.int64)\n        b_labels = batch[2].to(device).to(torch.int64)\n\n        # Always clear any previously calculated gradients before performing a backward pass. PyTorch doesn't do this automatically because accumulating the gradients is 'convenient while training RNNs'. \n        # Source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch\n        \n        model.zero_grad()        \n\n        # Perform a forward pass (evaluate the model on this training batch).\n        # The documentation for this `model` function is down here: \n        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers BertForSequenceClassification.\n        \n        # It returns different numbers of parameters depending on what arguments given and what flags are set. For our useage here, it returns the loss (because we provided labels),\n        # And the 'logits' (the model outputs prior to activation.)\n        \n        loss_log = model(b_input_ids, \n                             token_type_ids=None, \n                             attention_mask=b_input_mask, \n                             labels=b_labels)\n        \n        loss = loss_log.loss\n        logits = loss_log.logits\n        # Accumulate the training loss over all of the batches so that we can calculate the average loss at the end, \n        # `loss` is a tensor containing a single value; the `.item()` function just returns the Python value from the tensor.\n        \n        \n        total_train_loss += loss.item()\n\n        # Perform a backward pass to calculate the gradients.\n        \n        loss.backward()\n\n        # Clip the norm of the gradients to 1.0 This is to help prevent the 'exploding gradients' problem.\n        \n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n\n        # Update parameters and take a step using the computed gradient.\n        \n        # The optimizer dictates the 'update rule'(How the parameters are modified based on their gradients, the learning rate, etc.)\n        \n        optimizer.step()\n\n        # Update the learning rate.\n        \n        scheduler.step()\n\n    # Calculate the average loss over all of the batches.\n    \n    avg_train_loss = total_train_loss / len(train_dataloader)            \n    \n    # Measure how long this epoch took.\n    \n    training_time = format_time(time.time() - t0)\n\n    print('')\n    print('  Average training loss: {0:.2f}'.format(avg_train_loss))\n    print('  Training epcoh took: {:}'.format(training_time))\n        \n    # ========================================\n    #               Validation\n    # ========================================\n    # After the completion of each training epoch, measure our performance on our validation set.\n\n    print('')\n    print('Running Validation...')\n\n    t0 = time.time()\n\n    # Put the model in evaluation mode--the dropout layers behave differently during evaluation.\n    \n    model.eval()\n\n    # Tracking variables:\n    \n    total_eval_accuracy = 0\n    total_eval_loss = 0\n    total_eval_f1 = 0\n    nb_eval_steps = 0\n\n    # Evaluate data for one epoch.\n    \n    for batch in validation_dataloader:\n        \n        # Unpack this training batch from our dataloader. \n        \n        # As we unpack the batch, we'll also copy each tensor to the GPU using the `to` method.\n        \n        # `batch` contains three pytorch tensors:\n        #   [0]: input ids \n        #   [1]: attention masks\n        #   [2]: labels \n        b_input_ids = batch[0].to(device)\n        b_input_mask = batch[1].to(device)\n        b_labels = batch[2].to(device)\n        \n        # Tell pytorch not to bother with constructing the compute graph during the forward pass, since this is only needed for backprop (training part).\n        \n        with torch.no_grad():        \n\n            # Forward pass, calculate logit predictions.\n            # token_type_ids is the same as the 'segment ids', which differentiates sentence 1 and 2 in 2-sentence tasks.\n            # The documentation for this `model` function is down here: \n            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers BertForSequenceClassification.\n            # Get the 'logits' output by the model. The 'logits' are the output values prior to applying an activation function like the softmax.\n            \n            loss_log = model(b_input_ids, \n                                   token_type_ids=None, \n                                   attention_mask=b_input_mask,\n                                   labels=b_labels)\n        loss = loss_log.loss\n        logits = loss_log.logits\n        # Accumulate the validation loss.\n        \n        total_eval_loss += loss.item()\n\n        # Move logits and labels to CPU:\n        \n        logits = logits.detach().cpu().numpy()\n        label_ids = b_labels.to('cpu').numpy()\n\n        # Calculate the accuracy for this batch of test sentences, and accumulate it over all batches:\n        \n        total_eval_accuracy += flat_accuracy(logits, label_ids)\n        total_eval_f1 += flat_f1(logits, label_ids)\n        \n\n    # Report the final accuracy for this validation run.\n    \n    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n    print('  Accuracy: {0:.2f}'.format(avg_val_accuracy))\n    \n    # Report the final f1 score for this validation run.\n    \n    avg_val_f1 = total_eval_f1 / len(validation_dataloader)\n    print('  F1: {0:.2f}'.format(avg_val_f1))\n\n    # Calculate the average loss over all of the batches.\n    \n    avg_val_loss = total_eval_loss / len(validation_dataloader)\n    \n    \n    \n    # Measure how long the validation run took:\n    \n    validation_time = format_time(time.time() - t0)\n    \n    print('  Validation Loss: {0:.2f}'.format(avg_val_loss))\n    print('  Validation took: {:}'.format(validation_time))\n\n    # Record all statistics from this epoch.\n    \n    training_stats.append(\n        {\n            'epoch': epoch_i + 1,\n            'Training Loss': avg_train_loss,\n            'Valid. Loss': avg_val_loss,\n            'Valid. Accur.': avg_val_accuracy,\n            'Val_F1' : avg_val_f1,\n            'Training Time': training_time,\n            'Validation Time': validation_time\n        }\n    )\n\nprint('')\nprint('Training complete!')\n\nprint('Total training took {:} (h:mm:ss)'.format(format_time(time.time()-total_t0)))","metadata":{"execution":{"iopub.status.busy":"2024-02-21T23:24:20.634380Z","iopub.execute_input":"2024-02-21T23:24:20.634752Z","iopub.status.idle":"2024-02-21T23:32:53.198286Z","shell.execute_reply.started":"2024-02-21T23:24:20.634720Z","shell.execute_reply":"2024-02-21T23:32:53.197278Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"\n======== Epoch 1 / 3 ========\nTraining...\n  Batch    50  of    191.    Elapsed: 0:00:41.\n  Batch   100  of    191.    Elapsed: 0:01:23.\n  Batch   150  of    191.    Elapsed: 0:02:04.\n\n  Average training loss: 0.35\n  Training epcoh took: 0:02:38\n\nRunning Validation...\n  Accuracy: 0.83\n  F1: 0.78\n  Validation Loss: 0.41\n  Validation took: 0:00:13\n\n======== Epoch 2 / 3 ========\nTraining...\n  Batch    50  of    191.    Elapsed: 0:00:41.\n  Batch   100  of    191.    Elapsed: 0:01:23.\n  Batch   150  of    191.    Elapsed: 0:02:04.\n\n  Average training loss: 0.32\n  Training epcoh took: 0:02:38\n\nRunning Validation...\n  Accuracy: 0.83\n  F1: 0.78\n  Validation Loss: 0.41\n  Validation took: 0:00:13\n\n======== Epoch 3 / 3 ========\nTraining...\n  Batch    50  of    191.    Elapsed: 0:00:41.\n  Batch   100  of    191.    Elapsed: 0:01:23.\n  Batch   150  of    191.    Elapsed: 0:02:04.\n\n  Average training loss: 0.31\n  Training epcoh took: 0:02:38\n\nRunning Validation...\n  Accuracy: 0.83\n  F1: 0.78\n  Validation Loss: 0.41\n  Validation took: 0:00:13\n\nTraining complete!\nTotal training took 0:08:33 (h:mm:ss)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Viewing training stats\n","metadata":{}},{"cell_type":"code","source":"# Create a DataFrame from our training statistics.\n\ndf_stats = pd.DataFrame(data=training_stats)\n\n# Use the 'epoch' as the row index.\n\ndf_stats = df_stats.set_index('epoch')\n\n# Display the table.\n\ndisplay(df_stats)","metadata":{"execution":{"iopub.status.busy":"2024-02-21T23:36:10.466886Z","iopub.execute_input":"2024-02-21T23:36:10.467265Z","iopub.status.idle":"2024-02-21T23:36:10.480579Z","shell.execute_reply.started":"2024-02-21T23:36:10.467238Z","shell.execute_reply":"2024-02-21T23:36:10.479658Z"},"trusted":true},"execution_count":42,"outputs":[{"output_type":"display_data","data":{"text/plain":"       Training Loss  Valid. Loss  Valid. Accur.    Val_F1 Training Time  \\\nepoch                                                                      \n1           0.347482     0.407566       0.827645  0.779521       0:02:38   \n2           0.318671     0.414223       0.828947  0.782620       0:02:38   \n3           0.312550     0.414223       0.828947  0.782620       0:02:38   \n\n      Validation Time  \nepoch                  \n1             0:00:13  \n2             0:00:13  \n3             0:00:13  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Training Loss</th>\n      <th>Valid. Loss</th>\n      <th>Valid. Accur.</th>\n      <th>Val_F1</th>\n      <th>Training Time</th>\n      <th>Validation Time</th>\n    </tr>\n    <tr>\n      <th>epoch</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>0.347482</td>\n      <td>0.407566</td>\n      <td>0.827645</td>\n      <td>0.779521</td>\n      <td>0:02:38</td>\n      <td>0:00:13</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.318671</td>\n      <td>0.414223</td>\n      <td>0.828947</td>\n      <td>0.782620</td>\n      <td>0:02:38</td>\n      <td>0:00:13</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.312550</td>\n      <td>0.414223</td>\n      <td>0.828947</td>\n      <td>0.782620</td>\n      <td>0:02:38</td>\n      <td>0:00:13</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Increase the plot size and font size:\n\nfig, axes = plt.subplots(figsize=(12,8))\n\n# Plot the learning curve:\n\nplt.plot(df_stats['Training Loss'], 'b-o', label='Training')\nplt.plot(df_stats['Valid. Loss'], 'g-o', label='Validation')\n\n# Label the plot:\n\nplt.title('Training & Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\n\nplt.legend()\nplt.xticks([1, 2, 3])\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-21T23:36:50.453742Z","iopub.execute_input":"2024-02-21T23:36:50.454746Z","iopub.status.idle":"2024-02-21T23:36:50.706398Z","shell.execute_reply.started":"2024-02-21T23:36:50.454700Z","shell.execute_reply":"2024-02-21T23:36:50.705535Z"},"trusted":true},"execution_count":43,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1200x800 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}