{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\n!pip install pip3-autoremove\n!pip-autoremove torch torchvision torchaudio -y\n!pip install torch torchvision torchaudio xformers --index-url https://download.pytorch.org/whl/cu121\n!pip install unsloth","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T22:26:40.754276Z","iopub.execute_input":"2024-11-30T22:26:40.755087Z","iopub.status.idle":"2024-11-30T22:30:00.866955Z","shell.execute_reply.started":"2024-11-30T22:26:40.755043Z","shell.execute_reply":"2024-11-30T22:30:00.865733Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"from unsloth import FastLanguageModel\n\nimport torch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T22:31:03.845192Z","iopub.execute_input":"2024-11-30T22:31:03.845535Z","iopub.status.idle":"2024-11-30T22:31:25.381464Z","shell.execute_reply.started":"2024-11-30T22:31:03.845502Z","shell.execute_reply":"2024-11-30T22:31:25.380479Z"}},"outputs":[{"name":"stdout","text":"ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\nðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\ndtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\nload_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n\nmodel, tokenizer = FastLanguageModel.from_pretrained(\n    model_name = \"unsloth/Llama-3.2-3B-Instruct\", # or choose \"unsloth/Llama-3.2-1B-Instruct\"\n    max_seq_length = max_seq_length,\n    dtype = dtype,\n    load_in_4bit = load_in_4bit,\n    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T22:31:49.111623Z","iopub.execute_input":"2024-11-30T22:31:49.112012Z","iopub.status.idle":"2024-11-30T22:32:09.087023Z","shell.execute_reply.started":"2024-11-30T22:31:49.111983Z","shell.execute_reply":"2024-11-30T22:32:09.086084Z"}},"outputs":[{"name":"stdout","text":"==((====))==  Unsloth 2024.11.11: Fast Llama patching. Transformers:4.46.3.\n   \\\\   /|    GPU: Tesla T4. Max memory: 14.741 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.5.1+cu121. CUDA: 7.5. CUDA Toolkit: 12.1. Triton: 3.1.0\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.28.post3. FA2 = False]\n \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.24G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"adf6305548a64a33aa2a33c1e6e57dd7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/184 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c2786cbb621a4e43a4864dfdbfb4fdad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/54.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca882c7de18d463fb2aeadab426738f4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"96b9bdb823724cbd8771e617943fad2a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/454 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0018b62a5efc4e88bbefeb8beb9f2598"}},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"RANDOM_SEED = 1359","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T22:45:18.365451Z","iopub.execute_input":"2024-11-30T22:45:18.366157Z","iopub.status.idle":"2024-11-30T22:45:18.369855Z","shell.execute_reply.started":"2024-11-30T22:45:18.366114Z","shell.execute_reply":"2024-11-30T22:45:18.368995Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"model = FastLanguageModel.get_peft_model(\n    model,\n    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n    lora_alpha = 16,\n    lora_dropout = 0, # Supports any, but = 0 is optimized\n    bias = \"none\",    # Supports any, but = \"none\" is optimized\n    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n    random_state = RANDOM_SEED,\n    use_rslora = False,  # We support rank stabilized LoRA\n    loftq_config = None, # And LoftQ\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T22:45:21.518547Z","iopub.execute_input":"2024-11-30T22:45:21.519250Z","iopub.status.idle":"2024-11-30T22:45:26.886375Z","shell.execute_reply.started":"2024-11-30T22:45:21.519218Z","shell.execute_reply":"2024-11-30T22:45:26.885708Z"}},"outputs":[{"name":"stderr","text":"Unsloth 2024.11.11 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"# Dataset preparation","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\n\ndataset = load_dataset(\"mlabonne/FineTome-100k\", split = \"train\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T22:37:24.815438Z","iopub.execute_input":"2024-11-30T22:37:24.815817Z","iopub.status.idle":"2024-11-30T22:37:27.841098Z","shell.execute_reply.started":"2024-11-30T22:37:24.815786Z","shell.execute_reply":"2024-11-30T22:37:27.840202Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/982 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa7a0e6b37a7445b86f35e8b9d146af0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/117M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"443a76f2a2644008bd8c4b21e35b582d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/100000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"477a7aff5d344296beb843a09efb41f8"}},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T22:37:31.074506Z","iopub.execute_input":"2024-11-30T22:37:31.074868Z","iopub.status.idle":"2024-11-30T22:37:31.081230Z","shell.execute_reply.started":"2024-11-30T22:37:31.074836Z","shell.execute_reply":"2024-11-30T22:37:31.080335Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['conversations', 'source', 'score'],\n    num_rows: 100000\n})"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"dataset[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T22:37:37.659365Z","iopub.execute_input":"2024-11-30T22:37:37.659734Z","iopub.status.idle":"2024-11-30T22:37:37.671479Z","shell.execute_reply.started":"2024-11-30T22:37:37.659702Z","shell.execute_reply":"2024-11-30T22:37:37.670616Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"{'conversations': [{'from': 'human',\n   'value': 'Explain what boolean operators are, what they do, and provide examples of how they can be used in programming. Additionally, describe the concept of operator precedence and provide examples of how it affects the evaluation of boolean expressions. Discuss the difference between short-circuit evaluation and normal evaluation in boolean expressions and demonstrate their usage in code. \\n\\nFurthermore, add the requirement that the code must be written in a language that does not support short-circuit evaluation natively, forcing the test taker to implement their own logic for short-circuit evaluation.\\n\\nFinally, delve into the concept of truthiness and falsiness in programming languages, explaining how it affects the evaluation of boolean expressions. Add the constraint that the test taker must write code that handles cases where truthiness and falsiness are implemented differently across different programming languages.'},\n  {'from': 'gpt',\n   'value': 'Boolean operators are logical operators used in programming to manipulate boolean values. They operate on one or more boolean operands and return a boolean result. The three main boolean operators are \"AND\" (&&), \"OR\" (||), and \"NOT\" (!).\\n\\nThe \"AND\" operator returns true if both of its operands are true, and false otherwise. For example:\\n\\n```python\\nx = 5\\ny = 10\\nresult = (x > 0) and (y < 20)  # This expression evaluates to True\\n```\\n\\nThe \"OR\" operator returns true if at least one of its operands is true, and false otherwise. For example:\\n\\n```python\\nx = 5\\ny = 10\\nresult = (x > 0) or (y < 20)  # This expression evaluates to True\\n```\\n\\nThe \"NOT\" operator negates the boolean value of its operand. It returns true if the operand is false, and false if the operand is true. For example:\\n\\n```python\\nx = 5\\nresult = not (x > 10)  # This expression evaluates to True\\n```\\n\\nOperator precedence refers to the order in which operators are evaluated in an expression. It ensures that expressions are evaluated correctly. In most programming languages, logical AND has higher precedence than logical OR. For example:\\n\\n```python\\nresult = True or False and False  # This expression is evaluated as (True or (False and False)), which is True\\n```\\n\\nShort-circuit evaluation is a behavior where the second operand of a logical operator is not evaluated if the result can be determined based on the value of the first operand. In short-circuit evaluation, if the first operand of an \"AND\" operator is false, the second operand is not evaluated because the result will always be false. Similarly, if the first operand of an \"OR\" operator is true, the second operand is not evaluated because the result will always be true.\\n\\nIn programming languages that support short-circuit evaluation natively, you can use it to improve performance or avoid errors. For example:\\n\\n```python\\nif x != 0 and (y / x) > 10:\\n    # Perform some operation\\n```\\n\\nIn languages without native short-circuit evaluation, you can implement your own logic to achieve the same behavior. Here\\'s an example in pseudocode:\\n\\n```\\nif x != 0 {\\n    if (y / x) > 10 {\\n        // Perform some operation\\n    }\\n}\\n```\\n\\nTruthiness and falsiness refer to how non-boolean values are evaluated in boolean contexts. In many programming languages, non-zero numbers and non-empty strings are considered truthy, while zero, empty strings, and null/None values are considered falsy.\\n\\nWhen evaluating boolean expressions, truthiness and falsiness come into play. For example:\\n\\n```python\\nx = 5\\nresult = x  # The value of x is truthy, so result is also truthy\\n```\\n\\nTo handle cases where truthiness and falsiness are implemented differently across programming languages, you can explicitly check the desired condition. For example:\\n\\n```python\\nx = 5\\nresult = bool(x)  # Explicitly converting x to a boolean value\\n```\\n\\nThis ensures that the result is always a boolean value, regardless of the language\\'s truthiness and falsiness rules.'}],\n 'source': 'infini-instruct-top-500k',\n 'score': 5.212620735168457}"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"from unsloth.chat_templates import get_chat_template\n\ntokenizer = get_chat_template(\n    tokenizer,\n    chat_template = \"llama-3.1\",\n)\n\ndef formatting_prompts_func(examples):\n    convos = examples[\"conversations\"]\n    texts = [tokenizer.apply_chat_template(convo, tokenize = False, add_generation_prompt = False) for convo in convos]\n    return { \"text\" : texts, }\npass","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T22:38:27.604986Z","iopub.execute_input":"2024-11-30T22:38:27.605323Z","iopub.status.idle":"2024-11-30T22:38:27.611774Z","shell.execute_reply.started":"2024-11-30T22:38:27.605294Z","shell.execute_reply":"2024-11-30T22:38:27.610737Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"from unsloth.chat_templates import standardize_sharegpt\n\ndataset = standardize_sharegpt(dataset) # converts dataset keys to standard ones for unlsoth : system/user/assistant + all have \"content\" as key for content\ndataset = dataset.map(formatting_prompts_func, batched = True,)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T22:41:55.725256Z","iopub.execute_input":"2024-11-30T22:41:55.725604Z","iopub.status.idle":"2024-11-30T22:42:06.115013Z","shell.execute_reply.started":"2024-11-30T22:41:55.725578Z","shell.execute_reply":"2024-11-30T22:42:06.114123Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Standardizing format:   0%|          | 0/100000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf743299cd8c46b391df827571a70db8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/100000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f46a011be6b47aa98eb122ac399bcf1"}},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"dataset[5][\"conversations\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T22:42:08.882312Z","iopub.execute_input":"2024-11-30T22:42:08.882623Z","iopub.status.idle":"2024-11-30T22:42:08.888873Z","shell.execute_reply.started":"2024-11-30T22:42:08.882597Z","shell.execute_reply":"2024-11-30T22:42:08.888007Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"[{'content': 'How do astronomers determine the original wavelength of light emitted by a celestial body at rest, which is necessary for measuring its speed using the Doppler effect?',\n  'role': 'user'},\n {'content': 'Astronomers make use of the unique spectral fingerprints of elements found in stars. These elements emit and absorb light at specific, known wavelengths, forming an absorption spectrum. By analyzing the light received from distant stars and comparing it to the laboratory-measured spectra of these elements, astronomers can identify the shifts in these wavelengths due to the Doppler effect. The observed shift tells them the extent to which the light has been redshifted or blueshifted, thereby allowing them to calculate the speed of the star along the line of sight relative to Earth.',\n  'role': 'assistant'}]"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"dataset[5] \n\n# Llama 3.1 Instruct's default chat template default adds \"Cutting Knowledge Date: December 2023\\nToday Date: 26 July 2024\", so do not be alarmed!","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T22:43:07.282532Z","iopub.execute_input":"2024-11-30T22:43:07.282919Z","iopub.status.idle":"2024-11-30T22:43:07.289224Z","shell.execute_reply.started":"2024-11-30T22:43:07.282889Z","shell.execute_reply":"2024-11-30T22:43:07.288380Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"{'conversations': [{'content': 'How do astronomers determine the original wavelength of light emitted by a celestial body at rest, which is necessary for measuring its speed using the Doppler effect?',\n   'role': 'user'},\n  {'content': 'Astronomers make use of the unique spectral fingerprints of elements found in stars. These elements emit and absorb light at specific, known wavelengths, forming an absorption spectrum. By analyzing the light received from distant stars and comparing it to the laboratory-measured spectra of these elements, astronomers can identify the shifts in these wavelengths due to the Doppler effect. The observed shift tells them the extent to which the light has been redshifted or blueshifted, thereby allowing them to calculate the speed of the star along the line of sight relative to Earth.',\n   'role': 'assistant'}],\n 'source': 'WebInstructSub_axolotl',\n 'score': 5.025244235992432,\n 'text': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 July 2024\\n\\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nHow do astronomers determine the original wavelength of light emitted by a celestial body at rest, which is necessary for measuring its speed using the Doppler effect?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nAstronomers make use of the unique spectral fingerprints of elements found in stars. These elements emit and absorb light at specific, known wavelengths, forming an absorption spectrum. By analyzing the light received from distant stars and comparing it to the laboratory-measured spectra of these elements, astronomers can identify the shifts in these wavelengths due to the Doppler effect. The observed shift tells them the extent to which the light has been redshifted or blueshifted, thereby allowing them to calculate the speed of the star along the line of sight relative to Earth.<|eot_id|>'}"},"metadata":{}}],"execution_count":11},{"cell_type":"markdown","source":"# Train\n\nset `num_train_epochs = 1` for full train instead of 60 steps","metadata":{}},{"cell_type":"code","source":"from trl import SFTTrainer\nfrom transformers import TrainingArguments, DataCollatorForSeq2Seq\nfrom unsloth import is_bfloat16_supported\n\ntrainer = SFTTrainer(\n    model = model,\n    tokenizer = tokenizer,\n    train_dataset = dataset,\n    dataset_text_field = \"text\",\n    max_seq_length = max_seq_length,\n    data_collator = DataCollatorForSeq2Seq(tokenizer = tokenizer), # TODO READ DOCS FOR THIS\n    dataset_num_proc = 2,\n    packing = False, # Can make training 5x faster for short sequences.\n    args = TrainingArguments(\n        per_device_train_batch_size = 2,\n        gradient_accumulation_steps = 4,\n        warmup_steps = 5,\n        # num_train_epochs = 1, # Set this for 1 full training run (and delete max_steps=60 if so)\n        max_steps = 60,\n        learning_rate = 2e-4,\n        fp16 = not is_bfloat16_supported(),\n        bf16 = is_bfloat16_supported(),\n        logging_steps = 1,\n        optim = \"adamw_8bit\",\n        weight_decay = 0.01,\n        lr_scheduler_type = \"linear\",\n        seed = RANDOM_SEED,\n        output_dir = \"outputs\",\n        report_to = \"none\", # Use this for WandB etc\n    ),\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T22:47:45.654400Z","iopub.execute_input":"2024-11-30T22:47:45.655382Z","iopub.status.idle":"2024-11-30T22:49:12.861201Z","shell.execute_reply.started":"2024-11-30T22:47:45.655342Z","shell.execute_reply":"2024-11-30T22:49:12.860392Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map (num_proc=2):   0%|          | 0/100000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e2e9ce6f937d4509a334a1e5a1ecb56c"}},"metadata":{}},{"name":"stderr","text":"max_steps is given, it will override any value given in num_train_epochs\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"We also use Unsloth's train_on_completions method to only train on the assistant outputs and ignore the loss on the user's inputs.","metadata":{}},{"cell_type":"code","source":"from unsloth.chat_templates import train_on_responses_only\n\ntrainer = train_on_responses_only(\n    trainer,\n    instruction_part = \"<|start_header_id|>user<|end_header_id|>\\n\\n\",\n    response_part = \"<|start_header_id|>assistant<|end_header_id|>\\n\\n\",\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T22:49:37.923118Z","iopub.execute_input":"2024-11-30T22:49:37.923496Z","iopub.status.idle":"2024-11-30T22:50:19.526202Z","shell.execute_reply.started":"2024-11-30T22:49:37.923463Z","shell.execute_reply":"2024-11-30T22:50:19.525237Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/100000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c5e6848c0364546ae6fc49e36773fcb"}},"metadata":{}}],"execution_count":18},{"cell_type":"markdown","source":"### Check that the train on response masking has actually worked","metadata":{}},{"cell_type":"code","source":"tokenizer.decode(trainer.train_dataset[5][\"input_ids\"])","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}