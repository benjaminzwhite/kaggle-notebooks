{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# HuggingFace NLP Course Chapter 3\n\n## Fine-tuning a model with the Trainer API\n\n[https://huggingface.co/learn/nlp-course/chapter3/3?fw=pt](https://huggingface.co/learn/nlp-course/chapter3/3?fw=pt)\n\nWorking through first part quickly since familiar - I want to get to the part where it introduces `Accelerate` library\n\n---\n\n## Quick notes from previous section - Processing The Data\n\n### dataset\n\nwe will use as an example the MRPC (Microsoft Research Paraphrase Corpus) dataset, introduced in a paper by William B. Dolan and Chris Brockett. The dataset consists of 5,801 pairs of sentences, with a label indicating if they are paraphrases or not (i.e., if both sentences mean the same thing). We‚Äôve selected it for this chapter because it‚Äôs a small dataset, so it‚Äôs easy to experiment with training on it.","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\n\nraw_datasets = load_dataset(\"glue\", \"mrpc\")","metadata":{"execution":{"iopub.status.busy":"2024-05-04T21:51:18.425819Z","iopub.execute_input":"2024-05-04T21:51:18.426151Z","iopub.status.idle":"2024-05-04T21:51:28.438569Z","shell.execute_reply.started":"2024-05-04T21:51:18.426124Z","shell.execute_reply":"2024-05-04T21:51:28.434203Z"},"trusted":true},"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/35.3k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f7eeb4dc29944aeeab02cb11c0b3a205"}},"metadata":{}},{"name":"stderr","text":"Downloading data: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 649k/649k [00:00<00:00, 2.48MB/s]\nDownloading data: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 75.7k/75.7k [00:00<00:00, 412kB/s]\nDownloading data: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 308k/308k [00:00<00:00, 1.60MB/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/3668 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc1a5ddb11714e668506f7057916ad95"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/408 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b52c3111d4e45cd834ac648e15f9c96"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/1725 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47418dc4472242008ba23771ed8ca7db"}},"metadata":{}}]},{"cell_type":"code","source":"raw_datasets","metadata":{"execution":{"iopub.status.busy":"2024-05-04T21:51:28.440688Z","iopub.execute_input":"2024-05-04T21:51:28.441588Z","iopub.status.idle":"2024-05-04T21:51:28.457622Z","shell.execute_reply.started":"2024-05-04T21:51:28.441551Z","shell.execute_reply":"2024-05-04T21:51:28.456514Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['sentence1', 'sentence2', 'label', 'idx'],\n        num_rows: 3668\n    })\n    validation: Dataset({\n        features: ['sentence1', 'sentence2', 'label', 'idx'],\n        num_rows: 408\n    })\n    test: Dataset({\n        features: ['sentence1', 'sentence2', 'label', 'idx'],\n        num_rows: 1725\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"raw_train_dataset = raw_datasets[\"train\"]\nraw_train_dataset[0]","metadata":{"execution":{"iopub.status.busy":"2024-05-04T21:51:28.459174Z","iopub.execute_input":"2024-05-04T21:51:28.459839Z","iopub.status.idle":"2024-05-04T21:51:28.475100Z","shell.execute_reply.started":"2024-05-04T21:51:28.459805Z","shell.execute_reply":"2024-05-04T21:51:28.474269Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"{'sentence1': 'Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence .',\n 'sentence2': 'Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .',\n 'label': 1,\n 'idx': 0}"},"metadata":{}}]},{"cell_type":"code","source":"raw_train_dataset.features","metadata":{"execution":{"iopub.status.busy":"2024-05-04T21:51:28.477591Z","iopub.execute_input":"2024-05-04T21:51:28.480433Z","iopub.status.idle":"2024-05-04T21:51:28.486741Z","shell.execute_reply.started":"2024-05-04T21:51:28.480390Z","shell.execute_reply":"2024-05-04T21:51:28.485915Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"{'sentence1': Value(dtype='string', id=None),\n 'sentence2': Value(dtype='string', id=None),\n 'label': ClassLabel(names=['not_equivalent', 'equivalent'], id=None),\n 'idx': Value(dtype='int32', id=None)}"},"metadata":{}}]},{"cell_type":"markdown","source":"## Using Trainer class\n\nPractice with HF stuff first before `Accelerate` DIY","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\nfrom transformers import AutoTokenizer, DataCollatorWithPadding\n\nraw_datasets = load_dataset(\"glue\", \"mrpc\")\ncheckpoint = \"bert-base-uncased\"\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)\n\n# DATSET CONSISTS OF PAIRS OF SENTENCES\n# NOTE IN CH03 \"Processing the data\" IT SHOWS THAT tokenizer(\"sentence 1\", \"sent 2\", ...)\n# CAN ACCEPT A LIST OF SENTENCES, SO BELOW CODE MAKES SENSE\ndef tokenize_function(example):\n    return tokenizer(example[\"sentence1\"], example[\"sentence2\"], truncation=True)\n\n\ntokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-05-04T21:51:28.488352Z","iopub.execute_input":"2024-05-04T21:51:28.488980Z","iopub.status.idle":"2024-05-04T21:51:51.644052Z","shell.execute_reply.started":"2024-05-04T21:51:28.488949Z","shell.execute_reply":"2024-05-04T21:51:51.643115Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"2024-05-04 21:51:36.555269: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-04 21:51:36.555369: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-04 21:51:36.694917: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"50e9936e73634e69856f22c1f25284ef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4917bfcedb47458f8ef02de776a10717"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d46030772cd8434a8ad4deb8f54c3c73"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6178cd4dbee041b49b84e3f207216809"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3668 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f123636fa0464f0691e10f1edd635fa1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/408 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ebdf9fdb5a549298255fc6b9b0652e9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1725 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2bd0e170586a4881a5ab0bd021ae6a11"}},"metadata":{}}]},{"cell_type":"code","source":"from transformers import TrainingArguments\n\ntraining_args = TrainingArguments(\"test-trainer\") # THE ONLY ARG THAT IS NEEDED IS NAME OF SAVE DIRECTORY","metadata":{"execution":{"iopub.status.busy":"2024-05-04T21:51:51.645147Z","iopub.execute_input":"2024-05-04T21:51:51.645428Z","iopub.status.idle":"2024-05-04T21:51:52.600986Z","shell.execute_reply.started":"2024-05-04T21:51:51.645404Z","shell.execute_reply":"2024-05-04T21:51:52.600192Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# 2 LABELS BECAUSE TASK IS \"is sentence2 a paraphrase of sentence1 -> yes / no classification\"\nfrom transformers import AutoModelForSequenceClassification\n\nmodel = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)","metadata":{"execution":{"iopub.status.busy":"2024-05-04T21:51:52.602148Z","iopub.execute_input":"2024-05-04T21:51:52.602473Z","iopub.status.idle":"2024-05-04T21:51:54.918595Z","shell.execute_reply.started":"2024-05-04T21:51:52.602447Z","shell.execute_reply":"2024-05-04T21:51:54.917602Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a206c3911934d7683dedb8655f32f46"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import Trainer\n\ntrainer = Trainer(\n    model,\n    training_args,\n    train_dataset=tokenized_datasets[\"train\"],\n    eval_dataset=tokenized_datasets[\"validation\"],\n    data_collator=data_collator,\n    tokenizer=tokenizer,\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-04T21:52:26.243143Z","iopub.execute_input":"2024-05-04T21:52:26.243900Z","iopub.status.idle":"2024-05-04T21:52:27.387340Z","shell.execute_reply.started":"2024-05-04T21:52:26.243867Z","shell.execute_reply":"2024-05-04T21:52:27.386548Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \ndataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Evaluation\n\n(in the course they train they above without eval dataset or compute_metrics, then they make you redo with these 2 things afer)\n\n**NOTE I HAVE NOT DONE THIS SO BELOW CODE IS WITH UNTRAINED MODEL!!!!!!!**\n\n---\n\nLet‚Äôs see how we can build a useful compute_metrics() function and use it the next time we train. The function must take an EvalPrediction object (which is a named tuple with a predictions field and a label_ids field) and will return a dictionary mapping strings to floats (the strings being the names of the metrics returned, and the floats their values). To get some predictions from our model, we can use the Trainer.predict() command:","metadata":{}},{"cell_type":"code","source":"predictions = trainer.predict(tokenized_datasets[\"validation\"])\nprint(predictions.predictions.shape, predictions.label_ids.shape)","metadata":{"execution":{"iopub.status.busy":"2024-05-04T21:57:42.903045Z","iopub.execute_input":"2024-05-04T21:57:42.904063Z","iopub.status.idle":"2024-05-04T21:57:44.868154Z","shell.execute_reply.started":"2024-05-04T21:57:42.904024Z","shell.execute_reply":"2024-05-04T21:57:44.867177Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"(408, 2) (408,)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"The output of the predict() method is another named tuple with three fields: predictions, label_ids, and metrics. The metrics field will just contain the loss on the dataset passed, as well as some time metrics (how long it took to predict, in total and on average). Once we complete our compute_metrics() function and pass it to the Trainer, that field will also contain the metrics returned by compute_metrics().\n\nAs you can see, predictions is a two-dimensional array with shape 408 x 2 (408 being the number of elements in the dataset we used). Those are the logits for each element of the dataset we passed to predict() (as you saw in the previous chapter, all Transformer models return logits). To transform them into predictions that we can compare to our labels, we need to take the index with the maximum value on the second axis:","metadata":{}},{"cell_type":"code","source":"predictions.predictions[:10] # REMEMBER MY MODEL IS UNTRAINED","metadata":{"execution":{"iopub.status.busy":"2024-05-04T21:59:06.719636Z","iopub.execute_input":"2024-05-04T21:59:06.720005Z","iopub.status.idle":"2024-05-04T21:59:06.726566Z","shell.execute_reply.started":"2024-05-04T21:59:06.719976Z","shell.execute_reply":"2024-05-04T21:59:06.725674Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"array([[-0.949354  , -0.05467544],\n       [-0.93355924, -0.04643866],\n       [-0.9492972 , -0.06445806],\n       [-0.94276524, -0.06690286],\n       [-0.9375537 , -0.05669558],\n       [-0.9518137 , -0.05445227],\n       [-0.94520247, -0.06065865],\n       [-0.9233213 , -0.05202857],\n       [-0.9564588 , -0.04163671],\n       [-0.9583559 , -0.04877253]], dtype=float32)"},"metadata":{}}]},{"cell_type":"code","source":"predictions.label_ids[:10] # LABEL IDS IS WHAT THEY CALL THE \"GOLD\" / \"REFERENCE\"","metadata":{"execution":{"iopub.status.busy":"2024-05-04T22:00:27.951748Z","iopub.execute_input":"2024-05-04T22:00:27.952149Z","iopub.status.idle":"2024-05-04T22:00:27.958886Z","shell.execute_reply.started":"2024-05-04T22:00:27.952119Z","shell.execute_reply":"2024-05-04T22:00:27.957750Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"array([1, 0, 0, 1, 0, 1, 0, 1, 1, 1])"},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\n\npreds = np.argmax(predictions.predictions, axis=-1)","metadata":{"execution":{"iopub.status.busy":"2024-05-04T21:59:33.430126Z","iopub.execute_input":"2024-05-04T21:59:33.430555Z","iopub.status.idle":"2024-05-04T21:59:33.436170Z","shell.execute_reply.started":"2024-05-04T21:59:33.430521Z","shell.execute_reply":"2024-05-04T21:59:33.434981Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"We can now compare those preds to the labels. To build our compute_metric() function, we will rely on the metrics from the ü§ó Evaluate library. We can load the metrics associated with the MRPC dataset as easily as we loaded the dataset, this time with the evaluate.load() function. The object returned has a compute() method we can use to do the metric calculation:","metadata":{}},{"cell_type":"code","source":"%pip install evaluate\n","metadata":{"execution":{"iopub.status.busy":"2024-05-04T22:01:26.661306Z","iopub.execute_input":"2024-05-04T22:01:26.661683Z","iopub.status.idle":"2024-05-04T22:01:40.114443Z","shell.execute_reply.started":"2024-05-04T22:01:26.661650Z","shell.execute_reply":"2024-05-04T22:01:40.113275Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting evaluate\n  Downloading evaluate-0.4.2-py3-none-any.whl.metadata (9.3 kB)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.18.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.1.4)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.2.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.22.2)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.13.1)\nRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (15.0.2)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (0.6)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.2.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.4)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\nDownloading evaluate-0.4.2-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.2\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import evaluate\n\nmetric = evaluate.load(\"glue\", \"mrpc\")\nmetric.compute(predictions=preds, references=predictions.label_ids)","metadata":{"execution":{"iopub.status.busy":"2024-05-04T22:01:41.652358Z","iopub.execute_input":"2024-05-04T22:01:41.653314Z","iopub.status.idle":"2024-05-04T22:01:42.413004Z","shell.execute_reply.started":"2024-05-04T22:01:41.653275Z","shell.execute_reply":"2024-05-04T22:01:42.412130Z"},"trusted":true},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/5.75k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36b4f7fe63c44299a44150aa77b3acef"}},"metadata":{}},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"{'accuracy': 0.6838235294117647, 'f1': 0.8122270742358079}"},"metadata":{}}]},{"cell_type":"markdown","source":"Wrapping everything together, we get our compute_metrics() function:","metadata":{}},{"cell_type":"code","source":"def compute_metrics(eval_preds):\n    metric = evaluate.load(\"glue\", \"mrpc\")\n    logits, labels = eval_preds # WHY SO BAD CHOICE OF NAMES - the labels here are label_ids from before, which is just the REFERENCE/GOLD LABELS TO BE 100% CLEAR\n    predictions = np.argmax(logits, axis=-1)\n    return metric.compute(predictions=predictions, references=labels)","metadata":{"execution":{"iopub.status.busy":"2024-05-04T22:04:10.952360Z","iopub.execute_input":"2024-05-04T22:04:10.953106Z","iopub.status.idle":"2024-05-04T22:04:10.958688Z","shell.execute_reply.started":"2024-05-04T22:04:10.953074Z","shell.execute_reply":"2024-05-04T22:04:10.957420Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"And to see it used in action to report metrics at the end of each epoch, here is how we define a new Trainer with this compute_metrics() function:","metadata":{}},{"cell_type":"code","source":"training_args = TrainingArguments(\"test-trainer\",\n                                  evaluation_strategy=\"epoch\",\n                                 report_to=\"none\")\n\nmodel = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)\n\ntrainer = Trainer(\n    model,\n    training_args,\n    train_dataset=tokenized_datasets[\"train\"],\n    eval_dataset=tokenized_datasets[\"validation\"],\n    data_collator=data_collator,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics,\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-04T22:20:48.169054Z","iopub.execute_input":"2024-05-04T22:20:48.170007Z","iopub.status.idle":"2024-05-04T22:20:48.635641Z","shell.execute_reply.started":"2024-05-04T22:20:48.169962Z","shell.execute_reply":"2024-05-04T22:20:48.634715Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \ndataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-05-04T22:20:52.299735Z","iopub.execute_input":"2024-05-04T22:20:52.300380Z","iopub.status.idle":"2024-05-04T22:22:59.101434Z","shell.execute_reply.started":"2024-05-04T22:20:52.300344Z","shell.execute_reply":"2024-05-04T22:22:59.100495Z"},"trusted":true},"execution_count":24,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1377' max='1377' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1377/1377 02:06, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.387825</td>\n      <td>0.835784</td>\n      <td>0.888889</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.515100</td>\n      <td>0.445928</td>\n      <td>0.852941</td>\n      <td>0.892857</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.300100</td>\n      <td>0.593101</td>\n      <td>0.860294</td>\n      <td>0.901893</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1377, training_loss=0.33896216154964226, metrics={'train_runtime': 126.4371, 'train_samples_per_second': 87.031, 'train_steps_per_second': 10.891, 'total_flos': 405114969714960.0, 'train_loss': 0.33896216154964226, 'epoch': 3.0})"},"metadata":{}}]},{"cell_type":"markdown","source":"# A Full Training\n\nDoing the same as above but with more control in PyTorch\n\n---\n\nRepeat here the stuff we will need:","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\nfrom transformers import AutoTokenizer, DataCollatorWithPadding\n\nraw_datasets = load_dataset(\"glue\", \"mrpc\")\ncheckpoint = \"bert-base-uncased\"\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)\n\n\ndef tokenize_function(example):\n    return tokenizer(example[\"sentence1\"], example[\"sentence2\"], truncation=True)\n\n\ntokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-05-04T22:26:55.353442Z","iopub.execute_input":"2024-05-04T22:26:55.353827Z","iopub.status.idle":"2024-05-04T22:27:00.455305Z","shell.execute_reply.started":"2024-05-04T22:26:55.353795Z","shell.execute_reply":"2024-05-04T22:27:00.454170Z"},"trusted":true},"execution_count":26,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1725 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b898d843af2c469b849810a7dce76043"}},"metadata":{}}]},{"cell_type":"markdown","source":"## Prepare for training\n\nBefore actually writing our training loop, we will need to define a few objects. The first ones are the dataloaders we will use to iterate over batches. But before we can define those dataloaders, we need to apply a bit of postprocessing to our tokenized_datasets, to take care of some things that the Trainer did for us automatically. Specifically, we need to:\n\n* Remove the columns corresponding to values the model does not expect (like the sentence1 and sentence2 columns).\n* Rename the column label to labels **(because the model expects the argument to be named labels)**.\n* Set the format of the datasets so they return PyTorch tensors instead of lists.\n\nOur tokenized_datasets has one method for each of those steps:","metadata":{}},{"cell_type":"code","source":"# REMINDER OF COLUMNS ETC\ntokenized_datasets","metadata":{"execution":{"iopub.status.busy":"2024-05-04T22:27:55.794846Z","iopub.execute_input":"2024-05-04T22:27:55.795570Z","iopub.status.idle":"2024-05-04T22:27:55.801674Z","shell.execute_reply.started":"2024-05-04T22:27:55.795538Z","shell.execute_reply":"2024-05-04T22:27:55.800666Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 3668\n    })\n    validation: Dataset({\n        features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 408\n    })\n    test: Dataset({\n        features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 1725\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"tokenized_datasets = tokenized_datasets.remove_columns([\"sentence1\", \"sentence2\", \"idx\"])\n\ntokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n\ntokenized_datasets.set_format(\"torch\")\n\ntokenized_datasets[\"train\"].column_names # [\"attention_mask\", \"input_ids\", \"labels\", \"token_type_ids\"]","metadata":{"execution":{"iopub.status.busy":"2024-05-04T22:28:23.249943Z","iopub.execute_input":"2024-05-04T22:28:23.250884Z","iopub.status.idle":"2024-05-04T22:28:23.270507Z","shell.execute_reply.started":"2024-05-04T22:28:23.250851Z","shell.execute_reply":"2024-05-04T22:28:23.269739Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"['labels', 'input_ids', 'token_type_ids', 'attention_mask']"},"metadata":{}}]},{"cell_type":"markdown","source":"Now can easily define our needed dataloaders:","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\ntrain_dataloader = DataLoader(\n    tokenized_datasets[\"train\"], shuffle=True, batch_size=8, collate_fn=data_collator\n)\n\neval_dataloader = DataLoader(\n    tokenized_datasets[\"validation\"], batch_size=8, collate_fn=data_collator\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-04T22:29:03.792120Z","iopub.execute_input":"2024-05-04T22:29:03.793042Z","iopub.status.idle":"2024-05-04T22:29:03.798663Z","shell.execute_reply.started":"2024-05-04T22:29:03.793009Z","shell.execute_reply":"2024-05-04T22:29:03.797579Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"To quickly check there is no mistake in the data processing, we can inspect a batch like this:\n\n**SEE ABOVE: OUR BATCH SIZE IS 8 SO SHOULD SEE 8 AS A DIMENSION IN BELOW TENSORS - THE OTHER VAR IS RANDOM SINCE WE HAVE SHUFFLE=TRUE IN THE TRAIN DATALOADER**","metadata":{}},{"cell_type":"code","source":"for batch in train_dataloader:\n    break\n{k: v.shape for k, v in batch.items()}","metadata":{"execution":{"iopub.status.busy":"2024-05-04T22:29:23.329151Z","iopub.execute_input":"2024-05-04T22:29:23.330076Z","iopub.status.idle":"2024-05-04T22:29:23.345892Z","shell.execute_reply.started":"2024-05-04T22:29:23.330041Z","shell.execute_reply":"2024-05-04T22:29:23.344893Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"{'labels': torch.Size([8]),\n 'input_ids': torch.Size([8, 81]),\n 'token_type_ids': torch.Size([8, 81]),\n 'attention_mask': torch.Size([8, 81])}"},"metadata":{}}]},{"cell_type":"markdown","source":"Now turn to model part:","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification\n\nmodel = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)","metadata":{"execution":{"iopub.status.busy":"2024-05-04T22:30:35.192476Z","iopub.execute_input":"2024-05-04T22:30:35.192916Z","iopub.status.idle":"2024-05-04T22:30:35.491788Z","shell.execute_reply.started":"2024-05-04T22:30:35.192885Z","shell.execute_reply":"2024-05-04T22:30:35.491037Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**GOOD PRACTICE SEND 1 BATCH THROUGH**\n\nTo make sure that everything will go smoothly during training, we pass our batch to this model:","metadata":{}},{"cell_type":"code","source":"outputs = model(**batch)\nprint(outputs)\nprint(\"----\")\nprint(outputs.loss)\nprint(outputs.logits.shape)","metadata":{"execution":{"iopub.status.busy":"2024-05-04T22:56:46.246568Z","iopub.execute_input":"2024-05-04T22:56:46.247710Z","iopub.status.idle":"2024-05-04T22:56:46.846478Z","shell.execute_reply.started":"2024-05-04T22:56:46.247671Z","shell.execute_reply":"2024-05-04T22:56:46.845451Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"SequenceClassifierOutput(loss=tensor(0.9363, grad_fn=<NllLossBackward0>), logits=tensor([[ 0.6608, -0.3372],\n        [ 0.6689, -0.3575],\n        [ 0.6599, -0.3340],\n        [ 0.6668, -0.3561],\n        [ 0.6559, -0.3264],\n        [ 0.6782, -0.3260],\n        [ 0.6623, -0.3201],\n        [ 0.6589, -0.3497]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n----\ntensor(0.9363, grad_fn=<NllLossBackward0>)\ntorch.Size([8, 2])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"We‚Äôre almost ready to write our training loop! We‚Äôre just missing two things: an optimizer and a learning rate scheduler. Since we are trying to replicate what the Trainer was doing by hand, we will use the same defaults. The optimizer used by the Trainer is AdamW, which is the same as Adam, but with a twist for weight decay regularization (see ‚ÄúDecoupled Weight Decay Regularization‚Äù by Ilya Loshchilov and Frank Hutter):","metadata":{}},{"cell_type":"code","source":"from transformers import AdamW\n\noptimizer = AdamW(model.parameters(), lr=5e-5)","metadata":{"execution":{"iopub.status.busy":"2024-05-04T22:57:27.492612Z","iopub.execute_input":"2024-05-04T22:57:27.492990Z","iopub.status.idle":"2024-05-04T22:57:27.523571Z","shell.execute_reply.started":"2024-05-04T22:57:27.492959Z","shell.execute_reply":"2024-05-04T22:57:27.522597Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:457: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Finally, the learning rate scheduler used by default is just a linear decay from the maximum value (5e-5) to 0. To properly define it, we need to know the number of training steps we will take, which is the number of epochs we want to run multiplied by the number of training batches (which is the length of our training dataloader). The Trainer uses three epochs by default, so we will follow that:","metadata":{}},{"cell_type":"code","source":"from transformers import get_scheduler\n\nnum_epochs = 3\nnum_training_steps = num_epochs * len(train_dataloader)\nlr_scheduler = get_scheduler(\n    \"linear\",\n    optimizer=optimizer,\n    num_warmup_steps=0,\n    num_training_steps=num_training_steps,\n)\nprint(num_training_steps)","metadata":{"execution":{"iopub.status.busy":"2024-05-04T22:58:28.345562Z","iopub.execute_input":"2024-05-04T22:58:28.346502Z","iopub.status.idle":"2024-05-04T22:58:28.351978Z","shell.execute_reply.started":"2024-05-04T22:58:28.346456Z","shell.execute_reply":"2024-05-04T22:58:28.351017Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"1377\n","output_type":"stream"}]},{"cell_type":"markdown","source":"One last thing: we will want to use the GPU if we have access to one (on a CPU, training might take several hours instead of a couple of minutes). To do this, we define a device we will put our model and our batches on:","metadata":{}},{"cell_type":"code","source":"import torch\n\ndevice = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\nmodel.to(device)\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-05-04T22:58:46.097176Z","iopub.execute_input":"2024-05-04T22:58:46.097900Z","iopub.status.idle":"2024-05-04T22:58:46.224909Z","shell.execute_reply.started":"2024-05-04T22:58:46.097866Z","shell.execute_reply":"2024-05-04T22:58:46.223976Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"markdown","source":"We are now ready to train! To get some sense of when training will be finished, we add a progress bar over our number of training steps, using the tqdm library:","metadata":{}},{"cell_type":"code","source":"from tqdm.auto import tqdm\n\nprogress_bar = tqdm(range(num_training_steps))\n\nmodel.train()\ndebug = 0\nfor epoch in range(num_epochs):\n    for batch in train_dataloader:\n        if debug < 1:\n            print(batch)\n            debug = 123\n        batch = {k: v.to(device) for k, v in batch.items()}\n        outputs = model(**batch)\n        loss = outputs.loss\n        loss.backward()\n\n        optimizer.step()\n        lr_scheduler.step()\n        optimizer.zero_grad()\n        progress_bar.update(1)","metadata":{"execution":{"iopub.status.busy":"2024-05-04T23:00:04.000364Z","iopub.execute_input":"2024-05-04T23:00:04.000783Z","iopub.status.idle":"2024-05-04T23:01:50.066136Z","shell.execute_reply.started":"2024-05-04T23:00:04.000750Z","shell.execute_reply":"2024-05-04T23:01:50.065062Z"},"trusted":true},"execution_count":38,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1377 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"41c603ee040b4c34b13b9c8c0040ce32"}},"metadata":{}},{"name":"stdout","text":"{'labels': tensor([1, 0, 0, 1, 0, 1, 1, 1]), 'input_ids': tensor([[  101,  2157,  2085,  1010,  2069,  2416,  2163,  2079,  1024,  6751,\n          1010,  4174,  1010,  5135,  1010,  2047,  3933,  1010,  3448,  1010,\n          1998,  5273,  1012,   102,  6410,  2015,  2550,  2011,  2069,  2416,\n          2163,  1035,  6751,  1010,  4174,  1010,  5135,  1010,  2047,  3933,\n          1010,  3448,  1998,  5273,  1035,  2085,  2031,  2107,  5433,  1012,\n           102,     0,     0,     0,     0,     0,     0,     0,     0],\n        [  101,  1996, 13486, 12163,  3446,  3062,  2000,  1020,  1012,  1018,\n          3867,  1010,  2091,  2013,  1037,  8001,  1020,  1012,  1021,  3867,\n          1999,  2257,  1012,   102,  1996, 12163,  3446,  1999,  2624, 16877,\n          2221, 13537,  2197,  3204,  2000,  1022,  1012,  1019,  3867,  1010,\n          2091,  3053,  1037,  2440,  7017,  2391,  2013,  2257,  1012,   102,\n             0,     0,     0,     0,     0,     0,     0,     0,     0],\n        [  101,  1996,  3405,  3068,  2523,  1997,  2637,  2758,  2009,  3488,\n          2000,  9790,  1996,  2299, 13066,  2279,  3204,  1012,   102,  2008,\n          2003,  1010,  2065,  1996,  3405,  3068,  2523,  1997,  2637,  2038,\n          2505,  2000,  2360,  2055,  2009,  1012,   102,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0],\n        [  101,  2009,  5031,  1997,  2809, 10823,  1010,  2048,  3124,  7231,\n          3366,  1998,  2048, 12461,  1012,   102,  1996,  2047,  6467,  5031,\n          1997,  2809, 10823,  1010,  2048, 12461,  1998,  2048, 18414, 29165,\n          2015,  1997,  3124,  7231,  3366,  6934,  1012,   102,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0],\n        [  101,  1996, 12012,  1998,  3863,  3222,  2036,  6406,  1037,  2942,\n          9861, 12087,  2114, 11586,  2232,  1010,  1997,  6708,  3077,  1012,\n           102,  1996, 12012,  1998,  3863,  3222,  2716,  1037,  3141,  2942,\n          2553,  2006,  9432,  1012,   102,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0],\n        [  101,  1000,  1996, 10984,  1997,  1031,  1996, 13612,  1033,  2003,\n          7078, 26233,  2000,  2033,  1010,  1000,  7912, 11531,  2056,  1999,\n          1037,  4861,  2000,  4419,  2739,  3149,  2197,  2733,  1012,   102,\n          7912, 11531,  3843,  1037,  4861,  2197,  2733,  2000,  1996,  4419,\n          2739,  3149,  3038,  1010,  1000,  1996, 10984,  1997,  1031,  1996,\n         13612,  1033,  2003,  7078, 26233,  2000,  2033,  1012,   102],\n        [  101,  4012, 10526,  2465,  1037,  6661,  2020,  2039,  1022, 16653,\n          2012,  1002,  2382,  1012,  2753,  1999,  2851,  6202,  2006,  1996,\n         17235,  2850,  4160,  4518,  3006,  1012,   102,  1996,  4518,  3123,\n          4466, 16653,  2000,  1002,  2382,  7483,  1999, 17235,  2850,  4160,\n          4518,  3006,  6202,  1012,   102,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0],\n        [  101, 14766,  4146,  6064,  5852,  2006,  1996, 27094,  1998,  2743,\n          1996,  3463,  2083,  1037,  2120,  6064,  2951,  2918,  1999,  2257,\n          1012,   102, 14766,  4146,  6064,  5852,  2006,  1996, 27094,  1998,\n          2743,  1996,  3463,  2083,  1037,  2120,  7809,  2197,  3204,  1012,\n           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"You can see that the core of the training loop looks a lot like the one in the introduction. We didn‚Äôt ask for any reporting, so this training loop will not tell us anything about how the model fares. We need to add an evaluation loop for that.\n\n## The evaluation loop\n\nAs we did earlier, we will use a metric provided by the ü§ó Evaluate library. We‚Äôve already seen the metric.compute() method, but metrics can actually accumulate batches for us as we go over the prediction loop with the method add_batch(). Once we have accumulated all the batches, we can get the final result with metric.compute(). Here‚Äôs how to implement all of this in an evaluation loop:","metadata":{}},{"cell_type":"code","source":"import evaluate\n\nmetric = evaluate.load(\"glue\", \"mrpc\")\n\nmodel.eval()\n\ndebug = 0\nfor batch in eval_dataloader:\n    batch = {k: v.to(device) for k, v in batch.items()}\n    with torch.no_grad():\n        outputs = model(**batch)\n        \n    if debug < 1:\n        print(outputs)\n        debug = 9994\n    logits = outputs.logits\n    predictions = torch.argmax(logits, dim=-1)\n    metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n\nmetric.compute()","metadata":{"execution":{"iopub.status.busy":"2024-05-04T23:04:13.197256Z","iopub.execute_input":"2024-05-04T23:04:13.197701Z","iopub.status.idle":"2024-05-04T23:04:15.012341Z","shell.execute_reply.started":"2024-05-04T23:04:13.197670Z","shell.execute_reply":"2024-05-04T23:04:15.011302Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"SequenceClassifierOutput(loss=tensor(0.3927, device='cuda:0'), logits=tensor([[-2.0384,  1.7079],\n        [ 1.0465, -0.7586],\n        [ 0.2972, -1.2662],\n        [-1.2164,  0.8131],\n        [ 0.5937, -1.1682],\n        [-1.5595,  1.3339],\n        [-1.2748,  1.0378],\n        [-1.7863,  1.6049]], device='cuda:0'), hidden_states=None, attentions=None)\n","output_type":"stream"},{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"{'accuracy': 0.8529411764705882, 'f1': 0.8958333333333334}"},"metadata":{}}]},{"cell_type":"markdown","source":"## Supercharge your training loop with ü§ó Accelerate\n\nThe training loop we defined earlier works fine on a single CPU or GPU. But using the ü§ó Accelerate library, with just a few adjustments we can enable distributed training on multiple GPUs or TPUs. \n\n**NEW CODE BELOW - I COMMENTED OUT STUFF FROM PREVIOUS LOOP AND ADDED <---- TO NEW STUFF**","metadata":{}},{"cell_type":"code","source":"from accelerate import Accelerator # <------\nfrom transformers import AdamW, AutoModelForSequenceClassification, get_scheduler\n\naccelerator = Accelerator() # <------\n\nmodel = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)\noptimizer = AdamW(model.parameters(), lr=3e-5)\n\n#device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n#model.to(device)\n\ntrain_dataloader, eval_dataloader, model, optimizer = accelerator.prepare(\n    train_dataloader, eval_dataloader, model, optimizer\n) # <--------------------------------------------------------------\n\nnum_epochs = 3\nnum_training_steps = num_epochs * len(train_dataloader)\nlr_scheduler = get_scheduler(\n      \"linear\",\n      optimizer=optimizer,\n      num_warmup_steps=0,\n      num_training_steps=num_training_steps\n)\n\nprogress_bar = tqdm(range(num_training_steps))\n\nmodel.train()\nfor epoch in range(num_epochs):\n    for batch in train_dataloader:\n        #batch = {k: v.to(device) for k, v in batch.items()}\n        outputs = model(**batch)\n        loss = outputs.loss\n        #loss.backward()\n        accelerator.backward(loss) # <---------------\n        \n        optimizer.step()\n        lr_scheduler.step()\n        optimizer.zero_grad()\n        progress_bar.update(1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The first line to add is the import line. The second line instantiates an Accelerator object that will look at the environment and initialize the proper distributed setup. ü§ó Accelerate handles the device placement for you, so you can remove the lines that put the model on the device (or, if you prefer, change them to use accelerator.device instead of device).\n\nThen the main bulk of the work is done in the line that sends the dataloaders, the model, and the optimizer to accelerator.prepare(). This will wrap those objects in the proper container to make sure your distributed training works as intended. The remaining changes to make are removing the line that puts the batch on the device (again, if you want to keep this you can just change it to use accelerator.device) and replacing loss.backward() with accelerator.backward(loss).\n\n**In order to benefit from the speed-up offered by Cloud TPUs, we recommend padding your samples to a fixed length with the `padding=\"max_length\"` and `max_length` arguments of the tokenizer.**\n\n---\n\nPutting this in a train.py script will make that script runnable on any kind of distributed setup. To try it out in your distributed setup, run the command:\n\n`accelerate config`\n\nwhich will prompt you to answer a few questions and dump your answers in a configuration file used by this command:\n\n`accelerate launch train.py`\n\nwhich will launch the distributed training.\n\n---\n\nIf you want to try this in a Notebook (for instance, to test it with TPUs on Colab), just paste the code in a training_function() and run a last cell with:\n\n\n# UPDATE - THIS DOESN'T WORK: need to adjust (the NLP course stuff is wrong/incomplete - had to google elsewhere)\n\n**ALSO, cannot run in this notebook since already launched 1 Accelerate object already apparently**\n\n- will redo in new notebook","metadata":{}},{"cell_type":"code","source":"from accelerate import Accelerator\nfrom transformers import AdamW, AutoModelForSequenceClassification, get_scheduler\n\ndef training_function():\n    accelerator = Accelerator()\n    \n    model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)\n    \n    optimizer = AdamW(model.parameters(), lr=3e-5)\n\n    train_dl, eval_dl, model, optimizer = accelerator.prepare(\n        train_dataloader, eval_dataloader, model, optimizer\n    )\n\n    num_epochs = 3\n    num_training_steps = num_epochs * len(train_dl)\n    lr_scheduler = get_scheduler(\n        \"linear\",\n        optimizer=optimizer,\n        num_warmup_steps=0,\n        num_training_steps=num_training_steps,\n    )\n\n    progress_bar = tqdm(range(num_training_steps))\n\n    model.train()\n    for epoch in range(num_epochs):\n        for batch in train_dl:\n            outputs = model(**batch)\n            loss = outputs.loss\n            accelerator.backward(loss)\n\n            optimizer.step()\n            lr_scheduler.step()\n            optimizer.zero_grad()\n            progress_bar.update(1)","metadata":{"execution":{"iopub.status.busy":"2024-05-04T23:18:04.025324Z","iopub.execute_input":"2024-05-04T23:18:04.026210Z","iopub.status.idle":"2024-05-04T23:18:04.034479Z","shell.execute_reply.started":"2024-05-04T23:18:04.026159Z","shell.execute_reply":"2024-05-04T23:18:04.033382Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"from accelerate.utils import write_basic_config\nwrite_basic_config()","metadata":{"execution":{"iopub.status.busy":"2024-05-04T23:21:16.521772Z","iopub.execute_input":"2024-05-04T23:21:16.522279Z","iopub.status.idle":"2024-05-04T23:21:16.531356Z","shell.execute_reply.started":"2024-05-04T23:21:16.522234Z","shell.execute_reply":"2024-05-04T23:21:16.530256Z"},"trusted":true},"execution_count":43,"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"PosixPath('/root/.cache/huggingface/accelerate/default_config.yaml')"},"metadata":{}}]},{"cell_type":"code","source":"from accelerate import notebook_launcher\n\nnotebook_launcher(training_function, num_processes=2)","metadata":{"execution":{"iopub.status.busy":"2024-05-04T23:21:54.846795Z","iopub.execute_input":"2024-05-04T23:21:54.847795Z","iopub.status.idle":"2024-05-04T23:21:54.923403Z","shell.execute_reply.started":"2024-05-04T23:21:54.847760Z","shell.execute_reply":"2024-05-04T23:21:54.921944Z"},"trusted":true},"execution_count":45,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[45], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01maccelerate\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m notebook_launcher\n\u001b[0;32m----> 3\u001b[0m \u001b[43mnotebook_launcher\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_processes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/launchers.py:148\u001b[0m, in \u001b[0;36mnotebook_launcher\u001b[0;34m(function, args, num_processes, mixed_precision, use_port, master_addr, node_rank, num_nodes)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmultiprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspawn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ProcessRaisedException\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(AcceleratorState\u001b[38;5;241m.\u001b[39m_shared_state) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 148\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    149\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo launch a multi-GPU training from your notebook, the `Accelerator` should only be initialized \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    150\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minside your training function. Restart your notebook and make sure no cells initializes an \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    151\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`Accelerator`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    152\u001b[0m     )\n\u001b[1;32m    153\u001b[0m \u001b[38;5;66;03m# Check for specific libraries known to initialize CUDA that users constantly use\u001b[39;00m\n\u001b[1;32m    154\u001b[0m problematic_imports \u001b[38;5;241m=\u001b[39m are_libraries_initialized(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbitsandbytes\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mValueError\u001b[0m: To launch a multi-GPU training from your notebook, the `Accelerator` should only be initialized inside your training function. Restart your notebook and make sure no cells initializes an `Accelerator`."],"ename":"ValueError","evalue":"To launch a multi-GPU training from your notebook, the `Accelerator` should only be initialized inside your training function. Restart your notebook and make sure no cells initializes an `Accelerator`.","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}