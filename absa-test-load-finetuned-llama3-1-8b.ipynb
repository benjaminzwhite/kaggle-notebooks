{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\n!pip install pip3-autoremove\n!pip-autoremove torch torchvision torchaudio -y\n!pip install unsloth\n\nimport os\nos.environ[\"WANDB_DISABLED\"] = \"true\"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-13T19:53:03.932651Z","iopub.execute_input":"2024-10-13T19:53:03.932982Z","iopub.status.idle":"2024-10-13T19:56:20.790448Z","shell.execute_reply.started":"2024-10-13T19:53:03.932947Z","shell.execute_reply":"2024-10-13T19:56:20.789175Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import torch\n\nmax_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\ndtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\nload_in_4bit = True","metadata":{"execution":{"iopub.status.busy":"2024-10-13T19:56:20.792566Z","iopub.execute_input":"2024-10-13T19:56:20.792900Z","iopub.status.idle":"2024-10-13T19:56:22.648199Z","shell.execute_reply.started":"2024-10-13T19:56:20.792866Z","shell.execute_reply":"2024-10-13T19:56:22.647403Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from unsloth import FastLanguageModel\n\nmodel, tokenizer = FastLanguageModel.from_pretrained(\n    model_name = \"benjaminzwhite/Llama-3.1-8B_ABSQ-AQSP_LoRA\", # YOUR MODEL YOU USED FOR TRAINING\n    max_seq_length = max_seq_length,\n    dtype = dtype,\n    load_in_4bit = load_in_4bit,\n)\nFastLanguageModel.for_inference(model) # Enable native 2x faster inference","metadata":{"execution":{"iopub.status.busy":"2024-10-13T19:56:22.649506Z","iopub.execute_input":"2024-10-13T19:56:22.650012Z","iopub.status.idle":"2024-10-13T19:57:11.233979Z","shell.execute_reply.started":"2024-10-13T19:56:22.649966Z","shell.execute_reply":"2024-10-13T19:57:11.232888Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n","output_type":"stream"},{"name":"stderr","text":"Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\nUsing the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"},{"name":"stdout","text":"==((====))==  Unsloth 2024.9.post4: Fast Llama patching. Transformers = 4.44.2.\n   \\\\   /|    GPU: Tesla T4. Max memory: 14.741 GB. Platform = Linux.\nO^O/ \\_/ \\    Pytorch: 2.4.1+cu121. CUDA = 7.5. CUDA Toolkit = 12.1.\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.28.post1. FA2 = False]\n \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/5.70G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1376bbedf30447e69e8dc54cec46ea5a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/230 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"76a8a32edfbb4144843a5e9599de52b7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/50.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f7ada384f5ae4199a8bf73c7b01e3251"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0955aec4db1e4d69801215a58a44cbda"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/345 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"86e5d0b1d29648f184441b6be5d0d7a0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/168M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"46ce292ec0ca43baa9ca022ecf9f8115"}},"metadata":{}},{"name":"stderr","text":"Unsloth 2024.9.post4 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"PeftModelForCausalLM(\n  (base_model): LoraModel(\n    (model): LlamaForCausalLM(\n      (model): LlamaModel(\n        (embed_tokens): Embedding(128256, 4096)\n        (layers): ModuleList(\n          (0-31): 32 x LlamaDecoderLayer(\n            (self_attn): LlamaAttention(\n              (q_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Identity()\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (k_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Identity()\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=1024, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (v_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Identity()\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=1024, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (o_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Identity()\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (rotary_emb): LlamaExtendedRotaryEmbedding()\n            )\n            (mlp): LlamaMLP(\n              (gate_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Identity()\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=14336, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (up_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Identity()\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=14336, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (down_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Identity()\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=14336, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (act_fn): SiLU()\n            )\n            (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n            (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n          )\n        )\n        (norm): LlamaRMSNorm((4096,), eps=1e-05)\n        (rotary_emb): LlamaRotaryEmbedding()\n      )\n      (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n    )\n  )\n)"},"metadata":{}}]},{"cell_type":"markdown","source":"# Inference\n\n- can toggle inference mode","metadata":{}},{"cell_type":"code","source":"FastLanguageModel.for_inference(model) # Unsloth has 2x faster inference!\n","metadata":{"execution":{"iopub.status.busy":"2024-10-13T19:58:26.996184Z","iopub.execute_input":"2024-10-13T19:58:26.996991Z","iopub.status.idle":"2024-10-13T19:58:27.021805Z","shell.execute_reply.started":"2024-10-13T19:58:26.996951Z","shell.execute_reply":"2024-10-13T19:58:27.020941Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"PeftModelForCausalLM(\n  (base_model): LoraModel(\n    (model): LlamaForCausalLM(\n      (model): LlamaModel(\n        (embed_tokens): Embedding(128256, 4096)\n        (layers): ModuleList(\n          (0-31): 32 x LlamaDecoderLayer(\n            (self_attn): LlamaAttention(\n              (q_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Identity()\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (k_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Identity()\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=1024, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (v_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Identity()\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=1024, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (o_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Identity()\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (rotary_emb): LlamaExtendedRotaryEmbedding()\n            )\n            (mlp): LlamaMLP(\n              (gate_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Identity()\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=14336, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (up_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Identity()\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=14336, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (down_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Identity()\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=14336, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (act_fn): SiLU()\n            )\n            (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n            (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n          )\n        )\n        (norm): LlamaRMSNorm((4096,), eps=1e-05)\n        (rotary_emb): LlamaRotaryEmbedding()\n      )\n      (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n    )\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"prompt_template = \"\"\"Below is a DOCUMENT in which human beings may be expressing themselves about products or services.\n\nPerform a full aspect-based sentiment analysis of the DOCUMENT.\n    \nOnly use sentiment labels that appear in the below list of ALLOWED SENTIMENTS.\n    \nOnly use aspect category labels that appear in the below list of ALLOWED ASPECT CATEGORIES.\n    \nUse the exact words and spelling found in the DOCUMENT without modification.\n\nReturn your answer as a structured JSON object without deviation.\n\n### DOCUMENT:\n\n{manual_add_query}\n\n### ALLOWED SENTIMENTS:\n\n- positive\n- negative\n- neutral\n\n### ALLOWED ASPECT CATEGORIES:\n\n- food quality\n- service general\n- restaurant general\n- ambience general\n- food style_options\n- restaurant miscellaneous\n- food prices\n- restaurant prices\n- drinks quality\n- drinks style_options\n- location general\n- drinks prices\n- food general\n\n### RESPONSE:\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-10-13T19:59:20.571555Z","iopub.execute_input":"2024-10-13T19:59:20.571967Z","iopub.status.idle":"2024-10-13T19:59:20.577361Z","shell.execute_reply.started":"2024-10-13T19:59:20.571929Z","shell.execute_reply":"2024-10-13T19:59:20.576271Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## test single query end to end\n\n- **NOTE:** the base model is 8b, but NOT 8b-instruct **tutorial notebook wasn't clear about this afaict**\n\n- so might be better way of getting response\n\n- here i'm parsing by looking at \"what appears after `### RESPONSE:###` O_o","metadata":{}},{"cell_type":"code","source":"EOS_TOKEN = tokenizer.eos_token","metadata":{"execution":{"iopub.status.busy":"2024-10-13T20:03:10.099529Z","iopub.execute_input":"2024-10-13T20:03:10.099946Z","iopub.status.idle":"2024-10-13T20:03:10.104660Z","shell.execute_reply.started":"2024-10-13T20:03:10.099909Z","shell.execute_reply":"2024-10-13T20:03:10.103643Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"test_query = \"I really hated this place's burgers they are the worst i have ever tasted in New York!\"\n\ninputs = tokenizer(prompt_template.format(manual_add_query=test_query), return_tensors = \"pt\").to(\"cuda\")\n\noutputs = model.generate(input_ids = inputs.input_ids,\n                         attention_mask = inputs.attention_mask,\n                         max_new_tokens = 500)\n\nres = tokenizer.batch_decode(outputs)\n\n# add 0 here - might not work when have several in batch TODO: test with dataset not just 1 sample\nstart_idx = res[0].index(\"### RESPONSE:\\n\")\n\nprint(start_idx)\n\n# TODO: fix this better with error handling or if train with chat template understand how it works\ngenerated_absa_text = res[0][start_idx + len(\"### RESPONSE:\\n\"):]\n\n# remove the EOS_TOKEN at the end also\ngenerated_absa_text = generated_absa_text.rstrip(EOS_TOKEN)\n\ngenerated_absa_text","metadata":{"execution":{"iopub.status.busy":"2024-10-13T20:03:12.300160Z","iopub.execute_input":"2024-10-13T20:03:12.300587Z","iopub.status.idle":"2024-10-13T20:03:15.490993Z","shell.execute_reply.started":"2024-10-13T20:03:12.300547Z","shell.execute_reply":"2024-10-13T20:03:15.490108Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"951\n","output_type":"stream"},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"'{\"aspect_based_sentiment_analysis\": [{\"opinion term\": \"burgers\", \"aspect category\": \"food quality\", \"sentiment\": \"negative\", \"justification\": \"worst\"}] }'"},"metadata":{}}]},{"cell_type":"code","source":"res","metadata":{"execution":{"iopub.status.busy":"2024-10-13T20:16:27.183900Z","iopub.execute_input":"2024-10-13T20:16:27.184844Z","iopub.status.idle":"2024-10-13T20:16:27.190761Z","shell.execute_reply.started":"2024-10-13T20:16:27.184788Z","shell.execute_reply":"2024-10-13T20:16:27.189877Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"['<|begin_of_text|>Below is a DOCUMENT in which human beings may be expressing themselves about products or services.\\n\\nPerform a full aspect-based sentiment analysis of the DOCUMENT.\\n    \\nOnly use sentiment labels that appear in the below list of ALLOWED SENTIMENTS.\\n    \\nOnly use aspect category labels that appear in the below list of ALLOWED ASPECT CATEGORIES.\\n    \\nUse the exact words and spelling found in the DOCUMENT without modification.\\n\\nReturn your answer as a structured JSON object without deviation.\\n\\n### DOCUMENT:\\n\\nI really hated this place\\'s burgers they are the worst i have ever tasted in New York!\\n\\n### ALLOWED SENTIMENTS:\\n\\n- positive\\n- negative\\n- neutral\\n\\n### ALLOWED ASPECT CATEGORIES:\\n\\n- food quality\\n- service general\\n- restaurant general\\n- ambience general\\n- food style_options\\n- restaurant miscellaneous\\n- food prices\\n- restaurant prices\\n- drinks quality\\n- drinks style_options\\n- location general\\n- drinks prices\\n- food general\\n\\n### RESPONSE:\\n{\"aspect_based_sentiment_analysis\": [{\"opinion term\": \"burgers\", \"aspect category\": \"food quality\", \"sentiment\": \"negative\", \"justification\": \"worst\"}] }<|end_of_text|>']"},"metadata":{}}]},{"cell_type":"markdown","source":"# Evaluation\n\n## Ok loop over test set\n\n- reload the restaurants dataset, do the same processing on it to get same format","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\n\nabsa_quad = load_dataset(\"NEUDM/absa-quad\")","metadata":{"execution":{"iopub.status.busy":"2024-10-13T20:06:17.926041Z","iopub.execute_input":"2024-10-13T20:06:17.927005Z","iopub.status.idle":"2024-10-13T20:06:20.630976Z","shell.execute_reply.started":"2024-10-13T20:06:17.926963Z","shell.execute_reply":"2024-10-13T20:06:20.629966Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/2.83k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"377f95612eba4d72bfd571155feb8d99"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generation/train.jsonl:   0%|          | 0.00/2.00M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"efc336760c4943a092a060ffa8c2086f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generation/dev.jsonl:   0%|          | 0.00/503k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1b2ca7e71bc4678ab0b9b2f3e9b48fa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generation/test.jsonl:   0%|          | 0.00/1.03M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b3386d4d75c4b96976403584312f5c8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/2098 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2397cc40fab64fa4986cfb89e618f609"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/525 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"832cf697f4814a47afe88c7c7cbf3342"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/1081 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eef0f35c156248778d28502c10ee3046"}},"metadata":{}}]},{"cell_type":"code","source":"import ast\nimport json","metadata":{"execution":{"iopub.status.busy":"2024-10-13T20:06:53.517233Z","iopub.execute_input":"2024-10-13T20:06:53.517634Z","iopub.status.idle":"2024-10-13T20:06:53.521976Z","shell.execute_reply.started":"2024-10-13T20:06:53.517598Z","shell.execute_reply":"2024-10-13T20:06:53.521026Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"#\n# -- iterate over test dataset\n#\ntest_dataset_rows = []\n\nfor example in absa_quad[\"test\"].iter(batch_size=1):\n    # get the raw text\n    example_text = example[\"input\"][0]\n    #print(example_text)\n\n    input_text = ast.literal_eval(example_text)[0]\n    \n    gold_labels = example[\"output\"][0]\n    \n    #print(gold_labels)\n    golds = ast.literal_eval(gold_labels)\n    tmp_list_of_quads = []\n    for quad in golds:\n        #print(quad)\n        tmp_d = {}\n        tmp_d[\"opinion term\"] = quad[0]\n        tmp_d[\"aspect category\"] = quad[1]\n        tmp_d[\"sentiment\"] = quad[2]\n        tmp_d[\"justification\"] = quad[3]\n        \n        tmp_list_of_quads.append(tmp_d)\n        #print(tmp_d)\n    \n    test_dataset_rows.append({\n        \"input_text\": input_text,\n        \"gold_quads\": tmp_list_of_quads\n    })","metadata":{"execution":{"iopub.status.busy":"2024-10-13T20:38:55.879904Z","iopub.execute_input":"2024-10-13T20:38:55.880317Z","iopub.status.idle":"2024-10-13T20:38:56.029351Z","shell.execute_reply.started":"2024-10-13T20:38:55.880277Z","shell.execute_reply":"2024-10-13T20:38:56.028556Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom datasets import Dataset\n\n# convert to HF dataset\ndf = pd.DataFrame(test_dataset_rows)\n\ndf.sample(3)","metadata":{"execution":{"iopub.status.busy":"2024-10-13T20:42:26.437848Z","iopub.execute_input":"2024-10-13T20:42:26.438254Z","iopub.status.idle":"2024-10-13T20:42:26.454837Z","shell.execute_reply.started":"2024-10-13T20:42:26.438216Z","shell.execute_reply":"2024-10-13T20:42:26.453851Z"},"trusted":true},"execution_count":46,"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"                                            input_text  \\\n725  Another plus is the open feel of the restauran...   \n562  â€“ Mioposto has a very creative & delicious piz...   \n501   We asked for beverages and never received them .   \n\n                                            gold_quads  \n725  [{'opinion term': 'feel', 'aspect category': '...  \n562  [{'opinion term': 'pizza menu', 'aspect catego...  \n501  [{'opinion term': 'NULL', 'aspect category': '...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>input_text</th>\n      <th>gold_quads</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>725</th>\n      <td>Another plus is the open feel of the restauran...</td>\n      <td>[{'opinion term': 'feel', 'aspect category': '...</td>\n    </tr>\n    <tr>\n      <th>562</th>\n      <td>â€“ Mioposto has a very creative &amp; delicious piz...</td>\n      <td>[{'opinion term': 'pizza menu', 'aspect catego...</td>\n    </tr>\n    <tr>\n      <th>501</th>\n      <td>We asked for beverages and never received them .</td>\n      <td>[{'opinion term': 'NULL', 'aspect category': '...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"RANDOM_SEED = 1234\n\n# inference is slow since doing without batches etc - take sample\ndf_sample = df.sample(n=75, random_state=RANDOM_SEED)\n\ndf_sample.head(3)","metadata":{"execution":{"iopub.status.busy":"2024-10-13T20:42:30.657550Z","iopub.execute_input":"2024-10-13T20:42:30.658239Z","iopub.status.idle":"2024-10-13T20:42:30.670996Z","shell.execute_reply.started":"2024-10-13T20:42:30.658200Z","shell.execute_reply":"2024-10-13T20:42:30.669758Z"},"trusted":true},"execution_count":47,"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"                                            input_text  \\\n232  But $ 500 for a dinner for two that didn 't in...   \n62                                        Great food !   \n862  â€“ How to describe the best sushi in NYC : hmmm...   \n\n                                            gold_quads  \n232  [{'opinion term': 'dinner for two', 'aspect ca...  \n62   [{'opinion term': 'food', 'aspect category': '...  \n862  [{'opinion term': 'sushi', 'aspect category': ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>input_text</th>\n      <th>gold_quads</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>232</th>\n      <td>But $ 500 for a dinner for two that didn 't in...</td>\n      <td>[{'opinion term': 'dinner for two', 'aspect ca...</td>\n    </tr>\n    <tr>\n      <th>62</th>\n      <td>Great food !</td>\n      <td>[{'opinion term': 'food', 'aspect category': '...</td>\n    </tr>\n    <tr>\n      <th>862</th>\n      <td>â€“ How to describe the best sushi in NYC : hmmm...</td>\n      <td>[{'opinion term': 'sushi', 'aspect category': ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## iterate over rows and store inference results","metadata":{}},{"cell_type":"code","source":"#df.shape\ndf_sample.shape","metadata":{"execution":{"iopub.status.busy":"2024-10-13T20:42:33.977745Z","iopub.execute_input":"2024-10-13T20:42:33.978147Z","iopub.status.idle":"2024-10-13T20:42:33.984150Z","shell.execute_reply.started":"2024-10-13T20:42:33.978112Z","shell.execute_reply":"2024-10-13T20:42:33.983167Z"},"trusted":true},"execution_count":48,"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"(75, 2)"},"metadata":{}}]},{"cell_type":"code","source":"print(\"ITERATING OVER SAMPLE OF 75 TEST EXAMPLES\")\nprint(\"---\")\n\nfor index, row in df_sample.iterrows():\n    curr_query = row['input_text']\n    \n    print(\"Processing input query: \", curr_query)\n    \n    inputs = tokenizer(prompt_template.format(manual_add_query=curr_query), return_tensors = \"pt\").to(\"cuda\")\n\n    outputs = model.generate(input_ids = inputs.input_ids,\n                             attention_mask = inputs.attention_mask,\n                             max_new_tokens = 512)\n\n    res = tokenizer.batch_decode(outputs)\n    \n    raw_model_completion = res[0]\n    \n    #df.loc[index, \"raw_model_completion\"] = raw_model_completion\n    # update df_sample ---- redo with full dataset later TODO\n    df_sample.loc[index, \"raw_model_completion\"] = raw_model_completion\n    ","metadata":{"execution":{"iopub.status.busy":"2024-10-13T20:43:02.142703Z","iopub.execute_input":"2024-10-13T20:43:02.143231Z","iopub.status.idle":"2024-10-13T20:48:43.780356Z","shell.execute_reply.started":"2024-10-13T20:43:02.143187Z","shell.execute_reply":"2024-10-13T20:48:43.779496Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"ITERATING OVER SAMPLE OF 75 TEST EXAMPLES\n---\nProcessing input query:  But $ 500 for a dinner for two that didn 't include Wine ?\nProcessing input query:  Great food !\nProcessing input query:  â€“ How to describe the best sushi in NYC : hmmmm , delicious , amazing , fantastic , suculent , perfect , nah , all of the above .\nProcessing input query:  Servers are all different , Greg is my favorite .\nProcessing input query:  The pancakes were certainly inventive but $ 8.50 for 3 - 6 `` pancakes ( one of them was more like 5 `` ) in the pancake flight ( sample of 3 different pancakes ) is well over-priced .\nProcessing input query:  Brunch at Murphy 's is to die for , my specialty ... egg white omelet , the food is always freshly prepared .\nProcessing input query:  Food was good and cheap .\nProcessing input query:  Would NEVER go back\nProcessing input query:  To the owners of Open Sesame ... Bravo ... I ca n't wait to come back to dine at your restaurant !\nProcessing input query:  Overall the food quality was pretty good , though I hear the salmon is much better when it has n't sat cooling in front of the guest .\nProcessing input query:  The wait staff is very courteous and accomodating .\nProcessing input query:  All the various Greek and Cypriot dishes are excellent , but the gyro is the reason to come -- if you do n't eat one your trip was wasted .\nProcessing input query:  Great draft and bottle selection and the pizza rocks .\nProcessing input query:  â€“ Eggs , pancakes , potatoes , fresh fruit and yogurt -- everything they serve is delicious .\nProcessing input query:  I am actually offended to have spent so much money on such a bad experience .\nProcessing input query:  Great value sushi with high quality & nice setting .\nProcessing input query:  The appetizer of oysters , lobster , crab ( small size ) made a perfect entre for my wife .\nProcessing input query:  everyone was cheerfully cooperative and helpful .\nProcessing input query:  big thick pepperoni\nProcessing input query:  No desert menu , no apology , nothing ! ! ! ! ! !\nProcessing input query:  Everyone seemed generally happy with their food , except my brother who had the grilled Mahi Mahi , seemingly drenched in Grapfruit Juice !\nProcessing input query:  Poor customer service / poor pizza .\nProcessing input query:  Can get busy on Fridays for a table but once seated , the service is so efficient you can be in and out of there quickly .\nProcessing input query:  You are bound to have a very charming time .\nProcessing input query:  Overall , I would go back and eat at the restaurant again .\nProcessing input query:  The band was very good and the service was attentive .\nProcessing input query:  The food was ok , but the service was so poor that the food was cold buy the time everyone in my party was served .\nProcessing input query:  The sake â€™ s complimented the courses very well and is successfully easing me into the sake world .\nProcessing input query:  And $ 11 for a plate of bland guacamole ?\nProcessing input query:  This place doesn 't make any sense\nProcessing input query:  Best In ALL of NYC\nProcessing input query:  After the 4th time i asked again and the waiter than said after our dinner .\nProcessing input query:  great service\nProcessing input query:  â€“ After 12 years in Seattle Ray 's rates as the place we always go back to .\nProcessing input query:  The pasta was well cooked , did n't have enough sauce though or flavor .\nProcessing input query:  Regardless , we 'll be back and can 't wait to visit in the summer to take advantage of the patio .\nProcessing input query:  Easily the worst stir-fried squid I 've ever tasted .\nProcessing input query:  I got the shellfish and shrimp appetizer and it was alright .\nProcessing input query:  We have gone for dinner only a few times but the same great quality and service is given .\nProcessing input query:  It 's *very * reasonably priced , esp for the quality of the food .\nProcessing input query:  Do n't go with a larger group than 4 !\nProcessing input query:  The food is great , the bartenders go that extra mile .\nProcessing input query:  Fresh ingrediants and super tasty .\nProcessing input query:  Love it .\nProcessing input query:  Best food , phenominal service\nProcessing input query:  Very disappointed .\nProcessing input query:  Portions was just enough for me , but may not be for a big eater .\nProcessing input query:  Great , original taste .\nProcessing input query:  In other words , if they aren 't making $ $ off of you then you do n't rate high on their 'service scale ' .\nProcessing input query:  When I got there the place was packed but they made sure to seat me quickly .\nProcessing input query:  We ordered a selection of the small plates , and the shoe string onions , goat cheese pizza , grilled asparagus and fried brie with fruit were all very good .\nProcessing input query:  This place is a must visit !\nProcessing input query:  I will not go back .\nProcessing input query:  The best !\nProcessing input query:  Took forever to get our order taken , water refills were too much to ask for and the only time she was fast was when we asked for our bill when we could get her attention .\nProcessing input query:  They aren 't the most talkative , but everytime I 've been there they have been very busy , which probably accounts for the lack of conversation .\nProcessing input query:  The food here was mediocre at best .\nProcessing input query:  The waiter was a bit unfriendly and the feel of the restaurant was crowded .\nProcessing input query:  At first glance this place seems a bit pricey for a hot dog joint , but at Bark you do n't just get your average hot dog .\nProcessing input query:  Excellent food for great prices\nProcessing input query:  The best thing is , the prices are also quite reasonable .\nProcessing input query:  For a Fabulous Wedding !\nProcessing input query:  Very Disappointing\nProcessing input query:  â€“ It is sad to see a place that was once `` THE `` place to meet and eat for Bfast or Lunch , now be the place that is a big `` DONT BOTHER . ``\nProcessing input query:  In fact , many want to return a second time during their visit .\nProcessing input query:  There is only one place on the east coast that has it all , plus a lot more .\nProcessing input query:  She doesn 't make you feel welcome and treats you like an annoyance .\nProcessing input query:  The pizza itself is not exactly the best I 've had EVER , but still pretty good .\nProcessing input query:  It was n't as if this restaurant had any major bragging points before hand , but now it 's simply repulsive .\nProcessing input query:  The best Chuwam Mushi I have ever had .\nProcessing input query:  Amazing Spanish Mackeral special appetizer and perfect box sushi ( that eel with avodcao -- um um um ) .\nProcessing input query:  I came across Village Underground by accident , now I go there all the time .\nProcessing input query:  While this diner had reasonably good food , the restaurant staff seemed completely indifferent to our presence , and this attitude was reflected in the lack of service .\nProcessing input query:  A brief conversation with the manager at the end of the meal was the greatest disappointment -- to say we had been `` blown off `` would be an understatement .\n","output_type":"stream"}]},{"cell_type":"code","source":"df_sample.tail(3)","metadata":{"execution":{"iopub.status.busy":"2024-10-13T20:54:24.917798Z","iopub.execute_input":"2024-10-13T20:54:24.918212Z","iopub.status.idle":"2024-10-13T20:54:24.932635Z","shell.execute_reply.started":"2024-10-13T20:54:24.918176Z","shell.execute_reply":"2024-10-13T20:54:24.931521Z"},"trusted":true},"execution_count":51,"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"                                            input_text  \\\n124  I came across Village Underground by accident ...   \n899  While this diner had reasonably good food , th...   \n839  A brief conversation with the manager at the e...   \n\n                                            gold_quads  \\\n124  [{'opinion term': 'Village Underground', 'aspe...   \n899  [{'opinion term': 'food', 'aspect category': '...   \n839  [{'opinion term': 'manager', 'aspect category'...   \n\n                                  raw_model_completion  \n124  <|begin_of_text|>Below is a DOCUMENT in which ...  \n899  <|begin_of_text|>Below is a DOCUMENT in which ...  \n839  <|begin_of_text|>Below is a DOCUMENT in which ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>input_text</th>\n      <th>gold_quads</th>\n      <th>raw_model_completion</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>124</th>\n      <td>I came across Village Underground by accident ...</td>\n      <td>[{'opinion term': 'Village Underground', 'aspe...</td>\n      <td>&lt;|begin_of_text|&gt;Below is a DOCUMENT in which ...</td>\n    </tr>\n    <tr>\n      <th>899</th>\n      <td>While this diner had reasonably good food , th...</td>\n      <td>[{'opinion term': 'food', 'aspect category': '...</td>\n      <td>&lt;|begin_of_text|&gt;Below is a DOCUMENT in which ...</td>\n    </tr>\n    <tr>\n      <th>839</th>\n      <td>A brief conversation with the manager at the e...</td>\n      <td>[{'opinion term': 'manager', 'aspect category'...</td>\n      <td>&lt;|begin_of_text|&gt;Below is a DOCUMENT in which ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Export to JSON for later","metadata":{}},{"cell_type":"code","source":"with open('test_inference_75_samples.json', 'w') as file:\n    json.dump(df_sample.to_json(), file)","metadata":{"execution":{"iopub.status.busy":"2024-10-13T20:56:28.829092Z","iopub.execute_input":"2024-10-13T20:56:28.830376Z","iopub.status.idle":"2024-10-13T20:56:28.837779Z","shell.execute_reply.started":"2024-10-13T20:56:28.830322Z","shell.execute_reply":"2024-10-13T20:56:28.836798Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"markdown","source":"# Explore","metadata":{}},{"cell_type":"code","source":"df_sample","metadata":{"execution":{"iopub.status.busy":"2024-10-13T20:57:50.170407Z","iopub.execute_input":"2024-10-13T20:57:50.170851Z","iopub.status.idle":"2024-10-13T20:57:50.190903Z","shell.execute_reply.started":"2024-10-13T20:57:50.170792Z","shell.execute_reply":"2024-10-13T20:57:50.190000Z"},"trusted":true},"execution_count":53,"outputs":[{"execution_count":53,"output_type":"execute_result","data":{"text/plain":"                                            input_text  \\\n232  But $ 500 for a dinner for two that didn 't in...   \n62                                        Great food !   \n862  â€“ How to describe the best sushi in NYC : hmmm...   \n76   Servers are all different , Greg is my favorite .   \n966  The pancakes were certainly inventive but $ 8....   \n..                                                 ...   \n732            The best Chuwam Mushi I have ever had .   \n919  Amazing Spanish Mackeral special appetizer and...   \n124  I came across Village Underground by accident ...   \n899  While this diner had reasonably good food , th...   \n839  A brief conversation with the manager at the e...   \n\n                                            gold_quads  \\\n232  [{'opinion term': 'dinner for two', 'aspect ca...   \n62   [{'opinion term': 'food', 'aspect category': '...   \n862  [{'opinion term': 'sushi', 'aspect category': ...   \n76   [{'opinion term': 'Greg', 'aspect category': '...   \n966  [{'opinion term': 'pancakes', 'aspect category...   \n..                                                 ...   \n732  [{'opinion term': 'Chuwam Mushi', 'aspect cate...   \n919  [{'opinion term': 'Spanish Mackeral special ap...   \n124  [{'opinion term': 'Village Underground', 'aspe...   \n899  [{'opinion term': 'food', 'aspect category': '...   \n839  [{'opinion term': 'manager', 'aspect category'...   \n\n                                  raw_model_completion  \n232  <|begin_of_text|>Below is a DOCUMENT in which ...  \n62   <|begin_of_text|>Below is a DOCUMENT in which ...  \n862  <|begin_of_text|>Below is a DOCUMENT in which ...  \n76   <|begin_of_text|>Below is a DOCUMENT in which ...  \n966  <|begin_of_text|>Below is a DOCUMENT in which ...  \n..                                                 ...  \n732  <|begin_of_text|>Below is a DOCUMENT in which ...  \n919  <|begin_of_text|>Below is a DOCUMENT in which ...  \n124  <|begin_of_text|>Below is a DOCUMENT in which ...  \n899  <|begin_of_text|>Below is a DOCUMENT in which ...  \n839  <|begin_of_text|>Below is a DOCUMENT in which ...  \n\n[75 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>input_text</th>\n      <th>gold_quads</th>\n      <th>raw_model_completion</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>232</th>\n      <td>But $ 500 for a dinner for two that didn 't in...</td>\n      <td>[{'opinion term': 'dinner for two', 'aspect ca...</td>\n      <td>&lt;|begin_of_text|&gt;Below is a DOCUMENT in which ...</td>\n    </tr>\n    <tr>\n      <th>62</th>\n      <td>Great food !</td>\n      <td>[{'opinion term': 'food', 'aspect category': '...</td>\n      <td>&lt;|begin_of_text|&gt;Below is a DOCUMENT in which ...</td>\n    </tr>\n    <tr>\n      <th>862</th>\n      <td>â€“ How to describe the best sushi in NYC : hmmm...</td>\n      <td>[{'opinion term': 'sushi', 'aspect category': ...</td>\n      <td>&lt;|begin_of_text|&gt;Below is a DOCUMENT in which ...</td>\n    </tr>\n    <tr>\n      <th>76</th>\n      <td>Servers are all different , Greg is my favorite .</td>\n      <td>[{'opinion term': 'Greg', 'aspect category': '...</td>\n      <td>&lt;|begin_of_text|&gt;Below is a DOCUMENT in which ...</td>\n    </tr>\n    <tr>\n      <th>966</th>\n      <td>The pancakes were certainly inventive but $ 8....</td>\n      <td>[{'opinion term': 'pancakes', 'aspect category...</td>\n      <td>&lt;|begin_of_text|&gt;Below is a DOCUMENT in which ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>732</th>\n      <td>The best Chuwam Mushi I have ever had .</td>\n      <td>[{'opinion term': 'Chuwam Mushi', 'aspect cate...</td>\n      <td>&lt;|begin_of_text|&gt;Below is a DOCUMENT in which ...</td>\n    </tr>\n    <tr>\n      <th>919</th>\n      <td>Amazing Spanish Mackeral special appetizer and...</td>\n      <td>[{'opinion term': 'Spanish Mackeral special ap...</td>\n      <td>&lt;|begin_of_text|&gt;Below is a DOCUMENT in which ...</td>\n    </tr>\n    <tr>\n      <th>124</th>\n      <td>I came across Village Underground by accident ...</td>\n      <td>[{'opinion term': 'Village Underground', 'aspe...</td>\n      <td>&lt;|begin_of_text|&gt;Below is a DOCUMENT in which ...</td>\n    </tr>\n    <tr>\n      <th>899</th>\n      <td>While this diner had reasonably good food , th...</td>\n      <td>[{'opinion term': 'food', 'aspect category': '...</td>\n      <td>&lt;|begin_of_text|&gt;Below is a DOCUMENT in which ...</td>\n    </tr>\n    <tr>\n      <th>839</th>\n      <td>A brief conversation with the manager at the e...</td>\n      <td>[{'opinion term': 'manager', 'aspect category'...</td>\n      <td>&lt;|begin_of_text|&gt;Below is a DOCUMENT in which ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>75 rows Ã— 3 columns</p>\n</div>"},"metadata":{}}]}]}