{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Lab 1 of Data Centric AI course\n\n[https://github.com/dcai-course/dcai-lab/tree/master](https://github.com/dcai-course/dcai-lab/tree/master)\n\nAt the end of Lab 1, as a bonus it recommends to do a Transformer classification model of \"good and bad reviews\" from the magazine dataset that you study with basic ML techniques.\n\nYou are supposed to do 2 versions:\n\n1. train a model on \"as-is\" dataset\n2. train a model on the \"cleaned\" dataset: remove all reviews that contain HTML","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport transformers\nfrom transformers import AutoTokenizer, AutoModel\nfrom transformers import AutoModelForSequenceClassification\nfrom transformers import TrainingArguments, Trainer\nimport datasets\nfrom datasets import Dataset, DatasetDict, ClassLabel","metadata":{"execution":{"iopub.status.busy":"2024-06-09T13:58:16.980924Z","iopub.execute_input":"2024-06-09T13:58:16.981630Z","iopub.status.idle":"2024-06-09T13:58:35.568563Z","shell.execute_reply.started":"2024-06-09T13:58:16.981595Z","shell.execute_reply":"2024-06-09T13:58:35.567783Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-06-09 13:58:25.329272: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-09 13:58:25.329377: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-09 13:58:25.450691: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd","metadata":{"execution":{"iopub.status.busy":"2024-06-09T14:00:47.098407Z","iopub.execute_input":"2024-06-09T14:00:47.098765Z","iopub.status.idle":"2024-06-09T14:00:47.103248Z","shell.execute_reply.started":"2024-06-09T14:00:47.098737Z","shell.execute_reply":"2024-06-09T14:00:47.102196Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/reviews/reviews_train.csv')\ntest = pd.read_csv('/kaggle/input/reviews/reviews_test.csv')\n\ntrain.head(10)","metadata":{"execution":{"iopub.status.busy":"2024-06-09T14:02:40.124567Z","iopub.execute_input":"2024-06-09T14:02:40.125296Z","iopub.status.idle":"2024-06-09T14:02:40.185920Z","shell.execute_reply.started":"2024-06-09T14:02:40.125265Z","shell.execute_reply":"2024-06-09T14:02:40.184940Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"                                              review label\n0  Based on all the negative comments about Taste...  good\n1  I still have not received this.  Obviously I c...   bad\n2  </tr>The magazine is not worth the cost of sub...  good\n3  This magazine is basically ads. Kindve worthle...   bad\n4  The only thing I've recieved, so far, is the b...   bad\n5  The magazines are great, but I never received ...  good\n6  This is one magazine I really love. It has pri...  good\n7                                     Did not. Open.   bad\n8              Forever the best magazine!  Love it!!  good\n9  Very disappointed. It's nothing more than an a...   bad","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Based on all the negative comments about Taste...</td>\n      <td>good</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>I still have not received this.  Obviously I c...</td>\n      <td>bad</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>&lt;/tr&gt;The magazine is not worth the cost of sub...</td>\n      <td>good</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>This magazine is basically ads. Kindve worthle...</td>\n      <td>bad</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The only thing I've recieved, so far, is the b...</td>\n      <td>bad</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>The magazines are great, but I never received ...</td>\n      <td>good</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>This is one magazine I really love. It has pri...</td>\n      <td>good</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Did not. Open.</td>\n      <td>bad</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Forever the best magazine!  Love it!!</td>\n      <td>good</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Very disappointed. It's nothing more than an a...</td>\n      <td>bad</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# First model - trained on \"as-is\" dataset, include all reviews in training data","metadata":{}},{"cell_type":"code","source":"label_map = {\"bad\": 0, \"good\": 1}\ndataset_train = Dataset.from_dict({\"label\": train[\"label\"].map(label_map), \"text\": train[\"review\"].values})\ndataset_test = Dataset.from_dict({\"label\": test[\"label\"].map(label_map), \"text\": test[\"review\"].values})","metadata":{"execution":{"iopub.status.busy":"2024-06-09T14:03:29.440387Z","iopub.execute_input":"2024-06-09T14:03:29.441095Z","iopub.status.idle":"2024-06-09T14:03:29.486797Z","shell.execute_reply.started":"2024-06-09T14:03:29.441064Z","shell.execute_reply":"2024-06-09T14:03:29.485801Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"model_name = \"distilbert-base-uncased\"  # which pretrained neural network weights to load for fine-tuning on our data\n# other options you could try: \"bert-base-uncased\", \"bert-base-cased\", \"google/electra-small-discriminator\"\n\nmax_training_steps = 1000  # how many iterations our network will be trained for\n# Here set to a tiny value to ensure quick runtimes, set to higher values if you have a GPU to run this code on.\n\nmodel_folder = \"test_trainer\"  # file where model will be saved after training","metadata":{"execution":{"iopub.status.busy":"2024-06-09T14:06:15.568283Z","iopub.execute_input":"2024-06-09T14:06:15.568976Z","iopub.status.idle":"2024-06-09T14:06:15.573523Z","shell.execute_reply.started":"2024-06-09T14:06:15.568943Z","shell.execute_reply":"2024-06-09T14:06:15.572534Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_name)\n\ndef tokenize_function(examples):\n    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n\ntrain_tokenized_dataset = dataset_train.map(tokenize_function, batched=True)\ntrain_tokenized_dataset = train_tokenized_dataset.cast_column(\"label\", ClassLabel(names = [\"0\", \"1\"]))\n\ntest_tokenized_dataset = dataset_test.map(tokenize_function, batched=True)\ntest_tokenized_dataset = test_tokenized_dataset.cast_column(\"label\", ClassLabel(names = [\"0\", \"1\"]))\n\ntraining_args = TrainingArguments(max_steps=max_training_steps, output_dir=model_folder, report_to=\"none\")\nmodel = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_tokenized_dataset,\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-09T14:06:23.427946Z","iopub.execute_input":"2024-06-09T14:06:23.428635Z","iopub.status.idle":"2024-06-09T14:06:26.411967Z","shell.execute_reply.started":"2024-06-09T14:06:23.428601Z","shell.execute_reply":"2024-06-09T14:06:26.411015Z"},"trusted":true},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/6666 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00e5f46af3a44e20a0d6dda6cd405fbb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Casting the dataset:   0%|          | 0/6666 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a83bcf5ac2e45d3873933f2a0cfea81"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"779fd7e7be624db1852766a85e53d8f5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Casting the dataset:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c638f1381a504553ac704dbfa1b08922"}},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nmax_steps is given, it will override any value given in num_train_epochs\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-06-09T14:06:29.647590Z","iopub.execute_input":"2024-06-09T14:06:29.648370Z","iopub.status.idle":"2024-06-09T14:10:28.092547Z","shell.execute_reply.started":"2024-06-09T14:06:29.648324Z","shell.execute_reply":"2024-06-09T14:10:28.091574Z"},"trusted":true},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1000/1000 03:57, Epoch 1/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>0.251100</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.115200</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1000, training_loss=0.18315346145629882, metrics={'train_runtime': 237.893, 'train_samples_per_second': 33.629, 'train_steps_per_second': 4.204, 'total_flos': 1058944384856064.0, 'train_loss': 0.18315346145629882, 'epoch': 1.1990407673860912})"},"metadata":{}}]},{"cell_type":"code","source":"pred_probs = trainer.predict(test_tokenized_dataset).predictions\npred_classes = np.argmax(pred_probs, axis=1)\nprint(f\"Error rate of predictions: {np.mean(pred_classes != test_tokenized_dataset['label'])}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-09T14:12:11.559810Z","iopub.execute_input":"2024-06-09T14:12:11.560476Z","iopub.status.idle":"2024-06-09T14:12:21.305557Z","shell.execute_reply.started":"2024-06-09T14:12:11.560442Z","shell.execute_reply":"2024-06-09T14:12:21.304556Z"},"trusted":true},"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Error rate of predictions: 0.022\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Seems that Transformer model with 1000 steps is OK\n\nNot sure what benefit from removing the \"bad data\"\n\nWill try anyway:","metadata":{}},{"cell_type":"code","source":"def is_bad_data(review: str) -> bool:\n    if any(c in {'<', '>'} for c in review):\n        return True\n    return False","metadata":{"execution":{"iopub.status.busy":"2024-06-09T14:24:12.333848Z","iopub.execute_input":"2024-06-09T14:24:12.334826Z","iopub.status.idle":"2024-06-09T14:24:12.340604Z","shell.execute_reply.started":"2024-06-09T14:24:12.334785Z","shell.execute_reply":"2024-06-09T14:24:12.339397Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"train_clean = train[~train['review'].map(is_bad_data)]","metadata":{"execution":{"iopub.status.busy":"2024-06-09T14:25:30.415929Z","iopub.execute_input":"2024-06-09T14:25:30.416698Z","iopub.status.idle":"2024-06-09T14:25:30.462355Z","shell.execute_reply.started":"2024-06-09T14:25:30.416664Z","shell.execute_reply":"2024-06-09T14:25:30.461412Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"clean_dataset_train = Dataset.from_dict({\"label\": train_clean[\"label\"].map(label_map), \"text\": train_clean[\"review\"].values})\ndataset_test = Dataset.from_dict({\"label\": test[\"label\"].map(label_map), \"text\": test[\"review\"].values})","metadata":{"execution":{"iopub.status.busy":"2024-06-09T14:25:32.509855Z","iopub.execute_input":"2024-06-09T14:25:32.510711Z","iopub.status.idle":"2024-06-09T14:25:32.535232Z","shell.execute_reply.started":"2024-06-09T14:25:32.510675Z","shell.execute_reply":"2024-06-09T14:25:32.534281Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"clean_model_folder = \"clean_test_trainer\"","metadata":{"execution":{"iopub.status.busy":"2024-06-09T14:25:57.183476Z","iopub.execute_input":"2024-06-09T14:25:57.184100Z","iopub.status.idle":"2024-06-09T14:25:57.187979Z","shell.execute_reply.started":"2024-06-09T14:25:57.184068Z","shell.execute_reply":"2024-06-09T14:25:57.187076Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_name)\n\ndef tokenize_function(examples):\n    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n\n# HERE CHANGED: using \"cleaned\" dataset as the train dataset\ntrain_tokenized_dataset = clean_dataset_train.map(tokenize_function, batched=True)\ntrain_tokenized_dataset = train_tokenized_dataset.cast_column(\"label\", ClassLabel(names = [\"0\", \"1\"]))\n\ntest_tokenized_dataset = dataset_test.map(tokenize_function, batched=True)\ntest_tokenized_dataset = test_tokenized_dataset.cast_column(\"label\", ClassLabel(names = [\"0\", \"1\"]))\n\ntraining_args = TrainingArguments(max_steps=max_training_steps, output_dir=clean_model_folder, report_to=\"none\")\nmodel = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n\nclean_trainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_tokenized_dataset,\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-09T14:27:15.607178Z","iopub.execute_input":"2024-06-09T14:27:15.608375Z","iopub.status.idle":"2024-06-09T14:27:17.776801Z","shell.execute_reply.started":"2024-06-09T14:27:15.608325Z","shell.execute_reply":"2024-06-09T14:27:17.775715Z"},"trusted":true},"execution_count":28,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3998 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c4fabc6ecfe47bd9774bc1eeda51ffd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Casting the dataset:   0%|          | 0/3998 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f97993c728445e9a7fa214c8f8c3978"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"952914e6f0934906a109b181ac2739b3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Casting the dataset:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3089104ad30d4a9ca998e1e961e58e16"}},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nmax_steps is given, it will override any value given in num_train_epochs\n","output_type":"stream"}]},{"cell_type":"code","source":"clean_trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-06-09T14:27:22.855888Z","iopub.execute_input":"2024-06-09T14:27:22.856303Z","iopub.status.idle":"2024-06-09T14:31:17.991185Z","shell.execute_reply.started":"2024-06-09T14:27:22.856262Z","shell.execute_reply":"2024-06-09T14:31:17.990236Z"},"trusted":true},"execution_count":29,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1000/1000 03:54, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>0.168400</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.064700</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1000, training_loss=0.11655619430541993, metrics={'train_runtime': 234.5845, 'train_samples_per_second': 34.103, 'train_steps_per_second': 4.263, 'total_flos': 1059209319653376.0, 'train_loss': 0.11655619430541993, 'epoch': 2.0})"},"metadata":{}}]},{"cell_type":"code","source":"clean_pred_probs = clean_trainer.predict(test_tokenized_dataset).predictions\nclean_pred_classes = np.argmax(clean_pred_probs, axis=1)\nprint(f\"Error rate of predictions: {np.mean(clean_pred_classes != test_tokenized_dataset['label'])}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-09T14:31:19.236493Z","iopub.execute_input":"2024-06-09T14:31:19.237446Z","iopub.status.idle":"2024-06-09T14:31:28.930386Z","shell.execute_reply.started":"2024-06-09T14:31:19.237409Z","shell.execute_reply":"2024-06-09T14:31:28.929397Z"},"trusted":true},"execution_count":30,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Error rate of predictions: 0.027\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# So here error rate actually goes UP from 0.022 to 0.027","metadata":{}}]}