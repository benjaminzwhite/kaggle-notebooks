{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Qwen 3 testing","metadata":{}},{"cell_type":"code","source":"!pip install transformers==4.51.0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T21:49:56.975079Z","iopub.execute_input":"2025-04-28T21:49:56.975323Z","iopub.status.idle":"2025-04-28T21:50:09.602593Z","shell.execute_reply.started":"2025-04-28T21:49:56.975302Z","shell.execute_reply":"2025-04-28T21:50:09.601941Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Collecting transformers==4.51.0\n  Downloading transformers-4.51.0-py3-none-any.whl.metadata (38 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.0) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.0) (0.30.2)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.0) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.0) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.0) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.0) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.0) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.0) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.0) (0.5.2)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.0) (4.67.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.51.0) (2025.3.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.51.0) (4.13.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.51.0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.51.0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.51.0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.51.0) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.51.0) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.51.0) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.51.0) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.51.0) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.51.0) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.51.0) (2025.1.31)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers==4.51.0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers==4.51.0) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers==4.51.0) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers==4.51.0) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers==4.51.0) (2024.2.0)\nDownloading transformers-4.51.0-py3-none-any.whl (10.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m77.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m:01\u001b[0m\n\u001b[?25hInstalling collected packages: transformers\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.51.1\n    Uninstalling transformers-4.51.1:\n      Successfully uninstalled transformers-4.51.1\nSuccessfully installed transformers-4.51.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, AutoTokenizer\n\nmodel_name = \"Qwen/Qwen3-4B\"\n\n# load the tokenizer and the model\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    torch_dtype=\"auto\",\n    device_map=\"auto\"\n)\n\n# prepare the model input\nprompt = \"Give me a short introduction to large language model.\"\nmessages = [\n    {\"role\": \"user\", \"content\": prompt}\n]\ntext = tokenizer.apply_chat_template(\n    messages,\n    tokenize=False,\n    add_generation_prompt=True,\n    enable_thinking=True # Switches between thinking and non-thinking modes. Default is True.\n)\nmodel_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n\n# conduct text completion\ngenerated_ids = model.generate(\n    **model_inputs,\n    max_new_tokens=32768\n)\noutput_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist() \n\n# parsing thinking content\ntry:\n    # rindex finding 151668 (</think>)\n    index = len(output_ids) - output_ids[::-1].index(151668)\nexcept ValueError:\n    index = 0\n\nthinking_content = tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip(\"\\n\")\ncontent = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip(\"\\n\")\n\nprint(\"thinking content:\", thinking_content)\nprint(\"content:\", content)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T21:51:12.164157Z","iopub.execute_input":"2025-04-28T21:51:12.164781Z","iopub.status.idle":"2025-04-28T21:52:49.062732Z","shell.execute_reply.started":"2025-04-28T21:51:12.164754Z","shell.execute_reply":"2025-04-28T21:52:49.061931Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/9.68k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6eefb31541a44d4998ad3cf0694714b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"50e127a2bbf549be94009a26ff2aeeb4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4de2a87af4aa4ef08d3d957e41a578b7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e7359476767e44e187467495b45d538b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/726 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d547d5f850354c17acbcc074cecccc29"}},"metadata":{}},{"name":"stderr","text":"2025-04-28 21:51:26.911631: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1745877087.153738      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1745877087.219431      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/32.8k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b00d3e502a9b48c8bd2a471c90d9a88d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db6c9aa8aeab48488e6fa1775fc21f12"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00003.safetensors:   0%|          | 0.00/3.96G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"41b233052a894de28576e71e2270275d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00003.safetensors:   0%|          | 0.00/99.6M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff2887ccced4407f87517f4ec3cdba76"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00003.safetensors:   0%|          | 0.00/3.99G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d61b570d6e0b4e16bae97c1aac66d998"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f63f65d5c7c412fadd7f558d801e595"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/239 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"124e73ece417414c9f6e7d166f8fe98f"}},"metadata":{}},{"name":"stdout","text":"thinking content: <think>\nOkay, the user is asking for a short introduction to large language models. Let me start by recalling what I know about them. LLMs are a type of AI model that processes and generates human-like text. They're based on deep learning, specifically transformer architecture. I should mention their key components like neural networks and attention mechanisms.\n\nWait, the user might not be familiar with technical terms, so I need to explain it in simple terms. Maybe start by saying they're powerful AI systems that understand and create text. Then explain how they're trained on vast amounts of data, which allows them to generate coherent responses. \n\nI should highlight their applications, like answering questions, writing stories, coding, etc. Also, mention that they're used in various fields such as customer service, content creation, and more. But I need to keep it concise since the user asked for a short intro. \n\nDon't forget to note that they're developed by companies like OpenAI, Google, and others. Maybe add something about their ability to handle complex tasks and adapt to different contexts. Oh, and maybe touch on the fact that they're a big deal in AI research and have transformed natural language processing. \n\nWait, the user might be a student or someone new to AI, so avoiding jargon is key. Make sure the explanation is clear and not too technical. Also, ensure the introduction flows well from the basics to their uses and significance. Let me structure it step by step: definition, how they work, training data, applications, and their impact. Keep each part brief. Alright, that should cover it without being too long.\n</think>\ncontent: Large language models (LLMs) are advanced artificial intelligence systems designed to understand and generate human-like text. They are built using deep learning techniques, particularly the transformer architecture, which enables them to process vast amounts of data and recognize patterns in language. Trained on massive datasets, LLMs can answer questions, write stories, code, translate languages, and engage in complex conversations. Their ability to adapt to various tasks makes them invaluable in fields like customer service, content creation, and research. Powered by companies like OpenAI, Google, and Meta, LLMs represent a major breakthrough in natural language processing, revolutionizing how we interact with technology.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"## No thinking mode","metadata":{}},{"cell_type":"code","source":"text = tokenizer.apply_chat_template(\n    messages,\n    tokenize=False,\n    add_generation_prompt=True,\n    enable_thinking=False  # Setting enable_thinking=False disables thinking mode\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T21:54:24.408354Z","iopub.execute_input":"2025-04-28T21:54:24.408816Z","iopub.status.idle":"2025-04-28T21:54:24.413334Z","shell.execute_reply.started":"2025-04-28T21:54:24.408789Z","shell.execute_reply":"2025-04-28T21:54:24.412419Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n\n# conduct text completion\ngenerated_ids = model.generate(\n    **model_inputs,\n    max_new_tokens=32768,\n    temperature=0.7, # Qwen suggested Best practices\n    top_p=0.8,# Qwen suggested Best practices\n    top_k=20,# Qwen suggested Best practices\n    min_p=0,# Qwen suggested Best practices\n)\noutput_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist() \n\n# parsing thinking content\ntry:\n    # rindex finding 151668 (</think>)\n    index = len(output_ids) - output_ids[::-1].index(151668)\nexcept ValueError:\n    index = 0\n\nthinking_content = tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip(\"\\n\")\ncontent = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip(\"\\n\")\n\nprint(\"thinking content:\", thinking_content)\nprint(\"content:\", content)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T21:55:14.797103Z","iopub.execute_input":"2025-04-28T21:55:14.797378Z","iopub.status.idle":"2025-04-28T21:55:23.842151Z","shell.execute_reply.started":"2025-04-28T21:55:14.797355Z","shell.execute_reply":"2025-04-28T21:55:23.841358Z"}},"outputs":[{"name":"stdout","text":"thinking content: \ncontent: A large language model (LLM) is a type of artificial intelligence model that has been trained on vast amounts of text data to understand and generate human-like text. These models are capable of performing a wide range of tasks, such as answering questions, writing stories, coding, translating languages, and more. They are built using deep learning techniques and have a massive number of parameters, which allows them to capture complex patterns in language and context. LLMs have become increasingly powerful and are widely used in various applications, from customer service chatbots to content creation and research.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"# Extractive task test","metadata":{}},{"cell_type":"code","source":"SOURCE_DOC_2 = \"\"\"Yeah so I'm going with Bob Smith next week to work at Apple. You can contact me on 38-0441-1455, or drop me a message on fjupio@xmx.com.\n\nOK thanks, Max will be there as well but he's at KMB Construction these days so maybe he'll be late\n\"\"\"\n\nSOURCE_DOC_3 = \"\"\"Yeah so I'm going with Réné Borassé next week to work at Apple. You can contact me on 38-0441-1455, or drop me a message on fjupio@xmx.com.\n\nOK thanks, Max Orvàlerø will be there as well but he's at KMB Construction these days so maybe he'll be late\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T21:56:46.266654Z","iopub.execute_input":"2025-04-28T21:56:46.266962Z","iopub.status.idle":"2025-04-28T21:56:46.270736Z","shell.execute_reply.started":"2025-04-28T21:56:46.266940Z","shell.execute_reply":"2025-04-28T21:56:46.270197Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"prompt2 = f\"\"\"Extract all the personal data in the document below. Assign a label for each item. Only use labels in the allowed labels list below.\n\n## allowed labels\n\n- person\n- organization\n- telephone number\n- email address\n\n## document\n\n{SOURCE_DOC_2}\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T21:59:00.887875Z","iopub.execute_input":"2025-04-28T21:59:00.888170Z","iopub.status.idle":"2025-04-28T21:59:00.892053Z","shell.execute_reply.started":"2025-04-28T21:59:00.888149Z","shell.execute_reply":"2025-04-28T21:59:00.891258Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"messages2 = [\n    {\"role\": \"system\", \"content\": \"You are a personal data extraction expert.\"},\n    {\"role\": \"user\", \"content\": prompt2}\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T21:59:06.837143Z","iopub.execute_input":"2025-04-28T21:59:06.837680Z","iopub.status.idle":"2025-04-28T21:59:06.841142Z","shell.execute_reply.started":"2025-04-28T21:59:06.837651Z","shell.execute_reply":"2025-04-28T21:59:06.840517Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"text2 = tokenizer.apply_chat_template(\n    messages2,\n    tokenize=False,\n    add_generation_prompt=True,\n    enable_thinking=True  # Setting enable_thinking=False disables thinking mode\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T21:59:31.567541Z","iopub.execute_input":"2025-04-28T21:59:31.568121Z","iopub.status.idle":"2025-04-28T21:59:31.571910Z","shell.execute_reply.started":"2025-04-28T21:59:31.568099Z","shell.execute_reply":"2025-04-28T21:59:31.571142Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"model_inputs2 = tokenizer([text2], return_tensors=\"pt\").to(model.device)\n\n# conduct text completion\ngenerated_ids2 = model.generate(\n    **model_inputs2,\n    max_new_tokens=32768,\n    temperature=0.6, # Qwen suggested Best practices\n    top_p=0.95,# Qwen suggested Best practices\n    top_k=20,# Qwen suggested Best practices\n    min_p=0,# Qwen suggested Best practices\n)\noutput_ids2 = generated_ids2[0][len(model_inputs2.input_ids[0]):].tolist() \n\n# parsing thinking content\ntry:\n    # rindex finding 151668 (</think>)\n    index2 = len(output_ids2) - output_ids2[::-1].index(151668)\nexcept ValueError:\n    index2 = 0\n\nthinking_content2 = tokenizer.decode(output_ids2[:index2], skip_special_tokens=True).strip(\"\\n\")\ncontent2 = tokenizer.decode(output_ids2[index2:], skip_special_tokens=True).strip(\"\\n\")\n\nprint(\"thinking content:\", thinking_content2)\nprint(\"content:\", content2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T22:00:47.491376Z","iopub.execute_input":"2025-04-28T22:00:47.491980Z","iopub.status.idle":"2025-04-28T22:01:23.908313Z","shell.execute_reply.started":"2025-04-28T22:00:47.491957Z","shell.execute_reply":"2025-04-28T22:01:23.907512Z"}},"outputs":[{"name":"stdout","text":"thinking content: <think>\nOkay, let's tackle this. The user wants me to extract personal data from the given document and assign labels from the allowed list. The allowed labels are person, organization, telephone number, and email address.\n\nFirst, I'll read through the document carefully. The first sentence says, \"Yeah so I'm going with Bob Smith next week to work at Apple.\" Here, \"Bob Smith\" is a person's name, so that's a person label. \"Apple\" is an organization, right? Because it's a company name.\n\nNext part: \"You can contact me on 38-0441-1455, or drop me a message on fjupio@xmx.com.\" The phone number is 38-0441-1455, which is a telephone number. The email is fjupio@xmx.com, so that's an email address.\n\nThen the next sentence: \"OK thanks, Max will be there as well but he's at KMB Construction these days so maybe he'll be late.\" \"Max\" is another person. \"KMB Construction\" is an organization since it's a company name.\n\nWait, need to make sure I'm not missing any. Let me check again. The document mentions Bob Smith, Max, Apple, KMB Construction, the phone number, and the email. No other names or numbers. So the labels should be:\n\n- Bob Smith: person\n- Apple: organization\n- 38-0441-1455: telephone number\n- fjupio@xmx.com: email address\n- Max: person\n- KMB Construction: organization\n\nBut the user said to assign labels to each item. So each of these should be listed with their respective labels. Let me make sure I didn't miss any. The phone number and email are clearly there. The organizations are Apple and KMB Construction. The people are Bob Smith and Max. That's all. I think that's it.\n</think>\ncontent: - **Bob Smith**: person  \n- **Apple**: organization  \n- **38-0441-1455**: telephone number  \n- **fjupio@xmx.com**: email address  \n- **Max**: person  \n- **KMB Construction**: organization\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"#### Same without thinking mode","metadata":{}},{"cell_type":"code","source":"text3 = tokenizer.apply_chat_template(\n    messages2,\n    tokenize=False,\n    add_generation_prompt=True,\n    enable_thinking=False  # Setting enable_thinking=False disables thinking mode\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T22:02:29.402428Z","iopub.execute_input":"2025-04-28T22:02:29.402747Z","iopub.status.idle":"2025-04-28T22:02:29.407392Z","shell.execute_reply.started":"2025-04-28T22:02:29.402725Z","shell.execute_reply":"2025-04-28T22:02:29.406547Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"model_inputs = tokenizer([text3], return_tensors=\"pt\").to(model.device)\n\n# conduct text completion\ngenerated_ids = model.generate(\n    **model_inputs,\n    max_new_tokens=32768,\n    temperature=0.7, # Qwen suggested Best practices\n    top_p=0.8,# Qwen suggested Best practices\n    top_k=20,# Qwen suggested Best practices\n    min_p=0,# Qwen suggested Best practices\n)\noutput_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist() \n\n# parsing thinking content\ntry:\n    # rindex finding 151668 (</think>)\n    index = len(output_ids) - output_ids[::-1].index(151668)\nexcept ValueError:\n    index = 0\n\nthinking_content = tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip(\"\\n\")\ncontent = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip(\"\\n\")\n\nprint(\"thinking content:\", thinking_content)\nprint(\"content:\", content)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T22:03:10.679005Z","iopub.execute_input":"2025-04-28T22:03:10.679261Z","iopub.status.idle":"2025-04-28T22:03:14.965439Z","shell.execute_reply.started":"2025-04-28T22:03:10.679244Z","shell.execute_reply":"2025-04-28T22:03:14.964813Z"}},"outputs":[{"name":"stdout","text":"thinking content: \ncontent: - Bob Smith - person\n- Apple - organization\n- 38-0441-1455 - telephone number\n- fjupio@xmx.com - email address\n- KMB Construction - organization\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"## Same but ask for JSON in prompt only","metadata":{}},{"cell_type":"code","source":"prompt3 = f\"\"\"Extract all the personal data in the document below. Assign a label for each item. Only use labels in the allowed labels list below.\n\nReturn your example as a valid JSON object.\n\n## allowed labels\n\n- person\n- organization\n- telephone number\n- email address\n\n## document\n\n{SOURCE_DOC_2}\n\"\"\"\n\nmessages3 = [\n    {\"role\": \"system\", \"content\": \"You are a personal data extraction expert.\"},\n    {\"role\": \"user\", \"content\": prompt3}\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T22:05:36.194231Z","iopub.execute_input":"2025-04-28T22:05:36.194529Z","iopub.status.idle":"2025-04-28T22:05:36.199438Z","shell.execute_reply.started":"2025-04-28T22:05:36.194506Z","shell.execute_reply":"2025-04-28T22:05:36.198530Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"text4 = tokenizer.apply_chat_template(\n    messages3,\n    tokenize=False,\n    add_generation_prompt=True,\n    enable_thinking=False  # Setting enable_thinking=False disables thinking mode\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T22:05:55.374317Z","iopub.execute_input":"2025-04-28T22:05:55.374769Z","iopub.status.idle":"2025-04-28T22:05:55.378726Z","shell.execute_reply.started":"2025-04-28T22:05:55.374746Z","shell.execute_reply":"2025-04-28T22:05:55.378061Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"model_inputs = tokenizer([text4], return_tensors=\"pt\").to(model.device)\n\n# conduct text completion\ngenerated_ids = model.generate(\n    **model_inputs,\n    max_new_tokens=32768,\n    temperature=0.7, # Qwen suggested Best practices\n    top_p=0.8,# Qwen suggested Best practices\n    top_k=20,# Qwen suggested Best practices\n    min_p=0,# Qwen suggested Best practices\n)\noutput_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist() \n\n# parsing thinking content\ntry:\n    # rindex finding 151668 (</think>)\n    index = len(output_ids) - output_ids[::-1].index(151668)\nexcept ValueError:\n    index = 0\n\nthinking_content = tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip(\"\\n\")\ncontent = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip(\"\\n\")\n\nprint(\"thinking content:\", thinking_content)\nprint(\"content:\", content)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T22:05:59.449621Z","iopub.execute_input":"2025-04-28T22:05:59.449915Z","iopub.status.idle":"2025-04-28T22:06:10.712193Z","shell.execute_reply.started":"2025-04-28T22:05:59.449862Z","shell.execute_reply":"2025-04-28T22:06:10.711417Z"}},"outputs":[{"name":"stdout","text":"thinking content: \ncontent: {\n  \"personal_data\": [\n    {\n      \"label\": \"person\",\n      \"value\": \"Bob Smith\"\n    },\n    {\n      \"label\": \"organization\",\n      \"value\": \"Apple\"\n    },\n    {\n      \"label\": \"telephone number\",\n      \"value\": \"38-0441-1455\"\n    },\n    {\n      \"label\": \"email address\",\n      \"value\": \"fjupio@xmx.com\"\n    },\n    {\n      \"label\": \"person\",\n      \"value\": \"Max\"\n    },\n    {\n      \"label\": \"organization\",\n      \"value\": \"KMB Construction\"\n    }\n  ]\n}\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"# Test load JSON\n\n- looks good O_o//","metadata":{}},{"cell_type":"code","source":"import json\n\ntest_json = json.loads(content)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T22:06:51.985402Z","iopub.execute_input":"2025-04-28T22:06:51.985687Z","iopub.status.idle":"2025-04-28T22:06:51.989194Z","shell.execute_reply.started":"2025-04-28T22:06:51.985665Z","shell.execute_reply":"2025-04-28T22:06:51.988499Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"print(type(test_json))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T22:06:58.857245Z","iopub.execute_input":"2025-04-28T22:06:58.857805Z","iopub.status.idle":"2025-04-28T22:06:58.861932Z","shell.execute_reply.started":"2025-04-28T22:06:58.857779Z","shell.execute_reply":"2025-04-28T22:06:58.861174Z"}},"outputs":[{"name":"stdout","text":"<class 'dict'>\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"print(test_json.keys())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T22:07:07.426229Z","iopub.execute_input":"2025-04-28T22:07:07.426791Z","iopub.status.idle":"2025-04-28T22:07:07.430702Z","shell.execute_reply.started":"2025-04-28T22:07:07.426768Z","shell.execute_reply":"2025-04-28T22:07:07.429934Z"}},"outputs":[{"name":"stdout","text":"dict_keys(['personal_data'])\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"print(test_json)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T22:07:13.975125Z","iopub.execute_input":"2025-04-28T22:07:13.975844Z","iopub.status.idle":"2025-04-28T22:07:13.979237Z","shell.execute_reply.started":"2025-04-28T22:07:13.975821Z","shell.execute_reply":"2025-04-28T22:07:13.978583Z"}},"outputs":[{"name":"stdout","text":"{'personal_data': [{'label': 'person', 'value': 'Bob Smith'}, {'label': 'organization', 'value': 'Apple'}, {'label': 'telephone number', 'value': '38-0441-1455'}, {'label': 'email address', 'value': 'fjupio@xmx.com'}, {'label': 'person', 'value': 'Max'}, {'label': 'organization', 'value': 'KMB Construction'}]}\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"for d in test_json[\"personal_data\"]:\n    print(d[\"value\"], \"-->\", d[\"label\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T22:08:21.589609Z","iopub.execute_input":"2025-04-28T22:08:21.590327Z","iopub.status.idle":"2025-04-28T22:08:21.594240Z","shell.execute_reply.started":"2025-04-28T22:08:21.590302Z","shell.execute_reply":"2025-04-28T22:08:21.593707Z"}},"outputs":[{"name":"stdout","text":"Bob Smith --> person\nApple --> organization\n38-0441-1455 --> telephone number\nfjupio@xmx.com --> email address\nMax --> person\nKMB Construction --> organization\n","output_type":"stream"}],"execution_count":22},{"cell_type":"markdown","source":"# Repeat with example with accents and weird names","metadata":{}},{"cell_type":"code","source":"prompt11 = f\"\"\"Extract all the personal data in the document below. Assign a label for each item. Only use labels in the allowed labels list below.\n\nReturn your example as a valid JSON object.\n\n## allowed labels\n\n- person\n- organization\n- telephone number\n- email address\n\n## document\n\n{SOURCE_DOC_3}\n\"\"\"\n# *******\n# HERE CHANGED TO DOC 3 WITH ACCENTS\n#\n\nmessages11 = [\n    {\"role\": \"system\", \"content\": \"You are a personal data extraction expert.\"},\n    {\"role\": \"user\", \"content\": prompt11}\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T22:09:18.193470Z","iopub.execute_input":"2025-04-28T22:09:18.194171Z","iopub.status.idle":"2025-04-28T22:09:18.197959Z","shell.execute_reply.started":"2025-04-28T22:09:18.194148Z","shell.execute_reply":"2025-04-28T22:09:18.197116Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"text11 = tokenizer.apply_chat_template(\n    messages11,\n    tokenize=False,\n    add_generation_prompt=True,\n    enable_thinking=False  # Setting enable_thinking=False disables thinking mode\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T22:09:59.150981Z","iopub.execute_input":"2025-04-28T22:09:59.151671Z","iopub.status.idle":"2025-04-28T22:09:59.155603Z","shell.execute_reply.started":"2025-04-28T22:09:59.151650Z","shell.execute_reply":"2025-04-28T22:09:59.155050Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"model_inputs = tokenizer([text11], return_tensors=\"pt\").to(model.device)\n\n# conduct text completion\ngenerated_ids = model.generate(\n    **model_inputs,\n    max_new_tokens=32768,\n    temperature=0.7, # Qwen suggested Best practices\n    top_p=0.8,# Qwen suggested Best practices\n    top_k=20,# Qwen suggested Best practices\n    min_p=0,# Qwen suggested Best practices\n)\noutput_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist() \n\n# parsing thinking content\ntry:\n    # rindex finding 151668 (</think>)\n    index = len(output_ids) - output_ids[::-1].index(151668)\nexcept ValueError:\n    index = 0\n\nthinking_content = tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip(\"\\n\")\ncontent = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip(\"\\n\")\n\nprint(\"thinking content:\", thinking_content)\nprint(\"content:\", content)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T22:12:47.039086Z","iopub.execute_input":"2025-04-28T22:12:47.039630Z","iopub.status.idle":"2025-04-28T22:12:53.464848Z","shell.execute_reply.started":"2025-04-28T22:12:47.039611Z","shell.execute_reply":"2025-04-28T22:12:53.464231Z"}},"outputs":[{"name":"stdout","text":"thinking content: \ncontent: {\n  \"person\": \"Réné Borassé\",\n  \"organization\": \"Apple\",\n  \"telephone number\": \"38-0441-1455\",\n  \"email address\": \"fjupio@xmx.com\",\n  \"person\": \"Max Orvàlerø\",\n  \"organization\": \"KMB Construction\"\n}\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"print(content)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T22:13:00.806231Z","iopub.execute_input":"2025-04-28T22:13:00.806848Z","iopub.status.idle":"2025-04-28T22:13:00.810448Z","shell.execute_reply.started":"2025-04-28T22:13:00.806827Z","shell.execute_reply":"2025-04-28T22:13:00.809911Z"}},"outputs":[{"name":"stdout","text":"{\n  \"person\": \"Réné Borassé\",\n  \"organization\": \"Apple\",\n  \"telephone number\": \"38-0441-1455\",\n  \"email address\": \"fjupio@xmx.com\",\n  \"person\": \"Max Orvàlerø\",\n  \"organization\": \"KMB Construction\"\n}\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"test_json = json.loads(content)\n\nprint(SOURCE_DOC_3)\nprint(\"===\")\n\nfor d in test_json[\"personal_data\"]:\n    print(d[\"value\"], \"-->\", d[\"label\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T22:10:37.395845Z","iopub.execute_input":"2025-04-28T22:10:37.396529Z","iopub.status.idle":"2025-04-28T22:10:37.416249Z","shell.execute_reply.started":"2025-04-28T22:10:37.396507Z","shell.execute_reply":"2025-04-28T22:10:37.415209Z"}},"outputs":[{"name":"stdout","text":"Yeah so I'm going with Réné Borassé next week to work at Apple. You can contact me on 38-0441-1455, or drop me a message on fjupio@xmx.com.\n\nOK thanks, Max Orvàlerø will be there as well but he's at KMB Construction these days so maybe he'll be late\n\n===\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_31/1165344123.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"===\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_json\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"personal_data\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"-->\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'personal_data'"],"ename":"KeyError","evalue":"'personal_data'","output_type":"error"}],"execution_count":26},{"cell_type":"markdown","source":"#### Prompt isn't specific so JSON schema changes a bit\n\n- ok, just need to do structured generation or specify schema","metadata":{}},{"cell_type":"markdown","source":"# UPDATE : bug due to keys values\n\n- JSON has TAGS as keys, so when you convert to JSON it will not return ALL THE ENTITIES but only one of each\n- need to prompt to have ENTITIES:TAGS rather than TAGS:ENTITIES","metadata":{}},{"cell_type":"code","source":"test_json = json.loads(content)\n\nprint(test_json)\n\nprint(SOURCE_DOC_3)\nprint(\"===\")\n\nfor k,v in test_json.items():\n    print(v, \"-->\", k)\n\nprint(test_json)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T22:13:17.907272Z","iopub.execute_input":"2025-04-28T22:13:17.907955Z","iopub.status.idle":"2025-04-28T22:13:17.913506Z","shell.execute_reply.started":"2025-04-28T22:13:17.907925Z","shell.execute_reply":"2025-04-28T22:13:17.912699Z"}},"outputs":[{"name":"stdout","text":"{'person': 'Max Orvàlerø', 'organization': 'KMB Construction', 'telephone number': '38-0441-1455', 'email address': 'fjupio@xmx.com'}\nYeah so I'm going with Réné Borassé next week to work at Apple. You can contact me on 38-0441-1455, or drop me a message on fjupio@xmx.com.\n\nOK thanks, Max Orvàlerø will be there as well but he's at KMB Construction these days so maybe he'll be late\n\n===\nMax Orvàlerø --> person\nKMB Construction --> organization\n38-0441-1455 --> telephone number\nfjupio@xmx.com --> email address\n{'person': 'Max Orvàlerø', 'organization': 'KMB Construction', 'telephone number': '38-0441-1455', 'email address': 'fjupio@xmx.com'}\n","output_type":"stream"}],"execution_count":31},{"cell_type":"markdown","source":"# Prompt fix","metadata":{}},{"cell_type":"code","source":"prompt22 = f\"\"\"Extract all the personal data in the document below. Assign a label for each item. Only use labels in the allowed labels list below.\n\nReturn your example as a valid JSON object. Following the example schema below without deviation:\n\n{{\n    \"John Smith\": \"person\",\n    \"Apple Inc.\": \"organization\",\n    \"Bob Franklin\": \"person\"\n}}\n\n## allowed labels\n\n- person\n- organization\n- telephone number\n- email address\n\n## document\n\n{SOURCE_DOC_3}\n\"\"\"\n# *******\n# HERE CHANGED TO DOC 3 WITH ACCENTS\n#\n\nmessages22 = [\n    {\"role\": \"system\", \"content\": \"You are a personal data extraction expert.\"},\n    {\"role\": \"user\", \"content\": prompt22}\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T22:17:02.808294Z","iopub.execute_input":"2025-04-28T22:17:02.808746Z","iopub.status.idle":"2025-04-28T22:17:02.812576Z","shell.execute_reply.started":"2025-04-28T22:17:02.808723Z","shell.execute_reply":"2025-04-28T22:17:02.811873Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"print(prompt22)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T22:17:09.831091Z","iopub.execute_input":"2025-04-28T22:17:09.831798Z","iopub.status.idle":"2025-04-28T22:17:09.835465Z","shell.execute_reply.started":"2025-04-28T22:17:09.831774Z","shell.execute_reply":"2025-04-28T22:17:09.834781Z"}},"outputs":[{"name":"stdout","text":"Extract all the personal data in the document below. Assign a label for each item. Only use labels in the allowed labels list below.\n\nReturn your example as a valid JSON object. Following the example schema below without deviation:\n\n{\n    \"John Smith\": \"person\",\n    \"Apple Inc.\": \"organization\",\n    \"Bob Franklin\": \"person\"\n}\n\n## allowed labels\n\n- person\n- organization\n- telephone number\n- email address\n\n## document\n\nYeah so I'm going with Réné Borassé next week to work at Apple. You can contact me on 38-0441-1455, or drop me a message on fjupio@xmx.com.\n\nOK thanks, Max Orvàlerø will be there as well but he's at KMB Construction these days so maybe he'll be late\n\n\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"text22 = tokenizer.apply_chat_template(\n    messages22,\n    tokenize=False,\n    add_generation_prompt=True,\n    enable_thinking=False  # Setting enable_thinking=False disables thinking mode\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T22:17:27.691948Z","iopub.execute_input":"2025-04-28T22:17:27.692655Z","iopub.status.idle":"2025-04-28T22:17:27.696772Z","shell.execute_reply.started":"2025-04-28T22:17:27.692627Z","shell.execute_reply":"2025-04-28T22:17:27.696060Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"model_inputs = tokenizer([text22], return_tensors=\"pt\").to(model.device)\n\n# conduct text completion\ngenerated_ids = model.generate(\n    **model_inputs,\n    max_new_tokens=32768,\n    temperature=0.7, # Qwen suggested Best practices\n    top_p=0.8,# Qwen suggested Best practices\n    top_k=20,# Qwen suggested Best practices\n    min_p=0,# Qwen suggested Best practices\n)\noutput_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist() \n\n# parsing thinking content\ntry:\n    # rindex finding 151668 (</think>)\n    index = len(output_ids) - output_ids[::-1].index(151668)\nexcept ValueError:\n    index = 0\n\nthinking_content = tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip(\"\\n\")\ncontent = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip(\"\\n\")\n\nprint(\"thinking content:\", thinking_content)\nprint(\"content:\", content)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T22:17:43.272510Z","iopub.execute_input":"2025-04-28T22:17:43.272793Z","iopub.status.idle":"2025-04-28T22:17:49.845487Z","shell.execute_reply.started":"2025-04-28T22:17:43.272770Z","shell.execute_reply":"2025-04-28T22:17:49.844904Z"}},"outputs":[{"name":"stdout","text":"thinking content: \ncontent: {\n    \"Réné Borassé\": \"person\",\n    \"Apple\": \"organization\",\n    \"38-0441-1455\": \"telephone number\",\n    \"fjupio@xmx.com\": \"email address\",\n    \"Max Orvàlerø\": \"person\",\n    \"KMB Construction\": \"organization\"\n}\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"test_json = json.loads(content)\n\n\nprint(SOURCE_DOC_3)\nprint(\"===\")\n\nprint(test_json)\nprint(\"===\")\n\nfor k,v in test_json.items():\n    print(v, \"-->\", k)\n\nprint(\"===\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T22:18:56.013579Z","iopub.execute_input":"2025-04-28T22:18:56.014160Z","iopub.status.idle":"2025-04-28T22:18:56.018645Z","shell.execute_reply.started":"2025-04-28T22:18:56.014137Z","shell.execute_reply":"2025-04-28T22:18:56.017851Z"}},"outputs":[{"name":"stdout","text":"Yeah so I'm going with Réné Borassé next week to work at Apple. You can contact me on 38-0441-1455, or drop me a message on fjupio@xmx.com.\n\nOK thanks, Max Orvàlerø will be there as well but he's at KMB Construction these days so maybe he'll be late\n\n===\n{'Réné Borassé': 'person', 'Apple': 'organization', '38-0441-1455': 'telephone number', 'fjupio@xmx.com': 'email address', 'Max Orvàlerø': 'person', 'KMB Construction': 'organization'}\n===\nperson --> Réné Borassé\norganization --> Apple\ntelephone number --> 38-0441-1455\nemail address --> fjupio@xmx.com\nperson --> Max Orvàlerø\norganization --> KMB Construction\n===\n","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}