{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Natural Language Processing with Transformers\n\nChapter 4 - Multilingual Named Entity Recognition\n\nWe finetune a XLM-RoBERTa model to perform NER","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-13T06:26:07.394493Z","iopub.execute_input":"2024-02-13T06:26:07.395195Z","iopub.status.idle":"2024-02-13T06:26:07.801970Z","shell.execute_reply.started":"2024-02-13T06:26:07.395154Z","shell.execute_reply":"2024-02-13T06:26:07.800927Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Dataset has LOC, PER, ORG in IOB2 format\n\nfrom datasets import get_dataset_config_names\n\nxtreme_subsets = get_dataset_config_names(\"xtreme\")\n\nprint(f\"XTREME has {len(xtreme_subsets)} configurations\")","metadata":{"execution":{"iopub.status.busy":"2024-02-13T06:26:07.804010Z","iopub.execute_input":"2024-02-13T06:26:07.804856Z","iopub.status.idle":"2024-02-13T06:26:09.893358Z","shell.execute_reply.started":"2024-02-13T06:26:07.804819Z","shell.execute_reply":"2024-02-13T06:26:09.892291Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/9.09k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a0431c5243847b1b2c35cf82882ede8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading metadata:   0%|          | 0.00/23.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e2f87f80d60a4fb3b15f65eca3ca141a"}},"metadata":{}},{"name":"stdout","text":"XTREME has 183 configurations\n","output_type":"stream"}]},{"cell_type":"code","source":"panx_subsets = [s for s in xtreme_subsets if s.startswith(\"PAN\")]\n\npanx_subsets[:5]","metadata":{"execution":{"iopub.status.busy":"2024-02-13T06:26:09.894756Z","iopub.execute_input":"2024-02-13T06:26:09.895358Z","iopub.status.idle":"2024-02-13T06:26:09.903225Z","shell.execute_reply.started":"2024-02-13T06:26:09.895328Z","shell.execute_reply":"2024-02-13T06:26:09.902173Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"['PAN-X.af', 'PAN-X.ar', 'PAN-X.bg', 'PAN-X.bn', 'PAN-X.de']"},"metadata":{}}]},{"cell_type":"code","source":"# We will make a \"Swiss\" corpus based on DE IT and FR and some English also\nfrom collections import defaultdict\nfrom datasets import DatasetDict, load_dataset \n\nlangs = [\"de\", \"fr\", \"it\", \"en\"]\nfracs = [0.629, 0.229, 0.084, 0.059]\n\n# Return a DatasetDict if a key doesn't exist\npanx_ch = defaultdict(DatasetDict)\n\nfor lang, frac in zip(langs, fracs):\n    # single language dataset\n    ds = load_dataset(\"xtreme\", name=f\"PAN-X.{lang}\")\n    # shuffle then take a fraction corresponding to required total frac in corpus\n    for split in ds:\n        panx_ch[lang][split] = (\n        ds[split]\n        .shuffle(seed=0)\n        .select(range(int(frac * ds[split].num_rows))))\n        \npd.DataFrame({lang: [panx_ch[lang][\"train\"].num_rows] for lang in langs}, index=[\"Number of training examples\"])","metadata":{"execution":{"iopub.status.busy":"2024-02-13T06:26:09.905546Z","iopub.execute_input":"2024-02-13T06:26:09.905866Z","iopub.status.idle":"2024-02-13T06:26:51.027890Z","shell.execute_reply.started":"2024-02-13T06:26:09.905839Z","shell.execute_reply":"2024-02-13T06:26:51.026865Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Downloading and preparing dataset xtreme/PAN-X.de (download: 223.17 MiB, generated: 9.08 MiB, post-processed: Unknown size, total: 232.25 MiB) to /root/.cache/huggingface/datasets/xtreme/PAN-X.de/1.0.0/349258adc25bb45e47de193222f95e68a44f7a7ab53c4283b3f007208a11bf7e...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/234M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a87e4e0fa8294d758510edaf5c0a67b6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/20000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset xtreme downloaded and prepared to /root/.cache/huggingface/datasets/xtreme/PAN-X.de/1.0.0/349258adc25bb45e47de193222f95e68a44f7a7ab53c4283b3f007208a11bf7e. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b19ee28840d94675a727c36c912f85aa"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset xtreme/PAN-X.fr (download: 223.17 MiB, generated: 6.37 MiB, post-processed: Unknown size, total: 229.53 MiB) to /root/.cache/huggingface/datasets/xtreme/PAN-X.fr/1.0.0/349258adc25bb45e47de193222f95e68a44f7a7ab53c4283b3f007208a11bf7e...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/20000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset xtreme downloaded and prepared to /root/.cache/huggingface/datasets/xtreme/PAN-X.fr/1.0.0/349258adc25bb45e47de193222f95e68a44f7a7ab53c4283b3f007208a11bf7e. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de39b11fd9974b76a282c03482b7bdab"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset xtreme/PAN-X.it (download: 223.17 MiB, generated: 7.35 MiB, post-processed: Unknown size, total: 230.52 MiB) to /root/.cache/huggingface/datasets/xtreme/PAN-X.it/1.0.0/349258adc25bb45e47de193222f95e68a44f7a7ab53c4283b3f007208a11bf7e...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/20000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset xtreme downloaded and prepared to /root/.cache/huggingface/datasets/xtreme/PAN-X.it/1.0.0/349258adc25bb45e47de193222f95e68a44f7a7ab53c4283b3f007208a11bf7e. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b2a0d2978d241129a9d4ed79a18b9eb"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset xtreme/PAN-X.en (download: 223.17 MiB, generated: 7.30 MiB, post-processed: Unknown size, total: 230.47 MiB) to /root/.cache/huggingface/datasets/xtreme/PAN-X.en/1.0.0/349258adc25bb45e47de193222f95e68a44f7a7ab53c4283b3f007208a11bf7e...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/20000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset xtreme downloaded and prepared to /root/.cache/huggingface/datasets/xtreme/PAN-X.en/1.0.0/349258adc25bb45e47de193222f95e68a44f7a7ab53c4283b3f007208a11bf7e. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"80ba7e65c83b4220b9bb09a913f00f91"}},"metadata":{}},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                de    fr    it    en\nNumber of training examples  12580  4580  1680  1180","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>de</th>\n      <th>fr</th>\n      <th>it</th>\n      <th>en</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Number of training examples</th>\n      <td>12580</td>\n      <td>4580</td>\n      <td>1680</td>\n      <td>1180</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# we have more DE than other langs, we will use it as startpoint for the transfer learning\nprint(panx_ch[\"de\"][\"train\"][0])","metadata":{"execution":{"iopub.status.busy":"2024-02-13T06:26:51.029175Z","iopub.execute_input":"2024-02-13T06:26:51.029486Z","iopub.status.idle":"2024-02-13T06:26:51.037474Z","shell.execute_reply.started":"2024-02-13T06:26:51.029459Z","shell.execute_reply":"2024-02-13T06:26:51.035811Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"{'tokens': ['2.000', 'Einwohnern', 'an', 'der', 'Danziger', 'Bucht', 'in', 'der', 'polnischen', 'Woiwodschaft', 'Pommern', '.'], 'ner_tags': [0, 0, 0, 0, 5, 6, 0, 0, 5, 5, 6, 0], 'langs': ['de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de']}\n","output_type":"stream"}]},{"cell_type":"code","source":"# what do the ner_tags actually correspond to - get from .features\nreference_tags = panx_ch[\"de\"][\"train\"].features[\"ner_tags\"].feature\nprint(reference_tags)","metadata":{"execution":{"iopub.status.busy":"2024-02-13T06:26:51.038969Z","iopub.execute_input":"2024-02-13T06:26:51.039544Z","iopub.status.idle":"2024-02-13T06:26:51.917388Z","shell.execute_reply.started":"2024-02-13T06:26:51.039508Z","shell.execute_reply":"2024-02-13T06:26:51.916255Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"ClassLabel(num_classes=7, names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'], id=None)\n","output_type":"stream"}]},{"cell_type":"code","source":"# use ClassLabel.int2str to create the tag names as strings\ndef create_tag_names(batch):\n    return {\"ner_tags_str\": [reference_tags.int2str(idx) for idx in batch[\"ner_tags\"]]}\n\npanx_de = panx_ch[\"de\"].map(create_tag_names)","metadata":{"execution":{"iopub.status.busy":"2024-02-13T06:26:51.918684Z","iopub.execute_input":"2024-02-13T06:26:51.919025Z","iopub.status.idle":"2024-02-13T06:26:56.543594Z","shell.execute_reply.started":"2024-02-13T06:26:51.918987Z","shell.execute_reply":"2024-02-13T06:26:56.542756Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/12580 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9783485e7d4f433e82131ba476df8da2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/6290 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b7fd030bf50c4ab2a961f309e005e3a6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/6290 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14b9629d4db2463d901d5631d11883b5"}},"metadata":{}}]},{"cell_type":"code","source":"# look at first example in train\nde_example = panx_de[\"train\"][0]\n\npd.DataFrame( [de_example[\"tokens\"], de_example[\"ner_tags_str\"]], [\"Tokens\", \"Tags\"])","metadata":{"execution":{"iopub.status.busy":"2024-02-13T06:26:56.544729Z","iopub.execute_input":"2024-02-13T06:26:56.545176Z","iopub.status.idle":"2024-02-13T06:26:56.561800Z","shell.execute_reply.started":"2024-02-13T06:26:56.545149Z","shell.execute_reply":"2024-02-13T06:26:56.560824Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"           0           1   2    3         4      5   6    7           8   \\\nTokens  2.000  Einwohnern  an  der  Danziger  Bucht  in  der  polnischen   \nTags        O           O   O    O     B-LOC  I-LOC   O    O       B-LOC   \n\n                  9        10 11  \nTokens  Woiwodschaft  Pommern  .  \nTags           B-LOC    I-LOC  O  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Tokens</th>\n      <td>2.000</td>\n      <td>Einwohnern</td>\n      <td>an</td>\n      <td>der</td>\n      <td>Danziger</td>\n      <td>Bucht</td>\n      <td>in</td>\n      <td>der</td>\n      <td>polnischen</td>\n      <td>Woiwodschaft</td>\n      <td>Pommern</td>\n      <td>.</td>\n    </tr>\n    <tr>\n      <th>Tags</th>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>B-LOC</td>\n      <td>I-LOC</td>\n      <td>O</td>\n      <td>O</td>\n      <td>B-LOC</td>\n      <td>B-LOC</td>\n      <td>I-LOC</td>\n      <td>O</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# good practice to check the imbalance of the entities across the t/v/t splits\nfrom collections import Counter\n\nsplit2freqs = defaultdict(Counter)\n\nfor split, dataset in panx_de.items():\n    for row in dataset[\"ner_tags_str\"]:\n        for tag in row:\n            if tag.startswith(\"B\"):\n                tag_type = tag.split(\"-\")[1]\n                split2freqs[split][tag_type] += 1\n\npd.DataFrame.from_dict(split2freqs, orient=\"index\")","metadata":{"execution":{"iopub.status.busy":"2024-02-13T06:26:56.563411Z","iopub.execute_input":"2024-02-13T06:26:56.563753Z","iopub.status.idle":"2024-02-13T06:26:57.112870Z","shell.execute_reply.started":"2024-02-13T06:26:56.563724Z","shell.execute_reply":"2024-02-13T06:26:57.111896Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"             LOC   ORG   PER\ntrain       6186  5366  5810\nvalidation  3172  2683  2893\ntest        3180  2573  3071","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>LOC</th>\n      <th>ORG</th>\n      <th>PER</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>train</th>\n      <td>6186</td>\n      <td>5366</td>\n      <td>5810</td>\n    </tr>\n    <tr>\n      <th>validation</th>\n      <td>3172</td>\n      <td>2683</td>\n      <td>2893</td>\n    </tr>\n    <tr>\n      <th>test</th>\n      <td>3180</td>\n      <td>2573</td>\n      <td>3071</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# XLM-R uses SentencePiece tokenizer; that is trained on raw text of 100 different languages\n\nfrom transformers import AutoTokenizer\n\nxlmr_model_name = \"xlm-roberta-base\"\nxlmr_tokenizer = AutoTokenizer.from_pretrained(xlmr_model_name)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-02-13T06:26:57.116752Z","iopub.execute_input":"2024-02-13T06:26:57.117054Z","iopub.status.idle":"2024-02-13T06:27:05.801546Z","shell.execute_reply.started":"2024-02-13T06:26:57.117028Z","shell.execute_reply":"2024-02-13T06:27:05.800680Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"472808ea7b8f4c42aae209918acc1ed8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"965cffa4712c4ec092eff4cd050e2865"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff1a47de305e4c0096495cf563992594"}},"metadata":{}}]},{"cell_type":"code","source":"# example to show\nexample_text = \"Jack Sparrow loves New York!\"\n\nxlmr_tokens = xlmr_tokenizer(example_text).tokens()\nxlmr_tokens","metadata":{"execution":{"iopub.status.busy":"2024-02-13T06:27:05.802672Z","iopub.execute_input":"2024-02-13T06:27:05.803212Z","iopub.status.idle":"2024-02-13T06:27:05.811229Z","shell.execute_reply.started":"2024-02-13T06:27:05.803182Z","shell.execute_reply":"2024-02-13T06:27:05.810261Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"['<s>', '▁Jack', '▁Spar', 'row', '▁love', 's', '▁New', '▁York', '!', '</s>']"},"metadata":{}}]},{"cell_type":"markdown","source":"p97 book - IMPORTANT:\n\nFor subwords e.g. \"Christa\" -> \"Chr\", \"##ista\"\n\nwe will assign the B-PER label to the first subword, and IGNORE THE FOLLOWING ONE(S)\n\nWe will indicate ignored subwords with IGN.","metadata":{}},{"cell_type":"code","source":"# p99\n# Exercise - we PRETEND that there is no XLMRoberta for token classification (i.e no Head for the task we want)\n# just to see if we can build it ourself as exercise:\n\nimport torch.nn as nn\nfrom transformers import XLMRobertaConfig\nfrom transformers.modeling_outputs import TokenClassifierOutput\nfrom transformers.models.roberta.modeling_roberta import RobertaModel\nfrom transformers.models.roberta.modeling_roberta import RobertaPreTrainedModel\n\nclass CUSTOM_XLMRobertaForTokenClassification(RobertaPreTrainedModel):\n    config_class = XLMRobertaConfig # configuration object to initialize the model \n    \n    def __init__(self, config):\n        super().__init__(config)\n        self.num_labels = config.num_labels\n        \n        # Load model body\n        self.roberta = RobertaModel(config, add_pooling_layer=False)\n        \n        # Set up token classification head\n        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n        \n        # Load and initialize weights\n        self.init_weights()\n    \n    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None, labels=None, **kwargs):\n        # Use model body to get encoder representations\n        outputs = self.roberta(input_ids, attention_mask=attention_mask,\n        token_type_ids=token_type_ids, **kwargs)\n        # Apply classifier to encoder representation\n        sequence_output = self.dropout(outputs[0])\n        logits = self.classifier(sequence_output)\n        # Calculate losses\n        loss = None\n        if labels is not None:\n            loss_fct = nn.CrossEntropyLoss()\n            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n        # Return model output object\n        return TokenClassifierOutput(loss=loss, logits=logits, hidden_states=outputs.hidden_states, attentions=outputs.attentions)\n    \n\ntest = CUSTOM_XLMRobertaForTokenClassification.from_pretrained(\"roberta-base\")","metadata":{"execution":{"iopub.status.busy":"2024-02-13T06:27:05.812525Z","iopub.execute_input":"2024-02-13T06:27:05.812816Z","iopub.status.idle":"2024-02-13T06:27:10.115503Z","shell.execute_reply.started":"2024-02-13T06:27:05.812790Z","shell.execute_reply":"2024-02-13T06:27:10.114572Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec6223ff865c4738bef25bf002bb7ec9"}},"metadata":{}},{"name":"stderr","text":"You are using a model of type roberta to instantiate a model of type xlm-roberta. This is not supported for all configurations of models and can yield errors.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bbe878a5a45d4ce593e42906b006d08c"}},"metadata":{}},{"name":"stderr","text":"Some weights of CUSTOM_XLMRobertaForTokenClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"# (end of part about how you would build your own tokenclassification head)\n# Loading a Custom Model p101\n\n# from earlier:\n# ClassLabel(num_classes=7, names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'], id=None)\n# we are going to use this .names ^^^^^^ now to get the id2label etc\n\nid2label = {idx:tag for idx,tag in enumerate(reference_tags.names)}\nlabel2id = {tag:idx for idx,tag in enumerate(reference_tags.names)}","metadata":{"execution":{"iopub.status.busy":"2024-02-13T06:27:10.116994Z","iopub.execute_input":"2024-02-13T06:27:10.118191Z","iopub.status.idle":"2024-02-13T06:27:10.123838Z","shell.execute_reply.started":"2024-02-13T06:27:10.118149Z","shell.execute_reply":"2024-02-13T06:27:10.122794Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# We store the above mappings, and the reference_tags.num_classes, in an AutoConfig object\n# When you pass keywords to from_pretrained(), you override the default values ofc\n\nfrom transformers import AutoConfig\n\nxlmr_config = AutoConfig.from_pretrained(xlmr_model_name,\n                                        num_labels=reference_tags.num_classes,\n                                        id2label=id2label,\n                                        label2id=label2id)","metadata":{"execution":{"iopub.status.busy":"2024-02-13T06:27:10.125708Z","iopub.execute_input":"2024-02-13T06:27:10.126185Z","iopub.status.idle":"2024-02-13T06:27:10.202637Z","shell.execute_reply.started":"2024-02-13T06:27:10.126147Z","shell.execute_reply":"2024-02-13T06:27:10.201780Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# load model weights as usual, with the the additional config argument\nimport torch\nfrom transformers import XLMRobertaForTokenClassification\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# KAGGLE: turn on Accelerator GPU before run cell\n\nxlmr_model = XLMRobertaForTokenClassification.from_pretrained(xlmr_model_name,\n                                                             config=xlmr_config,\n                                                             ).to(device)","metadata":{"execution":{"iopub.status.busy":"2024-02-13T06:27:10.203909Z","iopub.execute_input":"2024-02-13T06:27:10.204258Z","iopub.status.idle":"2024-02-13T06:27:16.906894Z","shell.execute_reply.started":"2024-02-13T06:27:10.204229Z","shell.execute_reply":"2024-02-13T06:27:16.905892Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.12G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e645aaac70444fb90225221f640c285"}},"metadata":{}},{"name":"stderr","text":"Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"# check 1 - let's see if the tokenizer is working\ninput_ids = xlmr_tokenizer.encode(example_text, return_tensors=\"pt\")\n\npd.DataFrame([xlmr_tokens, input_ids[0].numpy()], index=[\"Tokens\", \"Input IDs\"])","metadata":{"execution":{"iopub.status.busy":"2024-02-13T06:27:16.908364Z","iopub.execute_input":"2024-02-13T06:27:16.908755Z","iopub.status.idle":"2024-02-13T06:27:16.925600Z","shell.execute_reply.started":"2024-02-13T06:27:16.908718Z","shell.execute_reply":"2024-02-13T06:27:16.924365Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"             0      1      2      3      4  5     6      7   8     9\nTokens     <s>  ▁Jack  ▁Spar    row  ▁love  s  ▁New  ▁York   !  </s>\nInput IDs    0  21763  37456  15555   5161  7  2356   5753  38     2","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Tokens</th>\n      <td>&lt;s&gt;</td>\n      <td>▁Jack</td>\n      <td>▁Spar</td>\n      <td>row</td>\n      <td>▁love</td>\n      <td>s</td>\n      <td>▁New</td>\n      <td>▁York</td>\n      <td>!</td>\n      <td>&lt;/s&gt;</td>\n    </tr>\n    <tr>\n      <th>Input IDs</th>\n      <td>0</td>\n      <td>21763</td>\n      <td>37456</td>\n      <td>15555</td>\n      <td>5161</td>\n      <td>7</td>\n      <td>2356</td>\n      <td>5753</td>\n      <td>38</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# check 2 - pass inputs to model and extract predictions with argmax\noutputs = xlmr_model(input_ids.to(device)).logits\n\npredictions = torch.argmax(outputs, dim=-1)\n\nprint(f\"Number of tokens in sequence: {len(xlmr_tokens)}\")\nprint(f\"Shape of outputs: {outputs.shape}\")\n\n# logits have the shape [batch_size, num_tokens, num_tags]","metadata":{"execution":{"iopub.status.busy":"2024-02-13T06:27:16.926728Z","iopub.execute_input":"2024-02-13T06:27:16.927020Z","iopub.status.idle":"2024-02-13T06:27:17.609811Z","shell.execute_reply.started":"2024-02-13T06:27:16.926993Z","shell.execute_reply":"2024-02-13T06:27:17.608704Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Number of tokens in sequence: 10\nShape of outputs: torch.Size([1, 10, 7])\n","output_type":"stream"}]},{"cell_type":"code","source":"preds = [reference_tags.names[p] for p in predictions[0].cpu().numpy()]\npd.DataFrame([xlmr_tokens, preds], index=[\"Tokens\", \"Tags\"])","metadata":{"execution":{"iopub.status.busy":"2024-02-13T06:27:17.610973Z","iopub.execute_input":"2024-02-13T06:27:17.611307Z","iopub.status.idle":"2024-02-13T06:27:17.627514Z","shell.execute_reply.started":"2024-02-13T06:27:17.611276Z","shell.execute_reply":"2024-02-13T06:27:17.626553Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"          0      1      2    3      4  5     6      7  8     9\nTokens  <s>  ▁Jack  ▁Spar  row  ▁love  s  ▁New  ▁York  !  </s>\nTags      O      O      O    O      O  O     O      O  O     O","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Tokens</th>\n      <td>&lt;s&gt;</td>\n      <td>▁Jack</td>\n      <td>▁Spar</td>\n      <td>row</td>\n      <td>▁love</td>\n      <td>s</td>\n      <td>▁New</td>\n      <td>▁York</td>\n      <td>!</td>\n      <td>&lt;/s&gt;</td>\n    </tr>\n    <tr>\n      <th>Tags</th>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# seems to give only O ?????????? compared to example in book\n# book is wrong - the weights are still randomly initialized??\nprint(outputs)\nprint(\"===\")\nprint(predictions)","metadata":{"execution":{"iopub.status.busy":"2024-02-13T06:27:17.628998Z","iopub.execute_input":"2024-02-13T06:27:17.629712Z","iopub.status.idle":"2024-02-13T06:27:17.755332Z","shell.execute_reply.started":"2024-02-13T06:27:17.629674Z","shell.execute_reply":"2024-02-13T06:27:17.754365Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"tensor([[[ 0.7402, -0.6636, -0.6215, -0.5031, -0.1908, -0.0203,  0.1403],\n         [ 0.4484, -0.5321, -0.4032, -0.3921,  0.0244,  0.0369,  0.1332],\n         [ 0.3872, -0.5667, -0.4375, -0.4612, -0.0045,  0.0595,  0.1141],\n         [ 0.3634, -0.5641, -0.4245, -0.3745,  0.0646,  0.0263,  0.1225],\n         [ 0.4474, -0.5678, -0.4394, -0.3793,  0.0481,  0.0076,  0.1923],\n         [ 0.4758, -0.5520, -0.4528, -0.3592, -0.0458,  0.0281,  0.1984],\n         [ 0.4601, -0.3724, -0.3678, -0.4029,  0.0502,  0.0915,  0.2082],\n         [ 0.5050, -0.4129, -0.4229, -0.3503,  0.0957,  0.0155,  0.2366],\n         [ 0.5331, -0.3767, -0.4398, -0.3598, -0.0154,  0.0569,  0.1850],\n         [ 0.7008, -0.6370, -0.6010, -0.5346, -0.2292, -0.0212,  0.1137]]],\n       device='cuda:0', grad_fn=<ViewBackward0>)\n===\ntensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')\n","output_type":"stream"}]},{"cell_type":"code","source":"# wrap the previous steps into a function\ndef tag_text(text, tags, model, tokenizer):\n    # Get tokens with special characters\n    tokens = tokenizer(text).tokens()\n    \n    # Encode the sequence into IDs\n    input_ids = xlmr_tokenizer(text, return_tensors=\"pt\").input_ids.to(device)\n    \n    # Get predictions as distribution over 7 possible classes\n    #outputs = model(inputs)[0] # <--- I THINK THIS IS WRONG IN BOOK ALSO ???\n    outputs = model(input_ids)[0] \n    \n    # Take argmax to get most likely class per token\n    predictions = torch.argmax(outputs, dim=2)\n    \n    # Convert to DataFrame\n    preds = [tags.names[p] for p in predictions[0].cpu().numpy()]\n    \n    return pd.DataFrame([tokens, preds], index=[\"Tokens\", \"Tags\"])","metadata":{"execution":{"iopub.status.busy":"2024-02-13T06:27:17.756662Z","iopub.execute_input":"2024-02-13T06:27:17.757571Z","iopub.status.idle":"2024-02-13T06:27:17.765027Z","shell.execute_reply.started":"2024-02-13T06:27:17.757533Z","shell.execute_reply":"2024-02-13T06:27:17.764084Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# before training, need to tokenize inputs and prepare labels\n# p103\nwords, labels = de_example[\"tokens\"], de_example[\"ner_tags\"]\n\nprint(words)\nprint(labels)","metadata":{"execution":{"iopub.status.busy":"2024-02-13T06:27:17.766325Z","iopub.execute_input":"2024-02-13T06:27:17.766635Z","iopub.status.idle":"2024-02-13T06:27:17.776130Z","shell.execute_reply.started":"2024-02-13T06:27:17.766609Z","shell.execute_reply":"2024-02-13T06:27:17.775221Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"['2.000', 'Einwohnern', 'an', 'der', 'Danziger', 'Bucht', 'in', 'der', 'polnischen', 'Woiwodschaft', 'Pommern', '.']\n[0, 0, 0, 0, 5, 6, 0, 0, 5, 5, 6, 0]\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenized_input = xlmr_tokenizer(de_example[\"tokens\"], is_split_into_words=True)\ntokens = xlmr_tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n\npd.DataFrame([tokens], index=[\"Tokens\"])","metadata":{"execution":{"iopub.status.busy":"2024-02-13T06:27:17.777312Z","iopub.execute_input":"2024-02-13T06:27:17.777605Z","iopub.status.idle":"2024-02-13T06:27:17.806963Z","shell.execute_reply.started":"2024-02-13T06:27:17.777579Z","shell.execute_reply":"2024-02-13T06:27:17.805862Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"         0       1           2  3    4     5     6   7    8      9   ...   15  \\\nTokens  <s>  ▁2.000  ▁Einwohner  n  ▁an  ▁der  ▁Dan  zi  ger  ▁Buch  ...  ▁Wo   \n\n       16   17      18   19    20 21 22 23    24  \nTokens  i  wod  schaft  ▁Po  mmer  n  ▁  .  </s>  \n\n[1 rows x 25 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>15</th>\n      <th>16</th>\n      <th>17</th>\n      <th>18</th>\n      <th>19</th>\n      <th>20</th>\n      <th>21</th>\n      <th>22</th>\n      <th>23</th>\n      <th>24</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Tokens</th>\n      <td>&lt;s&gt;</td>\n      <td>▁2.000</td>\n      <td>▁Einwohner</td>\n      <td>n</td>\n      <td>▁an</td>\n      <td>▁der</td>\n      <td>▁Dan</td>\n      <td>zi</td>\n      <td>ger</td>\n      <td>▁Buch</td>\n      <td>...</td>\n      <td>▁Wo</td>\n      <td>i</td>\n      <td>wod</td>\n      <td>schaft</td>\n      <td>▁Po</td>\n      <td>mmer</td>\n      <td>n</td>\n      <td>▁</td>\n      <td>.</td>\n      <td>&lt;/s&gt;</td>\n    </tr>\n  </tbody>\n</table>\n<p>1 rows × 25 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# REMEMBER - we are following convention that only first subword is going to be associated with e.g. B-LOC\n\n# tokenized_input has a word_ids() function:\nword_ids = tokenized_input.word_ids()\n\npd.DataFrame([tokens, word_ids], index=[\"Tokens\", \"Word IDs\"])","metadata":{"execution":{"iopub.status.busy":"2024-02-13T06:27:17.808266Z","iopub.execute_input":"2024-02-13T06:27:17.808682Z","iopub.status.idle":"2024-02-13T06:27:17.833305Z","shell.execute_reply.started":"2024-02-13T06:27:17.808640Z","shell.execute_reply":"2024-02-13T06:27:17.832256Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"            0       1           2  3    4     5     6   7    8      9   ...  \\\nTokens     <s>  ▁2.000  ▁Einwohner  n  ▁an  ▁der  ▁Dan  zi  ger  ▁Buch  ...   \nWord IDs  None       0           1  1    2     3     4   4    4      5  ...   \n\n           15 16   17      18   19    20  21  22  23    24  \nTokens    ▁Wo  i  wod  schaft  ▁Po  mmer   n   ▁   .  </s>  \nWord IDs    9  9    9       9   10    10  10  11  11  None  \n\n[2 rows x 25 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>15</th>\n      <th>16</th>\n      <th>17</th>\n      <th>18</th>\n      <th>19</th>\n      <th>20</th>\n      <th>21</th>\n      <th>22</th>\n      <th>23</th>\n      <th>24</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Tokens</th>\n      <td>&lt;s&gt;</td>\n      <td>▁2.000</td>\n      <td>▁Einwohner</td>\n      <td>n</td>\n      <td>▁an</td>\n      <td>▁der</td>\n      <td>▁Dan</td>\n      <td>zi</td>\n      <td>ger</td>\n      <td>▁Buch</td>\n      <td>...</td>\n      <td>▁Wo</td>\n      <td>i</td>\n      <td>wod</td>\n      <td>schaft</td>\n      <td>▁Po</td>\n      <td>mmer</td>\n      <td>n</td>\n      <td>▁</td>\n      <td>.</td>\n      <td>&lt;/s&gt;</td>\n    </tr>\n    <tr>\n      <th>Word IDs</th>\n      <td>None</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>5</td>\n      <td>...</td>\n      <td>9</td>\n      <td>9</td>\n      <td>9</td>\n      <td>9</td>\n      <td>10</td>\n      <td>10</td>\n      <td>10</td>\n      <td>11</td>\n      <td>11</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows × 25 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"\"\"\"Here we can see that word_ids has mapped each subword to the corresponding index\nin the words sequence, so the first subword, “▁2.000”, is assigned the index 0, while\n“▁Einwohner” and “n” are assigned the index 1 (since “Einwohnern” is the second\nword in words). We can also see that special tokens like <s> and <\\s> are mapped to\nNone. Let’s set –100 as the label for these special tokens and the subwords we wish to\nmask during training:\"\"\"\nprevious_word_idx = None\nlabel_ids = []\n\nfor word_idx in word_ids:\n    if word_idx is None or word_idx == previous_word_idx:\n        label_ids.append(-100)\n    elif word_idx != previous_word_idx:\n        label_ids.append(labels[word_idx])\n    previous_word_idx = word_idx\n    \nlabels = [id2label[l] if l != -100 else \"IGN\" for l in label_ids]\nindex = [\"Tokens\", \"Word IDs\", \"Label IDs\", \"Labels\"]\npd.DataFrame([tokens, word_ids, label_ids, labels], index=index)\n\n\n# the -100 is because of ignore_index in PyTorch CrossEntropyLoss","metadata":{"execution":{"iopub.status.busy":"2024-02-13T06:27:17.834828Z","iopub.execute_input":"2024-02-13T06:27:17.835578Z","iopub.status.idle":"2024-02-13T06:27:17.864118Z","shell.execute_reply.started":"2024-02-13T06:27:17.835538Z","shell.execute_reply":"2024-02-13T06:27:17.863046Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"             0       1           2     3    4     5      6     7     8   \\\nTokens      <s>  ▁2.000  ▁Einwohner     n  ▁an  ▁der   ▁Dan    zi   ger   \nWord IDs   None       0           1     1    2     3      4     4     4   \nLabel IDs  -100       0           0  -100    0     0      5  -100  -100   \nLabels      IGN       O           O   IGN    O     O  B-LOC   IGN   IGN   \n\n              9   ...     15    16    17      18     19    20    21  22    23  \\\nTokens     ▁Buch  ...    ▁Wo     i   wod  schaft    ▁Po  mmer     n   ▁     .   \nWord IDs       5  ...      9     9     9       9     10    10    10  11    11   \nLabel IDs      6  ...      5  -100  -100    -100      6  -100  -100   0  -100   \nLabels     I-LOC  ...  B-LOC   IGN   IGN     IGN  I-LOC   IGN   IGN   O   IGN   \n\n             24  \nTokens     </s>  \nWord IDs   None  \nLabel IDs  -100  \nLabels      IGN  \n\n[4 rows x 25 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>15</th>\n      <th>16</th>\n      <th>17</th>\n      <th>18</th>\n      <th>19</th>\n      <th>20</th>\n      <th>21</th>\n      <th>22</th>\n      <th>23</th>\n      <th>24</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Tokens</th>\n      <td>&lt;s&gt;</td>\n      <td>▁2.000</td>\n      <td>▁Einwohner</td>\n      <td>n</td>\n      <td>▁an</td>\n      <td>▁der</td>\n      <td>▁Dan</td>\n      <td>zi</td>\n      <td>ger</td>\n      <td>▁Buch</td>\n      <td>...</td>\n      <td>▁Wo</td>\n      <td>i</td>\n      <td>wod</td>\n      <td>schaft</td>\n      <td>▁Po</td>\n      <td>mmer</td>\n      <td>n</td>\n      <td>▁</td>\n      <td>.</td>\n      <td>&lt;/s&gt;</td>\n    </tr>\n    <tr>\n      <th>Word IDs</th>\n      <td>None</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>5</td>\n      <td>...</td>\n      <td>9</td>\n      <td>9</td>\n      <td>9</td>\n      <td>9</td>\n      <td>10</td>\n      <td>10</td>\n      <td>10</td>\n      <td>11</td>\n      <td>11</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>Label IDs</th>\n      <td>-100</td>\n      <td>0</td>\n      <td>0</td>\n      <td>-100</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>-100</td>\n      <td>-100</td>\n      <td>6</td>\n      <td>...</td>\n      <td>5</td>\n      <td>-100</td>\n      <td>-100</td>\n      <td>-100</td>\n      <td>6</td>\n      <td>-100</td>\n      <td>-100</td>\n      <td>0</td>\n      <td>-100</td>\n      <td>-100</td>\n    </tr>\n    <tr>\n      <th>Labels</th>\n      <td>IGN</td>\n      <td>O</td>\n      <td>O</td>\n      <td>IGN</td>\n      <td>O</td>\n      <td>O</td>\n      <td>B-LOC</td>\n      <td>IGN</td>\n      <td>IGN</td>\n      <td>I-LOC</td>\n      <td>...</td>\n      <td>B-LOC</td>\n      <td>IGN</td>\n      <td>IGN</td>\n      <td>IGN</td>\n      <td>I-LOC</td>\n      <td>IGN</td>\n      <td>IGN</td>\n      <td>O</td>\n      <td>IGN</td>\n      <td>IGN</td>\n    </tr>\n  </tbody>\n</table>\n<p>4 rows × 25 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# in the above DF you can see how the label IDs align with the tokens\n# let's apply this now to our entire dataset with a function to map\n\ndef tokenize_and_align_labels(batch):\n    tokenized_inputs = xlmr_tokenizer(batch[\"tokens\"], truncation=True, is_split_into_words=True)\n    labels = []\n    for idx, label in enumerate(batch[\"ner_tags\"]):\n        word_ids = tokenized_inputs.word_ids(batch_index=idx)\n        previous_word_idx = None\n        label_ids = []\n        for word_idx in word_ids:\n            if word_idx is None or word_idx == previous_word_idx:\n                label_ids.append(-100)\n            else:\n                label_ids.append(label[word_idx])\n            previous_word_idx = word_idx\n        labels.append(label_ids)\n    \n    tokenized_inputs[\"labels\"] = labels\n    \n    return tokenized_inputs","metadata":{"execution":{"iopub.status.busy":"2024-02-13T06:27:17.865446Z","iopub.execute_input":"2024-02-13T06:27:17.865770Z","iopub.status.idle":"2024-02-13T06:27:17.875746Z","shell.execute_reply.started":"2024-02-13T06:27:17.865744Z","shell.execute_reply":"2024-02-13T06:27:17.874926Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# now we write a function to encode each split\n# the remove_columns are specific to this PANX dataset of course (the langs part at least)\ndef encode_panx_dataset(corpus):\n    return corpus.map(tokenize_and_align_labels, batched=True, remove_columns=['langs', 'ner_tags', 'tokens'])\n\n\n# ENCODE THE GERMAN CORPUS:\npanx_de_encoded = encode_panx_dataset(panx_ch[\"de\"])","metadata":{"execution":{"iopub.status.busy":"2024-02-13T06:27:17.877039Z","iopub.execute_input":"2024-02-13T06:27:17.877424Z","iopub.status.idle":"2024-02-13T06:27:21.789530Z","shell.execute_reply.started":"2024-02-13T06:27:17.877391Z","shell.execute_reply":"2024-02-13T06:27:21.788475Z"},"trusted":true},"execution_count":26,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"742efd67502e4fda9e1d6d15501fdae2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/7 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"76f94d007a404856a7102c5829c3a796"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/7 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"56db3e3366cb4264a7712773ae64efd7"}},"metadata":{}}]},{"cell_type":"code","source":"# define Performance metrics\n# p105\n!pip install seqeval","metadata":{"execution":{"iopub.status.busy":"2024-02-13T06:27:21.790889Z","iopub.execute_input":"2024-02-13T06:27:21.791251Z","iopub.status.idle":"2024-02-13T06:27:41.644557Z","shell.execute_reply.started":"2024-02-13T06:27:21.791221Z","shell.execute_reply":"2024-02-13T06:27:41.643384Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting seqeval\n  Downloading seqeval-1.2.2.tar.gz (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from seqeval) (1.24.4)\nRequirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/lib/python3.10/site-packages (from seqeval) (1.2.2)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (1.11.4)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (3.2.0)\nBuilding wheels for collected packages: seqeval\n  Building wheel for seqeval (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=f27f74f6f8b4b58abab0cc1a53c9cbdff066f08cf57ea5b16a167c46b33e846e\n  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\nSuccessfully built seqeval\nInstalling collected packages: seqeval\nSuccessfully installed seqeval-1.2.2\n","output_type":"stream"}]},{"cell_type":"code","source":"from seqeval.metrics import classification_report","metadata":{"execution":{"iopub.status.busy":"2024-02-13T06:27:41.650518Z","iopub.execute_input":"2024-02-13T06:27:41.650868Z","iopub.status.idle":"2024-02-13T06:27:42.147169Z","shell.execute_reply.started":"2024-02-13T06:27:41.650837Z","shell.execute_reply":"2024-02-13T06:27:42.146285Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"\"\"\"seqeval expects the predictions and labels as lists of lists, with each list\ncorresponding to a single example in our validation or test sets. To integrate these\nmetrics during training, we need a function that can take the outputs of the model\nand convert them into the lists that seqeval expects. The following does the trick by\nensuring we ignore the label IDs associated with subsequent subwords:\"\"\"\n\nimport numpy as np\n\ndef align_predictions(predictions, label_ids):\n    preds = np.argmax(predictions, axis=2)\n    batch_size, seq_len = preds.shape\n    labels_list, preds_list = [], []\n    \n    for batch_idx in range(batch_size):\n        example_labels, example_preds = [], []\n        \n        for seq_idx in range(seq_len):\n        # Ignore label IDs = -100\n            if label_ids[batch_idx, seq_idx] != -100:\n                example_labels.append(id2label[label_ids[batch_idx][seq_idx]])\n                example_preds.append(id2label[preds[batch_idx][seq_idx]])\n        \n        labels_list.append(example_labels)\n        preds_list.append(example_preds)\n        \n    return preds_list, labels_list","metadata":{"execution":{"iopub.status.busy":"2024-02-13T06:27:42.148328Z","iopub.execute_input":"2024-02-13T06:27:42.149322Z","iopub.status.idle":"2024-02-13T06:27:42.157986Z","shell.execute_reply.started":"2024-02-13T06:27:42.149289Z","shell.execute_reply":"2024-02-13T06:27:42.156869Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# --- Finetuning XLM RoBERTa ---\n# finetune on the German subset of PAN-X\n\nfrom transformers import TrainingArguments\n\nnum_epochs = 3\nbatch_size = 24\nlogging_steps = len(panx_de_encoded[\"train\"]) // batch_size\n\nmodel_name = f\"{xlmr_model_name}-test-finetuned-panx-de\"\n\ntraining_args = TrainingArguments(output_dir=model_name,\n                                  log_level=\"error\",\n                                  num_train_epochs=num_epochs,\n                                  per_device_train_batch_size=batch_size,\n                                  per_device_eval_batch_size=batch_size,\n                                  evaluation_strategy=\"epoch\",\n                                  save_steps=1e6, # set save_steps to a large number to disable checkpointing and thus speed up training\n                                  weight_decay=0.01,\n                                  disable_tqdm=False,\n                                  logging_steps=logging_steps,\n                                  #load_best_model_at_end=True,\n                                  report_to=\"none\",\n                                  push_to_hub=True)","metadata":{"execution":{"iopub.status.busy":"2024-02-13T06:27:42.159544Z","iopub.execute_input":"2024-02-13T06:27:42.159951Z","iopub.status.idle":"2024-02-13T06:27:42.186148Z","shell.execute_reply.started":"2024-02-13T06:27:42.159916Z","shell.execute_reply":"2024-02-13T06:27:42.185007Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"from huggingface_hub import notebook_login\nnotebook_login()","metadata":{"execution":{"iopub.status.busy":"2024-02-13T06:28:04.765500Z","iopub.execute_input":"2024-02-13T06:28:04.766204Z","iopub.status.idle":"2024-02-13T06:28:04.794149Z","shell.execute_reply.started":"2024-02-13T06:28:04.766170Z","shell.execute_reply":"2024-02-13T06:28:04.793231Z"},"trusted":true},"execution_count":31,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1820785b8ee47818e900f02c4eef7bc"}},"metadata":{}}]},{"cell_type":"code","source":"# tell Trainer how to compute metrics on the validation set\n# -> use align_predictions() we defined earlier to get the predictions+labels in the format needed by seqeval\n# -> call f1_score on these 2 lists\nfrom seqeval.metrics import f1_score\n\ndef compute_metrics(eval_pred):\n    y_pred, y_true = align_predictions(eval_pred.predictions, eval_pred.label_ids)\n    \n    return {\"f1\": f1_score(y_true, y_pred)}\n","metadata":{"execution":{"iopub.status.busy":"2024-02-13T06:28:10.880679Z","iopub.execute_input":"2024-02-13T06:28:10.881439Z","iopub.status.idle":"2024-02-13T06:28:10.886845Z","shell.execute_reply.started":"2024-02-13T06:28:10.881404Z","shell.execute_reply":"2024-02-13T06:28:10.885727Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# data collator to pad each input sequence to largest sequence length in the batch\n\nfrom transformers import DataCollatorForTokenClassification\n\n# the ForTokenClassification means it will also pad the labels with -100 as well as the inputs\n\ndata_collator = DataCollatorForTokenClassification(xlmr_tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-02-13T06:28:31.575748Z","iopub.execute_input":"2024-02-13T06:28:31.576137Z","iopub.status.idle":"2024-02-13T06:28:31.580780Z","shell.execute_reply.started":"2024-02-13T06:28:31.576089Z","shell.execute_reply":"2024-02-13T06:28:31.579770Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"\"\"\"We will train several models in the course of this chapter, so we’ll avoid initializing a\nnew model for every Trainer by creating a model_init() method. This method loads\nan untrained model and is called at the beginning of the train() call:\n\"\"\"\ndef model_init():\n    return XLMRobertaForTokenClassification.from_pretrained(xlmr_model_name, config=xlmr_config).to(device)","metadata":{"execution":{"iopub.status.busy":"2024-02-13T06:28:34.433306Z","iopub.execute_input":"2024-02-13T06:28:34.433656Z","iopub.status.idle":"2024-02-13T06:28:34.438971Z","shell.execute_reply.started":"2024-02-13T06:28:34.433627Z","shell.execute_reply":"2024-02-13T06:28:34.437852Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"from transformers import Trainer\n\ntrainer = Trainer(model_init=model_init,\n                 args=training_args,\n                 data_collator=data_collator,\n                 compute_metrics=compute_metrics,\n                 train_dataset=panx_de_encoded[\"train\"],\n                 eval_dataset=panx_de_encoded[\"validation\"],\n                 tokenizer=xlmr_tokenizer)\n\nprint(\"--- TRAINING ---\", xlmr_model_name)\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-02-13T06:34:18.148938Z","iopub.execute_input":"2024-02-13T06:34:18.149817Z","iopub.status.idle":"2024-02-13T06:39:08.238298Z","shell.execute_reply.started":"2024-02-13T06:34:18.149778Z","shell.execute_reply":"2024-02-13T06:39:08.237318Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"--- TRAINING --- xlm-roberta-base\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1575' max='1575' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1575/1575 04:47, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.260800</td>\n      <td>0.153963</td>\n      <td>0.830155</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.126300</td>\n      <td>0.132494</td>\n      <td>0.854320</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.080000</td>\n      <td>0.139859</td>\n      <td>0.861233</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1575, training_loss=0.1554795039078546, metrics={'train_runtime': 287.8359, 'train_samples_per_second': 131.116, 'train_steps_per_second': 5.472, 'total_flos': 865978637734056.0, 'train_loss': 0.1554795039078546, 'epoch': 3.0})"},"metadata":{}}]},{"cell_type":"code","source":"# to confirm it works let's test on a German phrase\ntext_de = \"Jeff Dean ist ein Informatiker bei Google in Kalifornien\"\n\ntag_text(text_de, reference_tags, trainer.model, xlmr_tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-02-13T06:39:12.345088Z","iopub.execute_input":"2024-02-13T06:39:12.346041Z","iopub.status.idle":"2024-02-13T06:39:12.379645Z","shell.execute_reply.started":"2024-02-13T06:39:12.346006Z","shell.execute_reply":"2024-02-13T06:39:12.378590Z"},"trusted":true},"execution_count":41,"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"         0      1      2      3     4     5           6    7     8        9   \\\nTokens  <s>  ▁Jeff    ▁De     an  ▁ist  ▁ein  ▁Informati  ker  ▁bei  ▁Google   \nTags      O  B-PER  I-PER  I-PER     O     O           O    O     O    B-ORG   \n\n         10          11     12    13  \nTokens  ▁in  ▁Kaliforni     en  </s>  \nTags      O       B-LOC  I-LOC     O  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n      <th>12</th>\n      <th>13</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Tokens</th>\n      <td>&lt;s&gt;</td>\n      <td>▁Jeff</td>\n      <td>▁De</td>\n      <td>an</td>\n      <td>▁ist</td>\n      <td>▁ein</td>\n      <td>▁Informati</td>\n      <td>ker</td>\n      <td>▁bei</td>\n      <td>▁Google</td>\n      <td>▁in</td>\n      <td>▁Kaliforni</td>\n      <td>en</td>\n      <td>&lt;/s&gt;</td>\n    </tr>\n    <tr>\n      <th>Tags</th>\n      <td>O</td>\n      <td>B-PER</td>\n      <td>I-PER</td>\n      <td>I-PER</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>B-ORG</td>\n      <td>O</td>\n      <td>B-LOC</td>\n      <td>I-LOC</td>\n      <td>O</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# ERROR ANALYSIS\n\nAs in Chapter 2 - we can look at the validation examples with the Highest loss.\n\nWe can reuse a lot of the function from Chapter 2, used to analyse Sequence Classification model, but here we need to calculate a loss PER TOKEN in the sample sequence:","metadata":{}},{"cell_type":"code","source":"from torch.nn.functional import cross_entropy\n\ndef forward_pass_with_label(batch):\n    # Convert dict of lists to list of dicts suitable for data collator\n    features = [dict(zip(batch, t)) for t in zip(*batch.values())]\n    \n    # Pad inputs and labels and put all tensors on device\n    batch = data_collator(features)\n    input_ids = batch[\"input_ids\"].to(device)\n    attention_mask = batch[\"attention_mask\"].to(device)\n    \n    labels = batch[\"labels\"].to(device)\n    \n    with torch.no_grad():\n        # Pass data through model\n        output = trainer.model(input_ids, attention_mask)\n        # logit.size: [batch_size, sequence_length, classes]\n        # Predict class with largest logit value on classes axis\n        predicted_label = torch.argmax(output.logits, axis=-1).cpu().numpy()\n    \n    # Calculate loss per token after flattening batch dimension with view\n    loss = cross_entropy(output.logits.view(-1, 7), labels.view(-1), reduction=\"none\")\n    \n    # Unflatten batch dimension and convert to numpy array\n    loss = loss.view(len(input_ids), -1).cpu().numpy()\n    \n    return {\"loss\":loss, \"predicted_label\": predicted_label}","metadata":{"execution":{"iopub.status.busy":"2024-02-13T06:39:20.127401Z","iopub.execute_input":"2024-02-13T06:39:20.128246Z","iopub.status.idle":"2024-02-13T06:39:20.137430Z","shell.execute_reply.started":"2024-02-13T06:39:20.128210Z","shell.execute_reply":"2024-02-13T06:39:20.136242Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"\"\"\"apply this function to the whole validation set using map() and load all\nthe data into a DataFrame for further analysis:\"\"\"\n    \nvalid_set = panx_de_encoded[\"validation\"]\nvalid_set = valid_set.map(forward_pass_with_label, batched=True, batch_size=32)\ndf = valid_set.to_pandas()","metadata":{"execution":{"iopub.status.busy":"2024-02-13T06:39:23.114562Z","iopub.execute_input":"2024-02-13T06:39:23.115250Z","iopub.status.idle":"2024-02-13T06:39:33.323135Z","shell.execute_reply.started":"2024-02-13T06:39:23.115216Z","shell.execute_reply":"2024-02-13T06:39:33.322277Z"},"trusted":true},"execution_count":44,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/197 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"39ab0a3b94e84d50a8e8f29eb5f63f54"}},"metadata":{}}]},{"cell_type":"code","source":"print(id2label)","metadata":{"execution":{"iopub.status.busy":"2024-02-13T06:39:34.625999Z","iopub.execute_input":"2024-02-13T06:39:34.626419Z","iopub.status.idle":"2024-02-13T06:39:34.632034Z","shell.execute_reply.started":"2024-02-13T06:39:34.626385Z","shell.execute_reply":"2024-02-13T06:39:34.630966Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"{0: 'O', 1: 'B-PER', 2: 'I-PER', 3: 'B-ORG', 4: 'I-ORG', 5: 'B-LOC', 6: 'I-LOC'}\n","output_type":"stream"}]},{"cell_type":"code","source":"\"\"\"The tokens and the labels are still encoded with their IDs, so let’s map the tokens and\nlabels back to strings to make it easier to read the results. For the padding tokens with\nlabel –100 we assign a special label, IGN, so we can filter them later. We also get rid of\nall the padding in the loss and predicted_label fields by truncating them to the\nlength of the inputs:\"\"\"\n\n\nid2label[-100] = \"IGN\"\n\ndf[\"input_tokens\"] = df[\"input_ids\"].apply(lambda x: xlmr_tokenizer.convert_ids_to_tokens(x))\ndf[\"predicted_label\"] = df[\"predicted_label\"].apply(lambda x: [id2label[i] for i in x])\ndf[\"labels\"] = df[\"labels\"].apply(lambda x: [id2label[i] for i in x])\n\n# get rid of padding:\ndf['loss'] = df.apply(lambda x: x['loss'][:len(x['input_ids'])], axis=1)\ndf['predicted_label'] = df.apply(lambda x: x['predicted_label'][:len(x['input_ids'])], axis=1)\n\ndf.head(1)","metadata":{"execution":{"iopub.status.busy":"2024-02-13T06:39:38.190613Z","iopub.execute_input":"2024-02-13T06:39:38.191006Z","iopub.status.idle":"2024-02-13T06:39:38.759257Z","shell.execute_reply.started":"2024-02-13T06:39:38.190975Z","shell.execute_reply":"2024-02-13T06:39:38.758165Z"},"trusted":true},"execution_count":46,"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"                            input_ids         attention_mask  \\\n0  [0, 10699, 11, 15, 16104, 1388, 2]  [1, 1, 1, 1, 1, 1, 1]   \n\n                                        labels  \\\n0  [IGN, B-ORG, IGN, I-ORG, I-ORG, I-ORG, IGN]   \n\n                                                loss  \\\n0  [0.0, 0.012111809, 0.0, 0.013677333, 0.0097154...   \n\n                                     predicted_label  \\\n0  [I-ORG, B-ORG, I-ORG, I-ORG, I-ORG, I-ORG, I-ORG]   \n\n                                 input_tokens  \n0  [<s>, ▁Ham, a, ▁(, ▁Unternehmen, ▁), </s>]  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>input_ids</th>\n      <th>attention_mask</th>\n      <th>labels</th>\n      <th>loss</th>\n      <th>predicted_label</th>\n      <th>input_tokens</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[0, 10699, 11, 15, 16104, 1388, 2]</td>\n      <td>[1, 1, 1, 1, 1, 1, 1]</td>\n      <td>[IGN, B-ORG, IGN, I-ORG, I-ORG, I-ORG, IGN]</td>\n      <td>[0.0, 0.012111809, 0.0, 0.013677333, 0.0097154...</td>\n      <td>[I-ORG, B-ORG, I-ORG, I-ORG, I-ORG, I-ORG, I-ORG]</td>\n      <td>[&lt;s&gt;, ▁Ham, a, ▁(, ▁Unternehmen, ▁), &lt;/s&gt;]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# USEFUL PANDAS KNOWLEDGE\n\"\"\"Each column contains a list of tokens, labels, predicted labels, and so on for each\nsample. Let’s have a look at the tokens individually by unpacking these lists. The\npandas.Series.explode() function allows us to do exactly that in one line by creat‐\ning a row for each element in the original rows list. Since all the lists in one row have\nthe same length, we can do this in parallel for all columns. We also drop the padding\ntokens we named IGN, since their loss is zero anyway. Finally, we cast the losses, which\nare still numpy.Array objects, to standard floats:\"\"\"\n\ndf_tokens = df.apply(pd.Series.explode)\ndf_tokens = df_tokens.query(\"labels != 'IGN'\")\ndf_tokens[\"loss\"] = df_tokens[\"loss\"].astype(float).round(2)\ndf_tokens.head(7)","metadata":{"execution":{"iopub.status.busy":"2024-02-13T06:39:42.045880Z","iopub.execute_input":"2024-02-13T06:39:42.046294Z","iopub.status.idle":"2024-02-13T06:39:42.186568Z","shell.execute_reply.started":"2024-02-13T06:39:42.046263Z","shell.execute_reply":"2024-02-13T06:39:42.185460Z"},"trusted":true},"execution_count":47,"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"  input_ids attention_mask labels  loss predicted_label  input_tokens\n0     10699              1  B-ORG  0.01           B-ORG          ▁Ham\n0        15              1  I-ORG  0.01           I-ORG            ▁(\n0     16104              1  I-ORG  0.01           I-ORG  ▁Unternehmen\n0      1388              1  I-ORG  0.01           I-ORG            ▁)\n1     56530              1      O  0.00               O           ▁WE\n1     83982              1  B-ORG  1.22           B-LOC          ▁Luz\n1        10              1  I-ORG  1.26           I-LOC            ▁a","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>input_ids</th>\n      <th>attention_mask</th>\n      <th>labels</th>\n      <th>loss</th>\n      <th>predicted_label</th>\n      <th>input_tokens</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10699</td>\n      <td>1</td>\n      <td>B-ORG</td>\n      <td>0.01</td>\n      <td>B-ORG</td>\n      <td>▁Ham</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>15</td>\n      <td>1</td>\n      <td>I-ORG</td>\n      <td>0.01</td>\n      <td>I-ORG</td>\n      <td>▁(</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>16104</td>\n      <td>1</td>\n      <td>I-ORG</td>\n      <td>0.01</td>\n      <td>I-ORG</td>\n      <td>▁Unternehmen</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>1388</td>\n      <td>1</td>\n      <td>I-ORG</td>\n      <td>0.01</td>\n      <td>I-ORG</td>\n      <td>▁)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>56530</td>\n      <td>1</td>\n      <td>O</td>\n      <td>0.00</td>\n      <td>O</td>\n      <td>▁WE</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>83982</td>\n      <td>1</td>\n      <td>B-ORG</td>\n      <td>1.22</td>\n      <td>B-LOC</td>\n      <td>▁Luz</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10</td>\n      <td>1</td>\n      <td>I-ORG</td>\n      <td>1.26</td>\n      <td>I-LOC</td>\n      <td>▁a</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"\"\"\"With the data in this shape, we can now group it by the input tokens and aggregate\nthe losses for each token with the count, mean, and sum. Finally, we sort the\naggregated data by the sum of the losses and see which tokens have accumulated the\nmost loss in the validation set:\"\"\"\n(\ndf_tokens.groupby(\"input_tokens\")[[\"loss\"]]\n.agg([\"count\", \"mean\", \"sum\"])\n.droplevel(level=0, axis=1) # Get rid of multi-level columns\n.sort_values(by=\"sum\", ascending=False)\n.reset_index()\n.round(2)\n.head(10)\n.T\n)","metadata":{"execution":{"iopub.status.busy":"2024-02-13T06:39:44.801413Z","iopub.execute_input":"2024-02-13T06:39:44.802184Z","iopub.status.idle":"2024-02-13T06:39:44.854620Z","shell.execute_reply.started":"2024-02-13T06:39:44.802152Z","shell.execute_reply":"2024-02-13T06:39:44.853597Z"},"trusted":true},"execution_count":48,"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"                  0       1      2      3       4       5      6      7  \\\ninput_tokens      ▁    ▁der   ▁von    ▁in    ▁und      ▁/     ▁(    ▁''   \ncount          6066    1388    808    989    1171     163    246   2898   \nmean           0.04    0.09   0.15   0.12    0.09    0.67   0.29   0.02   \nsum           231.1  121.62  119.3  117.2  109.67  108.61  72.31  71.44   \n\n                  8      9  \ninput_tokens     ▁)     ▁A  \ncount           246    125  \nmean           0.27   0.45  \nsum           67.04  55.66  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>input_tokens</th>\n      <td>▁</td>\n      <td>▁der</td>\n      <td>▁von</td>\n      <td>▁in</td>\n      <td>▁und</td>\n      <td>▁/</td>\n      <td>▁(</td>\n      <td>▁''</td>\n      <td>▁)</td>\n      <td>▁A</td>\n    </tr>\n    <tr>\n      <th>count</th>\n      <td>6066</td>\n      <td>1388</td>\n      <td>808</td>\n      <td>989</td>\n      <td>1171</td>\n      <td>163</td>\n      <td>246</td>\n      <td>2898</td>\n      <td>246</td>\n      <td>125</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.04</td>\n      <td>0.09</td>\n      <td>0.15</td>\n      <td>0.12</td>\n      <td>0.09</td>\n      <td>0.67</td>\n      <td>0.29</td>\n      <td>0.02</td>\n      <td>0.27</td>\n      <td>0.45</td>\n    </tr>\n    <tr>\n      <th>sum</th>\n      <td>231.1</td>\n      <td>121.62</td>\n      <td>119.3</td>\n      <td>117.2</td>\n      <td>109.67</td>\n      <td>108.61</td>\n      <td>72.31</td>\n      <td>71.44</td>\n      <td>67.04</td>\n      <td>55.66</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# in the above table, note how whitespace token has highest total loss, but its mean loss isn't too bad\n# / ( and ) at the beginning of words are rare but have high mean loss -> need to investigate further\n\n# We can also group the label IDs and look at the losses for each class\n(\ndf_tokens.groupby(\"labels\")[[\"loss\"]]\n.agg([\"count\", \"mean\", \"sum\"])\n.droplevel(level=0, axis=1)\n.sort_values(by=\"mean\", ascending=False)\n.reset_index()\n.round(2)\n.T\n)","metadata":{"execution":{"iopub.status.busy":"2024-02-13T06:39:47.268433Z","iopub.execute_input":"2024-02-13T06:39:47.268821Z","iopub.status.idle":"2024-02-13T06:39:47.295584Z","shell.execute_reply.started":"2024-02-13T06:39:47.268786Z","shell.execute_reply":"2024-02-13T06:39:47.294583Z"},"trusted":true},"execution_count":49,"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"              0       1        2       3       4       5       6\nlabels    B-ORG   I-LOC    I-ORG   B-LOC   B-PER   I-PER       O\ncount      2683    1462     3820    3172    2893    4139   43648\nmean       0.62    0.59      0.5    0.32    0.28     0.2    0.03\nsum     1667.53  855.77  1895.96  999.22  810.85  834.12  1506.3","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>labels</th>\n      <td>B-ORG</td>\n      <td>I-LOC</td>\n      <td>I-ORG</td>\n      <td>B-LOC</td>\n      <td>B-PER</td>\n      <td>I-PER</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>count</th>\n      <td>2683</td>\n      <td>1462</td>\n      <td>3820</td>\n      <td>3172</td>\n      <td>2893</td>\n      <td>4139</td>\n      <td>43648</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.62</td>\n      <td>0.59</td>\n      <td>0.5</td>\n      <td>0.32</td>\n      <td>0.28</td>\n      <td>0.2</td>\n      <td>0.03</td>\n    </tr>\n    <tr>\n      <th>sum</th>\n      <td>1667.53</td>\n      <td>855.77</td>\n      <td>1895.96</td>\n      <td>999.22</td>\n      <td>810.85</td>\n      <td>834.12</td>\n      <td>1506.3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"We see that B-ORG has highest mean loss, so it seems determining beginning of an ORG is the hardest for our model\n\nLet's look at confusion matrix:","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\nimport matplotlib.pyplot as plt\n\ndef plot_confusion_matrix(y_preds, y_true, labels):\n    cm = confusion_matrix(y_true, y_preds, normalize=\"true\")\n    fig, ax = plt.subplots(figsize=(6, 6))\n    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n    disp.plot(cmap=\"Greens\", values_format=\".2f\", ax=ax, colorbar=False)\n    plt.title(\"Normalized confusion matrix\")\n    plt.show()\n\nplot_confusion_matrix(df_tokens[\"labels\"], df_tokens[\"predicted_label\"], reference_tags.names)","metadata":{"execution":{"iopub.status.busy":"2024-02-13T06:41:40.248800Z","iopub.execute_input":"2024-02-13T06:41:40.249231Z","iopub.status.idle":"2024-02-13T06:41:40.958955Z","shell.execute_reply.started":"2024-02-13T06:41:40.249200Z","shell.execute_reply":"2024-02-13T06:41:40.957881Z"},"trusted":true},"execution_count":52,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 600x600 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"markdown","source":"So we see that B-ORG is often confused with I-ORG\n\nLet's now look at the SENTENCE level loss, after looking at token level:","metadata":{}},{"cell_type":"code","source":"def get_samples(df):\n    for _, row in df.iterrows():\n        labels, preds, tokens, losses = [], [], [], []\n        for i, mask in enumerate(row[\"attention_mask\"]):\n            if i not in {0, len(row[\"attention_mask\"])}:\n                labels.append(row[\"labels\"][i])\n                preds.append(row[\"predicted_label\"][i])\n                tokens.append(row[\"input_tokens\"][i])\n                losses.append(f\"{row['loss'][i]:.2f}\")\n        \n        df_tmp = pd.DataFrame({\"tokens\": tokens, \"labels\": labels, \"preds\": preds, \"losses\": losses}).T\n        \n        yield df_tmp\n\ndf[\"total_loss\"] = df[\"loss\"].apply(sum)\ndf_tmp = df.sort_values(by=\"total_loss\", ascending=False).head(3)\n\nfor sample in get_samples(df_tmp):\n    display(sample)","metadata":{"execution":{"iopub.status.busy":"2024-02-13T06:43:34.699843Z","iopub.execute_input":"2024-02-13T06:43:34.700287Z","iopub.status.idle":"2024-02-13T06:43:34.832440Z","shell.execute_reply.started":"2024-02-13T06:43:34.700236Z","shell.execute_reply":"2024-02-13T06:43:34.831309Z"},"trusted":true},"execution_count":53,"outputs":[{"output_type":"display_data","data":{"text/plain":"          0     1      2      3     4     5      6      7      8      9   \\\ntokens    ▁'   ▁''     ▁Τ      Κ   ▁''    ▁'     ▁'    ▁''     ▁T    ▁''   \nlabels     O     O      O    IGN     O     O  B-LOC  I-LOC  I-LOC  I-LOC   \npreds      O     O  B-ORG  I-ORG     O     O      O      O      O      O   \nlosses  0.00  0.00   4.06   0.00  0.00  0.00  10.65   9.93   8.22   8.11   \n\n           10    11     12     13    14     15     16    17    18  \ntokens     ▁'    ri    ▁''     ▁'     k    ▁''     ▁'   ala  </s>  \nlabels  I-LOC   IGN  I-LOC  I-LOC   IGN  I-LOC  I-LOC   IGN   IGN  \npreds       O     O      O      O     O      O      O     O     O  \nlosses   8.16  0.00   8.17   8.73  0.00   8.73   8.79  0.00  0.00  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n      <th>12</th>\n      <th>13</th>\n      <th>14</th>\n      <th>15</th>\n      <th>16</th>\n      <th>17</th>\n      <th>18</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>tokens</th>\n      <td>▁'</td>\n      <td>▁''</td>\n      <td>▁Τ</td>\n      <td>Κ</td>\n      <td>▁''</td>\n      <td>▁'</td>\n      <td>▁'</td>\n      <td>▁''</td>\n      <td>▁T</td>\n      <td>▁''</td>\n      <td>▁'</td>\n      <td>ri</td>\n      <td>▁''</td>\n      <td>▁'</td>\n      <td>k</td>\n      <td>▁''</td>\n      <td>▁'</td>\n      <td>ala</td>\n      <td>&lt;/s&gt;</td>\n    </tr>\n    <tr>\n      <th>labels</th>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>IGN</td>\n      <td>O</td>\n      <td>O</td>\n      <td>B-LOC</td>\n      <td>I-LOC</td>\n      <td>I-LOC</td>\n      <td>I-LOC</td>\n      <td>I-LOC</td>\n      <td>IGN</td>\n      <td>I-LOC</td>\n      <td>I-LOC</td>\n      <td>IGN</td>\n      <td>I-LOC</td>\n      <td>I-LOC</td>\n      <td>IGN</td>\n      <td>IGN</td>\n    </tr>\n    <tr>\n      <th>preds</th>\n      <td>O</td>\n      <td>O</td>\n      <td>B-ORG</td>\n      <td>I-ORG</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>losses</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>4.06</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>10.65</td>\n      <td>9.93</td>\n      <td>8.22</td>\n      <td>8.11</td>\n      <td>8.16</td>\n      <td>0.00</td>\n      <td>8.17</td>\n      <td>8.73</td>\n      <td>0.00</td>\n      <td>8.73</td>\n      <td>8.79</td>\n      <td>0.00</td>\n      <td>0.00</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"           0     1     2      3      4      5         6     7      8      9   \\\ntokens    ▁''     8     .  ▁Juli    ▁''     ▁:  ▁Protest  camp   ▁auf   ▁dem   \nlabels  B-ORG   IGN   IGN  I-ORG  I-ORG  I-ORG     I-ORG   IGN  I-ORG  I-ORG   \npreds       O     O     O      O      O      O         O     O      O      O   \nlosses   8.45  0.00  0.00   6.86   8.47   8.42      6.51  0.00   7.06   8.24   \n\n              10     11          12     13      14     15     16    17  \ntokens  ▁Gelände   ▁der  ▁Republika      n  ischen   ▁Gar     de  </s>  \nlabels     I-ORG  I-ORG       I-ORG    IGN     IGN  I-ORG    IGN   IGN  \npreds          O      O       B-ORG  I-ORG   I-ORG  I-ORG  I-ORG     O  \nlosses      6.77   4.54        4.63   0.00    0.00   0.01   0.00  0.00  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n      <th>12</th>\n      <th>13</th>\n      <th>14</th>\n      <th>15</th>\n      <th>16</th>\n      <th>17</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>tokens</th>\n      <td>▁''</td>\n      <td>8</td>\n      <td>.</td>\n      <td>▁Juli</td>\n      <td>▁''</td>\n      <td>▁:</td>\n      <td>▁Protest</td>\n      <td>camp</td>\n      <td>▁auf</td>\n      <td>▁dem</td>\n      <td>▁Gelände</td>\n      <td>▁der</td>\n      <td>▁Republika</td>\n      <td>n</td>\n      <td>ischen</td>\n      <td>▁Gar</td>\n      <td>de</td>\n      <td>&lt;/s&gt;</td>\n    </tr>\n    <tr>\n      <th>labels</th>\n      <td>B-ORG</td>\n      <td>IGN</td>\n      <td>IGN</td>\n      <td>I-ORG</td>\n      <td>I-ORG</td>\n      <td>I-ORG</td>\n      <td>I-ORG</td>\n      <td>IGN</td>\n      <td>I-ORG</td>\n      <td>I-ORG</td>\n      <td>I-ORG</td>\n      <td>I-ORG</td>\n      <td>I-ORG</td>\n      <td>IGN</td>\n      <td>IGN</td>\n      <td>I-ORG</td>\n      <td>IGN</td>\n      <td>IGN</td>\n    </tr>\n    <tr>\n      <th>preds</th>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>B-ORG</td>\n      <td>I-ORG</td>\n      <td>I-ORG</td>\n      <td>I-ORG</td>\n      <td>I-ORG</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>losses</th>\n      <td>8.45</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>6.86</td>\n      <td>8.47</td>\n      <td>8.42</td>\n      <td>6.51</td>\n      <td>0.00</td>\n      <td>7.06</td>\n      <td>8.24</td>\n      <td>6.77</td>\n      <td>4.54</td>\n      <td>4.63</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.01</td>\n      <td>0.00</td>\n      <td>0.00</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"             0         1       2            3         4      5        6   \\\ntokens  ▁United  ▁Nations  ▁Multi  dimensional  ▁Integra    ted  ▁Stabil   \nlabels    B-PER     I-PER   I-PER          IGN     I-PER    IGN    I-PER   \npreds     B-ORG     I-ORG   I-ORG        I-ORG     I-ORG  I-ORG    I-ORG   \nlosses     7.31      6.30    6.22         0.00      6.13   0.00     6.08   \n\n             7         8      9      10        11        12         13     14  \ntokens  ization  ▁Mission    ▁in   ▁the  ▁Central  ▁African  ▁Republic   </s>  \nlabels      IGN     I-PER  I-PER  I-PER     I-PER     I-PER      I-PER    IGN  \npreds     I-ORG     I-ORG  I-ORG  I-ORG     I-ORG     I-ORG      I-ORG  I-ORG  \nlosses     0.00      6.01   5.48   5.92      6.47      6.33       6.24   0.00  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n      <th>12</th>\n      <th>13</th>\n      <th>14</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>tokens</th>\n      <td>▁United</td>\n      <td>▁Nations</td>\n      <td>▁Multi</td>\n      <td>dimensional</td>\n      <td>▁Integra</td>\n      <td>ted</td>\n      <td>▁Stabil</td>\n      <td>ization</td>\n      <td>▁Mission</td>\n      <td>▁in</td>\n      <td>▁the</td>\n      <td>▁Central</td>\n      <td>▁African</td>\n      <td>▁Republic</td>\n      <td>&lt;/s&gt;</td>\n    </tr>\n    <tr>\n      <th>labels</th>\n      <td>B-PER</td>\n      <td>I-PER</td>\n      <td>I-PER</td>\n      <td>IGN</td>\n      <td>I-PER</td>\n      <td>IGN</td>\n      <td>I-PER</td>\n      <td>IGN</td>\n      <td>I-PER</td>\n      <td>I-PER</td>\n      <td>I-PER</td>\n      <td>I-PER</td>\n      <td>I-PER</td>\n      <td>I-PER</td>\n      <td>IGN</td>\n    </tr>\n    <tr>\n      <th>preds</th>\n      <td>B-ORG</td>\n      <td>I-ORG</td>\n      <td>I-ORG</td>\n      <td>I-ORG</td>\n      <td>I-ORG</td>\n      <td>I-ORG</td>\n      <td>I-ORG</td>\n      <td>I-ORG</td>\n      <td>I-ORG</td>\n      <td>I-ORG</td>\n      <td>I-ORG</td>\n      <td>I-ORG</td>\n      <td>I-ORG</td>\n      <td>I-ORG</td>\n      <td>I-ORG</td>\n    </tr>\n    <tr>\n      <th>losses</th>\n      <td>7.31</td>\n      <td>6.30</td>\n      <td>6.22</td>\n      <td>0.00</td>\n      <td>6.13</td>\n      <td>0.00</td>\n      <td>6.08</td>\n      <td>0.00</td>\n      <td>6.01</td>\n      <td>5.48</td>\n      <td>5.92</td>\n      <td>6.47</td>\n      <td>6.33</td>\n      <td>6.24</td>\n      <td>0.00</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# In the above we see an explanation for why these sentences are bad -\n# we note for ex that Central African Republic is annotated as PER, 8 Juli is annotated ORG etc\n\"\"\" It turns out the annotations for the PAN-X dataset were generated through an automated process.\nSuch annotations are often referred to as “silver standard” (in contrast to the “gold\nstandard” of human-generated annotations), and it is no surprise that there are cases\nwhere the automated approach failed to produce sensible labels. In fact, such failure\nmodes are not unique to automatic approaches; even when humans carefully anno‐\ntate data, mistakes can occur when the concentration of the annotators fades or they\nsimply misunderstand the sentence.\"\"\"\n\n# we saw parens and slashes had high losses - here are sentences starting with them:\ndf_tmp = df.loc[df[\"input_tokens\"].apply(lambda x: u\"\\u2581(\" in x)].head(2)\nfor sample in get_samples(df_tmp):\n    display(sample)","metadata":{"execution":{"iopub.status.busy":"2024-02-13T06:53:48.400264Z","iopub.execute_input":"2024-02-13T06:53:48.401151Z","iopub.status.idle":"2024-02-13T06:53:48.431967Z","shell.execute_reply.started":"2024-02-13T06:53:48.401112Z","shell.execute_reply":"2024-02-13T06:53:48.430910Z"},"trusted":true},"execution_count":54,"outputs":[{"output_type":"display_data","data":{"text/plain":"            0      1      2             3      4      5\ntokens   ▁Ham      a     ▁(  ▁Unternehmen     ▁)   </s>\nlabels  B-ORG    IGN  I-ORG         I-ORG  I-ORG    IGN\npreds   B-ORG  I-ORG  I-ORG         I-ORG  I-ORG  I-ORG\nlosses   0.01   0.00   0.01          0.01   0.01   0.00","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>tokens</th>\n      <td>▁Ham</td>\n      <td>a</td>\n      <td>▁(</td>\n      <td>▁Unternehmen</td>\n      <td>▁)</td>\n      <td>&lt;/s&gt;</td>\n    </tr>\n    <tr>\n      <th>labels</th>\n      <td>B-ORG</td>\n      <td>IGN</td>\n      <td>I-ORG</td>\n      <td>I-ORG</td>\n      <td>I-ORG</td>\n      <td>IGN</td>\n    </tr>\n    <tr>\n      <th>preds</th>\n      <td>B-ORG</td>\n      <td>I-ORG</td>\n      <td>I-ORG</td>\n      <td>I-ORG</td>\n      <td>I-ORG</td>\n      <td>I-ORG</td>\n    </tr>\n    <tr>\n      <th>losses</th>\n      <td>0.01</td>\n      <td>0.00</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.00</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"            0      1      2      3      4      5      6      7\ntokens  ▁Kesk    kül      a     ▁(  ▁Mart     na     ▁)   </s>\nlabels  B-LOC    IGN    IGN  I-LOC  I-LOC    IGN  I-LOC    IGN\npreds   B-LOC  I-LOC  I-LOC  I-LOC  I-LOC  I-LOC  I-LOC  I-LOC\nlosses   0.02   0.00   0.00   0.02   0.02   0.00   0.02   0.00","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>tokens</th>\n      <td>▁Kesk</td>\n      <td>kül</td>\n      <td>a</td>\n      <td>▁(</td>\n      <td>▁Mart</td>\n      <td>na</td>\n      <td>▁)</td>\n      <td>&lt;/s&gt;</td>\n    </tr>\n    <tr>\n      <th>labels</th>\n      <td>B-LOC</td>\n      <td>IGN</td>\n      <td>IGN</td>\n      <td>I-LOC</td>\n      <td>I-LOC</td>\n      <td>IGN</td>\n      <td>I-LOC</td>\n      <td>IGN</td>\n    </tr>\n    <tr>\n      <th>preds</th>\n      <td>B-LOC</td>\n      <td>I-LOC</td>\n      <td>I-LOC</td>\n      <td>I-LOC</td>\n      <td>I-LOC</td>\n      <td>I-LOC</td>\n      <td>I-LOC</td>\n      <td>I-LOC</td>\n    </tr>\n    <tr>\n      <th>losses</th>\n      <td>0.02</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.02</td>\n      <td>0.02</td>\n      <td>0.00</td>\n      <td>0.02</td>\n      <td>0.00</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"\"\"\"In general we would not include the parentheses and their contents as part of the\nnamed entity, but this seems to be the way the automatic extraction annotated the\ndocuments. In the other examples, the parentheses contain a geographic specification.\nWhile this is indeed a location as well, we might want disconnect it from the original\nlocation in the annotations. This dataset consists of Wikipedia articles in different\nlanguages, and the article titles often contain some sort of explanation in parentheses.\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-02-13T06:54:20.096236Z","iopub.execute_input":"2024-02-13T06:54:20.096628Z","iopub.status.idle":"2024-02-13T06:54:20.103502Z","shell.execute_reply.started":"2024-02-13T06:54:20.096596Z","shell.execute_reply":"2024-02-13T06:54:20.102608Z"},"trusted":true},"execution_count":55,"outputs":[{"execution_count":55,"output_type":"execute_result","data":{"text/plain":"'In general we would not include the parentheses and their contents as part of the\\nnamed entity, but this seems to be the way the automatic extraction annotated the\\ndocuments. In the other examples, the parentheses contain a geographic specification.\\nWhile this is indeed a location as well, we might want disconnect it from the original\\nlocation in the annotations. This dataset consists of Wikipedia articles in different\\nlanguages, and the article titles often contain some sort of explanation in parentheses.'"},"metadata":{}}]},{"cell_type":"code","source":"# rest of chapter is traning on multilingual part ","metadata":{},"execution_count":null,"outputs":[]}]}