{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Post training notes / reminders\n\n\n**ALSO: seem to require force cu121 torch due to changes in unsloth ongoing October 2024 - couldn't reuse same pip installs as I did in september O_o**\n\n---\n\n\n- this is only 60 steps\n- **I think i managed to get the Train on Completions Only stuff to work with the collator (loss does indeed go down and results are sensible with a few test inferences - before I had loss stuck at 0 on previous notebooks attempts)**\n- filtered dataset so use only \"good samples\" see code below (there is metadata for the synthetic dataset)\n- **MISTAKE/notebook example:** USES Llama3.1 NOT THE INSTRUCT VERSION as the base model O_o **redo with instruct**\n\n- still can't get the GGUF to work on Kaggle, disk size it seems is problem","metadata":{}},{"cell_type":"code","source":"%%capture\n!pip install pip3-autoremove\n!pip-autoremove torch torchvision torchaudio -y\n!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n!pip install unsloth\n\n\nimport os\nos.environ[\"WANDB_DISABLED\"] = \"true\"","metadata":{"execution":{"iopub.status.busy":"2024-10-27T16:19:13.506893Z","iopub.execute_input":"2024-10-27T16:19:13.507451Z","iopub.status.idle":"2024-10-27T16:22:46.558929Z","shell.execute_reply.started":"2024-10-27T16:19:13.507418Z","shell.execute_reply":"2024-10-27T16:22:46.557574Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from unsloth import FastLanguageModel\nimport torch\nmax_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\ndtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\nload_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.","metadata":{"execution":{"iopub.status.busy":"2024-10-27T16:23:52.181868Z","iopub.execute_input":"2024-10-27T16:23:52.182286Z","iopub.status.idle":"2024-10-27T16:23:52.188449Z","shell.execute_reply.started":"2024-10-27T16:23:52.182250Z","shell.execute_reply":"2024-10-27T16:23:52.187259Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"model, tokenizer = FastLanguageModel.from_pretrained(\n    model_name = \"unsloth/Meta-Llama-3.1-8B\",\n    max_seq_length = max_seq_length,\n    dtype = dtype,\n    load_in_4bit = load_in_4bit,\n    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-27T16:23:54.749900Z","iopub.execute_input":"2024-10-27T16:23:54.750305Z","iopub.status.idle":"2024-10-27T16:24:09.685325Z","shell.execute_reply.started":"2024-10-27T16:23:54.750269Z","shell.execute_reply":"2024-10-27T16:24:09.684386Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"==((====))==  Unsloth 2024.10.7: Fast Llama patching. Transformers = 4.44.2.\n   \\\\   /|    GPU: Tesla T4. Max memory: 14.741 GB. Platform = Linux.\nO^O/ \\_/ \\    Pytorch: 2.5.0+cu121. CUDA = 7.5. CUDA Toolkit = 12.1.\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.28.post2. FA2 = False]\n \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/230 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"35a954d3863e40afa11cf74c690f5891"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/50.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a2b057a51a94cf4bf4bdcf461c0249b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f56a0ba8fac4052b44ca0198469a5d1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/345 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"134b5ab5c8904d3dae8e8eb7294b78e3"}},"metadata":{}},{"name":"stderr","text":"Unsloth: We fixed a gradient accumulation bug, but it seems like you don't have the latest transformers version!\nPlease update transformers, TRL and unsloth via:\n`pip install --upgrade --no-cache-dir unsloth git+https://github.com/huggingface/transformers.git git+https://github.com/huggingface/trl.git`\n","output_type":"stream"}]},{"cell_type":"code","source":"model = FastLanguageModel.get_peft_model(\n    model,\n    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n    lora_alpha = 16,\n    lora_dropout = 0, # Supports any, but = 0 is optimized\n    bias = \"none\",    # Supports any, but = \"none\" is optimized\n    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n    random_state = 3407,\n    use_rslora = False,  # We support rank stabilized LoRA\n    loftq_config = None, # And LoftQ\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-27T16:24:14.467926Z","iopub.execute_input":"2024-10-27T16:24:14.468334Z","iopub.status.idle":"2024-10-27T16:24:20.520373Z","shell.execute_reply.started":"2024-10-27T16:24:14.468298Z","shell.execute_reply":"2024-10-27T16:24:20.519360Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"Unsloth 2024.10.7 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Dataset prep\n\n- care large dataset - here i filtered on some kind of quality metric they have on their synthetic data","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\n\n\nfull_pii_ds = load_dataset(\"gretelai/synthetic_pii_finance_multilingual\")","metadata":{"execution":{"iopub.status.busy":"2024-10-27T16:24:24.864203Z","iopub.execute_input":"2024-10-27T16:24:24.865230Z","iopub.status.idle":"2024-10-27T16:24:29.071835Z","shell.execute_reply.started":"2024-10-27T16:24:24.865155Z","shell.execute_reply":"2024-10-27T16:24:29.071084Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/14.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c490340120bd4badb3924abe0514f913"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/48.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a8a93c5afa1541d19220e6250761d9af"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/5.42M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"742d1d5131c84b9f8997679e600b1271"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/50346 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9fe4676f15334fccb92136fc9706edf8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/5594 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85a4268f215f4cc198ec9083f27905c5"}},"metadata":{}}]},{"cell_type":"code","source":"full_pii_ds","metadata":{"execution":{"iopub.status.busy":"2024-10-27T16:24:30.329968Z","iopub.execute_input":"2024-10-27T16:24:30.330369Z","iopub.status.idle":"2024-10-27T16:24:30.337933Z","shell.execute_reply.started":"2024-10-27T16:24:30.330330Z","shell.execute_reply":"2024-10-27T16:24:30.337005Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['level_0', 'index', 'document_type', 'document_description', 'expanded_type', 'expanded_description', 'language', 'language_description', 'domain', 'generated_text', 'pii_spans', 'conformance_score', 'quality_score', 'toxicity_score', 'bias_score', 'groundedness_score'],\n        num_rows: 50346\n    })\n    test: Dataset({\n        features: ['level_0', 'index', 'document_type', 'document_description', 'expanded_type', 'expanded_description', 'language', 'language_description', 'domain', 'generated_text', 'pii_spans', 'conformance_score', 'quality_score', 'toxicity_score', 'bias_score', 'groundedness_score'],\n        num_rows: 5594\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"full_pii_ds[\"train\"][0]","metadata":{"execution":{"iopub.status.busy":"2024-10-27T16:24:32.559032Z","iopub.execute_input":"2024-10-27T16:24:32.559897Z","iopub.status.idle":"2024-10-27T16:24:32.571470Z","shell.execute_reply.started":"2024-10-27T16:24:32.559850Z","shell.execute_reply":"2024-10-27T16:24:32.570133Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"{'level_0': 40012,\n 'index': 40012,\n 'document_type': 'Supply Chain Management Agreement',\n 'document_description': 'A legal contract outlining the terms and conditions of managing the flow of goods and services within a supply chain, including responsibilities and performance metrics.',\n 'expanded_type': 'Vendor Management Contract',\n 'expanded_description': 'This subtype involves the contractual agreements and guidelines for managing vendors within the supply chain. It covers aspects such as vendor selection, performance evaluation, and dispute resolution procedures.',\n 'language': 'English',\n 'language_description': 'English language as spoken in the United States, the UK, or Canada',\n 'domain': 'finance',\n 'generated_text': 'SUPPLY CHAIN MANAGEMENT AGREEMENT\\n\\nThis Supply Chain Management Agreement (the \"Agreement\") is entered into as of this 1st day of March, 2021 (the \"Effective Date\"), by and between Cameron-Mcknight, a company organized and existing under the laws of the state of Delaware, with its head office located at 81685 Lopez Lodge, Apt. 6502, hereinafter referred to as \"Cameron-Mcknight\", and Jann N. Butte, an individual with a mailing address of 81685 Lopez Lodge, Apt. 6502.\\n\\nWHEREAS, Cameron-Mcknight desires to engage the services of Vendor for the provision of goods and services in connection with Cameron-Mcknight\\'s supply chain operations; and\\n\\nWHEREAS, Vendor desires to provide such goods and services to Cameron-Mcknight on the terms and conditions set forth herein.\\n\\nNOW, THEREFORE, in consideration of the mutual covenants and promises contained herein, the parties hereto agree as follows:\\n\\n1. APPOINTMENT\\n\\nCameron-Mcknight hereby appoints Vendor as a vendor for the provision of goods and services in connection with Cameron-Mcknight\\'s supply chain operations. Vendor shall provide such goods and services in accordance with the terms and conditions set forth herein.\\n\\n2. TERM\\n\\nThis Agreement shall commence on the Effective Date and shall continue in force for a period of one (1) year, unless earlier terminated in accordance with the provisions hereof.\\n\\n3. RESPONSIBILITIES OF VENDOR\\n\\n3.1. Performance. Vendor shall perform its obligations under this Agreement in a professional and workmanlike manner in accordance with industry standards.\\n\\n3.2. Compliance. Vendor shall comply with all applicable laws, rules, and regulations in connection with its performance under this Agreement.\\n\\n3.3. Confidentiality. Vendor shall maintain the confidentiality of all confidential information of Cameron-Mcknight and shall not disclose such confidential information to any third party without the prior written consent of Cameron-Mcknight.\\n\\n4. PERFORMANCE METRICS\\n\\nCamer',\n 'pii_spans': '[{\"start\": 119, \"end\": 141, \"label\": \"date\"}, {\"start\": 181, \"end\": 197, \"label\": \"company\"}, {\"start\": 305, \"end\": 333, \"label\": \"street_address\"}, {\"start\": 363, \"end\": 379, \"label\": \"company\"}, {\"start\": 386, \"end\": 399, \"label\": \"name\"}, {\"start\": 441, \"end\": 469, \"label\": \"street_address\"}, {\"start\": 481, \"end\": 497, \"label\": \"company\"}, {\"start\": 598, \"end\": 614, \"label\": \"company\"}, {\"start\": 709, \"end\": 725, \"label\": \"company\"}, {\"start\": 915, \"end\": 931, \"label\": \"company\"}, {\"start\": 1026, \"end\": 1042, \"label\": \"company\"}, {\"start\": 1797, \"end\": 1813, \"label\": \"company\"}, {\"start\": 1923, \"end\": 1939, \"label\": \"company\"}, {\"start\": 1283, \"end\": 1295, \"label\": \"date\"}]',\n 'conformance_score': 85,\n 'quality_score': 90,\n 'toxicity_score': 5,\n 'bias_score': 15,\n 'groundedness_score': 95}"},"metadata":{}}]},{"cell_type":"code","source":"good_data = full_pii_ds.filter(lambda x : x[\"conformance_score\"] > 90)","metadata":{"execution":{"iopub.status.busy":"2024-10-27T16:24:34.807960Z","iopub.execute_input":"2024-10-27T16:24:34.808370Z","iopub.status.idle":"2024-10-27T16:24:36.516857Z","shell.execute_reply.started":"2024-10-27T16:24:34.808332Z","shell.execute_reply":"2024-10-27T16:24:36.515991Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/50346 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dba5948c98e041aeb90c52700bd9828f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/5594 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cdf118d1a27c441e81cce79a61cbca8b"}},"metadata":{}}]},{"cell_type":"code","source":"good_data","metadata":{"execution":{"iopub.status.busy":"2024-10-27T16:24:38.321350Z","iopub.execute_input":"2024-10-27T16:24:38.322002Z","iopub.status.idle":"2024-10-27T16:24:38.328082Z","shell.execute_reply.started":"2024-10-27T16:24:38.321959Z","shell.execute_reply":"2024-10-27T16:24:38.327063Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['level_0', 'index', 'document_type', 'document_description', 'expanded_type', 'expanded_description', 'language', 'language_description', 'domain', 'generated_text', 'pii_spans', 'conformance_score', 'quality_score', 'toxicity_score', 'bias_score', 'groundedness_score'],\n        num_rows: 9197\n    })\n    test: Dataset({\n        features: ['level_0', 'index', 'document_type', 'document_description', 'expanded_type', 'expanded_description', 'language', 'language_description', 'domain', 'generated_text', 'pii_spans', 'conformance_score', 'quality_score', 'toxicity_score', 'bias_score', 'groundedness_score'],\n        num_rows: 1040\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"import json","metadata":{"execution":{"iopub.status.busy":"2024-10-27T16:24:40.684254Z","iopub.execute_input":"2024-10-27T16:24:40.684684Z","iopub.status.idle":"2024-10-27T16:24:40.689535Z","shell.execute_reply.started":"2024-10-27T16:24:40.684645Z","shell.execute_reply":"2024-10-27T16:24:40.688358Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# i converted to uppsercase\nPII_LABELS = ['ACCOUNT_PIN', 'API_KEY', 'BANK_ROUTING_NUMBER', 'BBAN', 'COMPANY', 'CREDIT_CARD_NUMBER', 'CREDIT_CARD_SECURITY_CODE', 'CUSTOMER_ID', 'DATE', 'DATE_OF_BIRTH', 'DATE_TIME', 'DRIVER_LICENSE_NUMBER', 'EMAIL', 'EMPLOYEE_ID', 'FIRST_NAME', 'IBAN', 'IPV4', 'IPV6', 'LAST_NAME', 'LOCAL_LATLNG', 'NAME', 'PASSPORT_NUMBER', 'PASSWORD', 'PHONE_NUMBER', 'SSN', 'STREET_ADDRESS', 'SWIFT_BIC_CODE', 'TIME', 'USER_NAME']","metadata":{"execution":{"iopub.status.busy":"2024-10-27T16:24:42.129438Z","iopub.execute_input":"2024-10-27T16:24:42.129906Z","iopub.status.idle":"2024-10-27T16:24:42.136130Z","shell.execute_reply.started":"2024-10-27T16:24:42.129851Z","shell.execute_reply":"2024-10-27T16:24:42.134844Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# ----------- important\n\n\nEOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n\n\n\n# must add to unsloth prompts it says O_o","metadata":{"execution":{"iopub.status.busy":"2024-10-27T16:25:20.671009Z","iopub.execute_input":"2024-10-27T16:25:20.671773Z","iopub.status.idle":"2024-10-27T16:25:20.676931Z","shell.execute_reply.started":"2024-10-27T16:25:20.671729Z","shell.execute_reply":"2024-10-27T16:25:20.675748Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def process_example(example):\n    curr_close_idx = 0\n    # iterate over dics of annotations, care account for closing index\n    processed_string = []\n    \n    orig_text = example[\"generated_text\"]\n    \n    pii_d = json.loads(example[\"pii_spans\"])\n\n    \n    for annot_d in pii_d:\n        s, e = annot_d[\"start\"], annot_d[\"end\"]\n        label = annot_d[\"label\"].upper()\n        \n        # add string up to this annotation\n        if s > curr_close_idx:\n            processed_string.append(orig_text[curr_close_idx:s])\n        \n        # update curr_close_idx\n        curr_close_idx = e\n        \n        # add the <TAG>xxxx</TAG>\n        tmp = f\"<START OF IDENTIFIABLE INFORMATION : {label}>{orig_text[s:e]}<END OF IDENTIFIABLE INFORMATION : {label}>\"\n        \n        processed_string.append(tmp)\n        \n    # handle end of sentence\n    if curr_close_idx < len(orig_text):\n        processed_string.append(orig_text[curr_close_idx:])\n    \n    pii_sequence_string = ''.join(processed_string)\n    \n    text_lang = example[\"language\"]\n    \n    llama3template = f\"\"\"Below is a DOCUMENT written in {text_lang} that may contain sensitive identifiable information, such as people's names or telephone numbers.\n\nFind all the sensitive identifiable information in the DOCUMENT and tag these sections of the DOCUMENT.\n\nUse only the tags in the IDENTIFIABLE INFORMATION TAGS list below.\n\nReply with a LABELLED DOCUMENT which contains all the sensitive identifiable information.\n\nFollow the formatting of the EXAMPLE given below without deviation.\n\n### EXAMPLE:\n\ndocument: \"My name is Bob Smith and you can call me on 0800-134-5813 today.\"\nlabelled document: \"My name is <START OF IDENTIFIABLE INFORMATION : NAME>Bob Smith<END OF IDENTIFIABLE INFORMATION : NAME> and you can call me on <START OF IDENTIFIABLE INFORMATION : PHONE_NUMBER>0800-134-5813<END OF IDENTIFIABLE INFORMATION : PHONE_NUMBER> today.\"\n\n### DOCUMENT:\n\n{orig_text}\n\n### IDENTIFIABLE INFORMATION TAGS:\n\n- ACCOUNT_PIN\n- API_KEY\n- BANK_ROUTING_NUMBER\n- BBAN\n- COMPANY\n- CREDIT_CARD_NUMBER\n- CREDIT_CARD_SECURITY_CODE\n- CUSTOMER_ID\n- DATE\n- DATE_OF_BIRTH\n- DATE_TIME\n- DRIVER_LICENSE_NUMBER\n- EMAIL\n- EMPLOYEE_ID\n- FIRST_NAME\n- IBAN\n- IPV4\n- IPV6\n- LAST_NAME\n- LOCAL_LATLNG\n- NAME\n- PASSPORT_NUMBER\n- PASSWORD\n- PHONE_NUMBER\n- SSN\n- STREET_ADDRESS\n- SWIFT_BIC_CODE\n- TIME\n- USER_NAME\n\n### LABELLED DOCUMENT:\n\n{pii_sequence_string}\"\"\"\n    \n    return llama3template + EOS_TOKEN # CARE! ADD MANUALLY\n    ","metadata":{"execution":{"iopub.status.busy":"2024-10-27T16:26:02.085372Z","iopub.execute_input":"2024-10-27T16:26:02.085828Z","iopub.status.idle":"2024-10-27T16:26:02.095139Z","shell.execute_reply.started":"2024-10-27T16:26:02.085790Z","shell.execute_reply":"2024-10-27T16:26:02.094092Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"print(process_example(good_data[\"train\"][0]))","metadata":{"execution":{"iopub.status.busy":"2024-10-27T16:26:05.866117Z","iopub.execute_input":"2024-10-27T16:26:05.867122Z","iopub.status.idle":"2024-10-27T16:26:05.874110Z","shell.execute_reply.started":"2024-10-27T16:26:05.867082Z","shell.execute_reply":"2024-10-27T16:26:05.873227Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Below is a DOCUMENT written in English that may contain sensitive identifiable information, such as people's names or telephone numbers.\n\nFind all the sensitive identifiable information in the DOCUMENT and tag these sections of the DOCUMENT.\n\nUse only the tags in the IDENTIFIABLE INFORMATION TAGS list below.\n\nReply with a LABELLED DOCUMENT which contains all the sensitive identifiable information.\n\nFollow the formatting of the EXAMPLE given below without deviation.\n\n### EXAMPLE:\n\ndocument: \"My name is Bob Smith and you can call me on 0800-134-5813 today.\"\nlabelled document: \"My name is <START OF IDENTIFIABLE INFORMATION : NAME>Bob Smith<END OF IDENTIFIABLE INFORMATION : NAME> and you can call me on <START OF IDENTIFIABLE INFORMATION : PHONE_NUMBER>0800-134-5813<END OF IDENTIFIABLE INFORMATION : PHONE_NUMBER> today.\"\n\n### DOCUMENT:\n\nSUPPLY CHAIN RESILIENCE FRAMEWORK\n\nThis Supply Chain Resilience Framework (the \"Agreement\") is entered into as of this 1st day of August, 2021, by and between Romeo R. Druso, residing at 406 Joshua Square, 08055, North Andrewberg (\"Client\") and LGWI52890450971869 (\"Service Provider\").\n\nWHEREAS, Client desires to engage Service Provider for the provision of supply chain management services, and Service Provider is willing to provide such services, subject to the terms and conditions set forth herein;\n\nNOW, THEREFORE, in consideration of the mutual covenants contained herein and for other good and valuable consideration, the receipt and sufficiency of which is hereby acknowledged, the parties agree as follows:\n\n1. Scope of Services. Service Provider agrees to provide supply chain management services to Client, including but not limited to risk diversification, contingency planning, and resilience metrics for maintaining operational continuity.\n\n2. Risk Diversification. Service Provider shall develop and implement a risk diversification strategy for Client's supply chain, which may include diversifying suppliers, transportation routes, and inventory sources.\n\n3. Contingency Planning. Service Provider shall create and maintain a contingency plan for Client's supply chain, which shall address potential disruptions, including natural disasters, political instability, and other unforeseen events.\n\n4. Resilience Metrics. Service Provider shall establish and track resilience metrics for Client's supply chain, which may include lead times, inventory levels, and service level agreements.\n\n5. Performance Standards. Service Provider shall use commercially reasonable efforts to meet the following performance standards:\n\na. Response Time: Service Provider shall respond to Client inquiries within two (2) business hours.\n\nb. Resolution Time: Service Provider shall resolve Client issues within two (2) business days.\n\nc. Uptime: Service Provider's platform shall be available 99.9% of the time, excluding scheduled maintenance.\n\n6. Term and Termination. This Agreement shall commence on the date first set forth above and shall continue for a term of one\n\n### IDENTIFIABLE INFORMATION TAGS:\n\n- ACCOUNT_PIN\n- API_KEY\n- BANK_ROUTING_NUMBER\n- BBAN\n- COMPANY\n- CREDIT_CARD_NUMBER\n- CREDIT_CARD_SECURITY_CODE\n- CUSTOMER_ID\n- DATE\n- DATE_OF_BIRTH\n- DATE_TIME\n- DRIVER_LICENSE_NUMBER\n- EMAIL\n- EMPLOYEE_ID\n- FIRST_NAME\n- IBAN\n- IPV4\n- IPV6\n- LAST_NAME\n- LOCAL_LATLNG\n- NAME\n- PASSPORT_NUMBER\n- PASSWORD\n- PHONE_NUMBER\n- SSN\n- STREET_ADDRESS\n- SWIFT_BIC_CODE\n- TIME\n- USER_NAME\n\n### LABELLED DOCUMENT:\n\nSUPPLY CHAIN RESILIENCE FRAMEWORK\n\nThis Supply Chain Resilience Framework (the \"Agreement\") is entered into as of this <START OF IDENTIFIABLE INFORMATION : DATE>1st day of August, 2021<END OF IDENTIFIABLE INFORMATION : DATE>, by and between <START OF IDENTIFIABLE INFORMATION : NAME>Romeo R. Druso<END OF IDENTIFIABLE INFORMATION : NAME>, residing at <START OF IDENTIFIABLE INFORMATION : STREET_ADDRESS>406 Joshua Square, 08055, North Andrewberg<END OF IDENTIFIABLE INFORMATION : STREET_ADDRESS> (\"Client\") and <START OF IDENTIFIABLE INFORMATION : BBAN>LGWI52890450971869<END OF IDENTIFIABLE INFORMATION : BBAN> (\"Service Provider\").\n\nWHEREAS, Client desires to engage Service Provider for the provision of supply chain management services, and Service Provider is willing to provide such services, subject to the terms and conditions set forth herein;\n\nNOW, THEREFORE, in consideration of the mutual covenants contained herein and for other good and valuable consideration, the receipt and sufficiency of which is hereby acknowledged, the parties agree as follows:\n\n1. Scope of Services. Service Provider agrees to provide supply chain management services to Client, including but not limited to risk diversification, contingency planning, and resilience metrics for maintaining operational continuity.\n\n2. Risk Diversification. Service Provider shall develop and implement a risk diversification strategy for Client's supply chain, which may include diversifying suppliers, transportation routes, and inventory sources.\n\n3. Contingency Planning. Service Provider shall create and maintain a contingency plan for Client's supply chain, which shall address potential disruptions, including natural disasters, political instability, and other unforeseen events.\n\n4. Resilience Metrics. Service Provider shall establish and track resilience metrics for Client's supply chain, which may include lead times, inventory levels, and service level agreements.\n\n5. Performance Standards. Service Provider shall use commercially reasonable efforts to meet the following performance standards:\n\na. Response Time: Service Provider shall respond to Client inquiries within two (2) business hours.\n\nb. Resolution Time: Service Provider shall resolve Client issues within two (2) business days.\n\nc. Uptime: Service Provider's platform shall be available 99.9% of the time, excluding scheduled maintenance.\n\n6. Term and Termination. This Agreement shall commence on the date first set forth above and shall continue for a term of one<|end_of_text|>\n","output_type":"stream"}]},{"cell_type":"code","source":"# BUILD TRAIN DATASET\n\nllama3_train_dataset = []\n\nfor example in good_data[\"train\"]:\n    x = process_example(example)\n    if x is not None:\n        llama3_train_dataset.append(x)","metadata":{"execution":{"iopub.status.busy":"2024-10-27T16:26:45.638980Z","iopub.execute_input":"2024-10-27T16:26:45.639885Z","iopub.status.idle":"2024-10-27T16:26:48.202122Z","shell.execute_reply.started":"2024-10-27T16:26:45.639837Z","shell.execute_reply":"2024-10-27T16:26:48.201134Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"len(llama3_train_dataset)","metadata":{"execution":{"iopub.status.busy":"2024-10-27T16:26:51.166409Z","iopub.execute_input":"2024-10-27T16:26:51.167261Z","iopub.status.idle":"2024-10-27T16:26:51.174366Z","shell.execute_reply.started":"2024-10-27T16:26:51.167209Z","shell.execute_reply":"2024-10-27T16:26:51.173163Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"9197"},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd\nfrom datasets import Dataset\n\n# convert to HF dataset\ndf = pd.DataFrame(llama3_train_dataset)\ntrain_data = Dataset.from_pandas(df.rename(columns={0: \"text\"}), split=\"train\")","metadata":{"execution":{"iopub.status.busy":"2024-10-27T16:27:11.069151Z","iopub.execute_input":"2024-10-27T16:27:11.070045Z","iopub.status.idle":"2024-10-27T16:27:11.362848Z","shell.execute_reply.started":"2024-10-27T16:27:11.070007Z","shell.execute_reply":"2024-10-27T16:27:11.362013Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"train_data[\"text\"][0]","metadata":{"execution":{"iopub.status.busy":"2024-10-27T16:28:13.149970Z","iopub.execute_input":"2024-10-27T16:28:13.150643Z","iopub.status.idle":"2024-10-27T16:28:13.198828Z","shell.execute_reply.started":"2024-10-27T16:28:13.150602Z","shell.execute_reply":"2024-10-27T16:28:13.197781Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"'Below is a DOCUMENT written in English that may contain sensitive identifiable information, such as people\\'s names or telephone numbers.\\n\\nFind all the sensitive identifiable information in the DOCUMENT and tag these sections of the DOCUMENT.\\n\\nUse only the tags in the IDENTIFIABLE INFORMATION TAGS list below.\\n\\nReply with a LABELLED DOCUMENT which contains all the sensitive identifiable information.\\n\\nFollow the formatting of the EXAMPLE given below without deviation.\\n\\n### EXAMPLE:\\n\\ndocument: \"My name is Bob Smith and you can call me on 0800-134-5813 today.\"\\nlabelled document: \"My name is <START OF IDENTIFIABLE INFORMATION : NAME>Bob Smith<END OF IDENTIFIABLE INFORMATION : NAME> and you can call me on <START OF IDENTIFIABLE INFORMATION : PHONE_NUMBER>0800-134-5813<END OF IDENTIFIABLE INFORMATION : PHONE_NUMBER> today.\"\\n\\n### DOCUMENT:\\n\\nSUPPLY CHAIN RESILIENCE FRAMEWORK\\n\\nThis Supply Chain Resilience Framework (the \"Agreement\") is entered into as of this 1st day of August, 2021, by and between Romeo R. Druso, residing at 406 Joshua Square, 08055, North Andrewberg (\"Client\") and LGWI52890450971869 (\"Service Provider\").\\n\\nWHEREAS, Client desires to engage Service Provider for the provision of supply chain management services, and Service Provider is willing to provide such services, subject to the terms and conditions set forth herein;\\n\\nNOW, THEREFORE, in consideration of the mutual covenants contained herein and for other good and valuable consideration, the receipt and sufficiency of which is hereby acknowledged, the parties agree as follows:\\n\\n1. Scope of Services. Service Provider agrees to provide supply chain management services to Client, including but not limited to risk diversification, contingency planning, and resilience metrics for maintaining operational continuity.\\n\\n2. Risk Diversification. Service Provider shall develop and implement a risk diversification strategy for Client\\'s supply chain, which may include diversifying suppliers, transportation routes, and inventory sources.\\n\\n3. Contingency Planning. Service Provider shall create and maintain a contingency plan for Client\\'s supply chain, which shall address potential disruptions, including natural disasters, political instability, and other unforeseen events.\\n\\n4. Resilience Metrics. Service Provider shall establish and track resilience metrics for Client\\'s supply chain, which may include lead times, inventory levels, and service level agreements.\\n\\n5. Performance Standards. Service Provider shall use commercially reasonable efforts to meet the following performance standards:\\n\\na. Response Time: Service Provider shall respond to Client inquiries within two (2) business hours.\\n\\nb. Resolution Time: Service Provider shall resolve Client issues within two (2) business days.\\n\\nc. Uptime: Service Provider\\'s platform shall be available 99.9% of the time, excluding scheduled maintenance.\\n\\n6. Term and Termination. This Agreement shall commence on the date first set forth above and shall continue for a term of one\\n\\n### IDENTIFIABLE INFORMATION TAGS:\\n\\n- ACCOUNT_PIN\\n- API_KEY\\n- BANK_ROUTING_NUMBER\\n- BBAN\\n- COMPANY\\n- CREDIT_CARD_NUMBER\\n- CREDIT_CARD_SECURITY_CODE\\n- CUSTOMER_ID\\n- DATE\\n- DATE_OF_BIRTH\\n- DATE_TIME\\n- DRIVER_LICENSE_NUMBER\\n- EMAIL\\n- EMPLOYEE_ID\\n- FIRST_NAME\\n- IBAN\\n- IPV4\\n- IPV6\\n- LAST_NAME\\n- LOCAL_LATLNG\\n- NAME\\n- PASSPORT_NUMBER\\n- PASSWORD\\n- PHONE_NUMBER\\n- SSN\\n- STREET_ADDRESS\\n- SWIFT_BIC_CODE\\n- TIME\\n- USER_NAME\\n\\n### LABELLED DOCUMENT:\\n\\nSUPPLY CHAIN RESILIENCE FRAMEWORK\\n\\nThis Supply Chain Resilience Framework (the \"Agreement\") is entered into as of this <START OF IDENTIFIABLE INFORMATION : DATE>1st day of August, 2021<END OF IDENTIFIABLE INFORMATION : DATE>, by and between <START OF IDENTIFIABLE INFORMATION : NAME>Romeo R. Druso<END OF IDENTIFIABLE INFORMATION : NAME>, residing at <START OF IDENTIFIABLE INFORMATION : STREET_ADDRESS>406 Joshua Square, 08055, North Andrewberg<END OF IDENTIFIABLE INFORMATION : STREET_ADDRESS> (\"Client\") and <START OF IDENTIFIABLE INFORMATION : BBAN>LGWI52890450971869<END OF IDENTIFIABLE INFORMATION : BBAN> (\"Service Provider\").\\n\\nWHEREAS, Client desires to engage Service Provider for the provision of supply chain management services, and Service Provider is willing to provide such services, subject to the terms and conditions set forth herein;\\n\\nNOW, THEREFORE, in consideration of the mutual covenants contained herein and for other good and valuable consideration, the receipt and sufficiency of which is hereby acknowledged, the parties agree as follows:\\n\\n1. Scope of Services. Service Provider agrees to provide supply chain management services to Client, including but not limited to risk diversification, contingency planning, and resilience metrics for maintaining operational continuity.\\n\\n2. Risk Diversification. Service Provider shall develop and implement a risk diversification strategy for Client\\'s supply chain, which may include diversifying suppliers, transportation routes, and inventory sources.\\n\\n3. Contingency Planning. Service Provider shall create and maintain a contingency plan for Client\\'s supply chain, which shall address potential disruptions, including natural disasters, political instability, and other unforeseen events.\\n\\n4. Resilience Metrics. Service Provider shall establish and track resilience metrics for Client\\'s supply chain, which may include lead times, inventory levels, and service level agreements.\\n\\n5. Performance Standards. Service Provider shall use commercially reasonable efforts to meet the following performance standards:\\n\\na. Response Time: Service Provider shall respond to Client inquiries within two (2) business hours.\\n\\nb. Resolution Time: Service Provider shall resolve Client issues within two (2) business days.\\n\\nc. Uptime: Service Provider\\'s platform shall be available 99.9% of the time, excluding scheduled maintenance.\\n\\n6. Term and Termination. This Agreement shall commence on the date first set forth above and shall continue for a term of one<|end_of_text|>'"},"metadata":{}}]},{"cell_type":"code","source":"from trl import DataCollatorForCompletionOnlyLM","metadata":{"execution":{"iopub.status.busy":"2024-10-27T16:36:19.293339Z","iopub.execute_input":"2024-10-27T16:36:19.293759Z","iopub.status.idle":"2024-10-27T16:36:19.298454Z","shell.execute_reply.started":"2024-10-27T16:36:19.293720Z","shell.execute_reply":"2024-10-27T16:36:19.297459Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"completions_only_collator = DataCollatorForCompletionOnlyLM(\n    instruction_template=tokenizer.eos_token,\n    response_template=tokenizer.bos_token,\n    tokenizer=tokenizer,\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-27T16:37:49.959559Z","iopub.execute_input":"2024-10-27T16:37:49.960503Z","iopub.status.idle":"2024-10-27T16:37:49.965629Z","shell.execute_reply.started":"2024-10-27T16:37:49.960449Z","shell.execute_reply":"2024-10-27T16:37:49.964797Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"from trl import SFTTrainer\nfrom transformers import TrainingArguments\nfrom unsloth import is_bfloat16_supported\n\ntrainer = SFTTrainer(\n    model = model,\n    tokenizer = tokenizer,\n    train_dataset = train_data,\n    dataset_text_field = \"text\",\n    max_seq_length = max_seq_length,\n    dataset_num_proc = 2,\n    data_collator=completions_only_collator, # NOTE -- I ADDED THIS FOR THE COMPLETIONS ONLY STUFF\n    args = TrainingArguments(\n        per_device_train_batch_size = 2,\n        gradient_accumulation_steps = 4,\n        \n        # Use num_train_epochs = 1, warmup_ratio for full training runs!\n        warmup_steps = 5,\n        max_steps = 60,\n\n        learning_rate = 2e-4,\n        fp16 = not is_bfloat16_supported(),\n        bf16 = is_bfloat16_supported(),\n        logging_steps = 1,\n        optim = \"adamw_8bit\",\n        weight_decay = 0.01,\n        lr_scheduler_type = \"linear\",\n        seed = 3407,\n        output_dir = \"outputs\",\n    ),\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-27T16:37:52.593226Z","iopub.execute_input":"2024-10-27T16:37:52.593601Z","iopub.status.idle":"2024-10-27T16:38:13.844956Z","shell.execute_reply.started":"2024-10-27T16:37:52.593567Z","shell.execute_reply":"2024-10-27T16:38:13.843954Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stderr","text":"Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map (num_proc=2):   0%|          | 0/9197 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77eecf46b86a44fc845d55f19b8ad4a7"}},"metadata":{}},{"name":"stderr","text":"max_steps is given, it will override any value given in num_train_epochs\n","output_type":"stream"}]},{"cell_type":"code","source":"gpu_stats = torch.cuda.get_device_properties(0)\nstart_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\nmax_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\nprint(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\nprint(f\"{start_gpu_memory} GB of memory reserved.\")","metadata":{"execution":{"iopub.status.busy":"2024-10-27T16:38:52.474232Z","iopub.execute_input":"2024-10-27T16:38:52.474646Z","iopub.status.idle":"2024-10-27T16:38:52.481724Z","shell.execute_reply.started":"2024-10-27T16:38:52.474604Z","shell.execute_reply":"2024-10-27T16:38:52.480737Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"GPU = Tesla T4. Max memory = 14.741 GB.\n6.004 GB of memory reserved.\n","output_type":"stream"}]},{"cell_type":"code","source":"# go\n\n# TOOD: CHECK LOSS IS NON ZERO SINCE CURRENTLY YTRYING TO GET THE COMPLETIONS ONLY COLLATOR TO WORK DOC ON HF IS UNCLEAr\n\ntrainer_stats = trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-10-27T16:39:35.722690Z","iopub.execute_input":"2024-10-27T16:39:35.723081Z","iopub.status.idle":"2024-10-27T17:10:45.573890Z","shell.execute_reply.started":"2024-10-27T16:39:35.723043Z","shell.execute_reply":"2024-10-27T17:10:45.572907Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stderr","text":"==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n   \\\\   /|    Num examples = 9,197 | Num Epochs = 1\nO^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n\\        /    Total batch size = 8 | Total steps = 60\n \"-____-\"     Number of trainable parameters = 41,943,040\n","output_type":"stream"},{"name":"stdout","text":"**** Unsloth: Please use our fixed gradient_accumulation_steps by updating transformers, TRL and Unsloth!\n`pip install --upgrade --no-cache-dir unsloth git+https://github.com/huggingface/transformers.git git+https://github.com/huggingface/trl.git`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [60/60 30:30, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.826000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.803500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.825200</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.798700</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.756100</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.677300</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.697800</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.622500</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.510100</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.459300</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>0.507700</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>0.470600</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>0.444000</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>0.513600</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>0.418400</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>0.401100</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>0.447000</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>0.433700</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>0.340800</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>0.415400</td>\n    </tr>\n    <tr>\n      <td>21</td>\n      <td>0.374000</td>\n    </tr>\n    <tr>\n      <td>22</td>\n      <td>0.382600</td>\n    </tr>\n    <tr>\n      <td>23</td>\n      <td>0.349700</td>\n    </tr>\n    <tr>\n      <td>24</td>\n      <td>0.399200</td>\n    </tr>\n    <tr>\n      <td>25</td>\n      <td>0.414300</td>\n    </tr>\n    <tr>\n      <td>26</td>\n      <td>0.360400</td>\n    </tr>\n    <tr>\n      <td>27</td>\n      <td>0.382600</td>\n    </tr>\n    <tr>\n      <td>28</td>\n      <td>0.382900</td>\n    </tr>\n    <tr>\n      <td>29</td>\n      <td>0.338000</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>0.331800</td>\n    </tr>\n    <tr>\n      <td>31</td>\n      <td>0.343000</td>\n    </tr>\n    <tr>\n      <td>32</td>\n      <td>0.332800</td>\n    </tr>\n    <tr>\n      <td>33</td>\n      <td>0.418300</td>\n    </tr>\n    <tr>\n      <td>34</td>\n      <td>0.263500</td>\n    </tr>\n    <tr>\n      <td>35</td>\n      <td>0.347500</td>\n    </tr>\n    <tr>\n      <td>36</td>\n      <td>0.318100</td>\n    </tr>\n    <tr>\n      <td>37</td>\n      <td>0.372900</td>\n    </tr>\n    <tr>\n      <td>38</td>\n      <td>0.355600</td>\n    </tr>\n    <tr>\n      <td>39</td>\n      <td>0.376900</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>0.285500</td>\n    </tr>\n    <tr>\n      <td>41</td>\n      <td>0.334900</td>\n    </tr>\n    <tr>\n      <td>42</td>\n      <td>0.380800</td>\n    </tr>\n    <tr>\n      <td>43</td>\n      <td>0.385400</td>\n    </tr>\n    <tr>\n      <td>44</td>\n      <td>0.393900</td>\n    </tr>\n    <tr>\n      <td>45</td>\n      <td>0.302700</td>\n    </tr>\n    <tr>\n      <td>46</td>\n      <td>0.385000</td>\n    </tr>\n    <tr>\n      <td>47</td>\n      <td>0.348600</td>\n    </tr>\n    <tr>\n      <td>48</td>\n      <td>0.318400</td>\n    </tr>\n    <tr>\n      <td>49</td>\n      <td>0.336700</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>0.389000</td>\n    </tr>\n    <tr>\n      <td>51</td>\n      <td>0.353600</td>\n    </tr>\n    <tr>\n      <td>52</td>\n      <td>0.329400</td>\n    </tr>\n    <tr>\n      <td>53</td>\n      <td>0.383300</td>\n    </tr>\n    <tr>\n      <td>54</td>\n      <td>0.301700</td>\n    </tr>\n    <tr>\n      <td>55</td>\n      <td>0.317000</td>\n    </tr>\n    <tr>\n      <td>56</td>\n      <td>0.400700</td>\n    </tr>\n    <tr>\n      <td>57</td>\n      <td>0.307300</td>\n    </tr>\n    <tr>\n      <td>58</td>\n      <td>0.410400</td>\n    </tr>\n    <tr>\n      <td>59</td>\n      <td>0.373600</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>0.327500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}]},{"cell_type":"code","source":"used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\nused_memory_for_lora = round(used_memory - start_gpu_memory, 3)\nused_percentage = round(used_memory         /max_memory*100, 3)\nlora_percentage = round(used_memory_for_lora/max_memory*100, 3)\nprint(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\nprint(f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\")\nprint(f\"Peak reserved memory = {used_memory} GB.\")\nprint(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\nprint(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\nprint(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")","metadata":{"execution":{"iopub.status.busy":"2024-10-27T17:12:30.400333Z","iopub.execute_input":"2024-10-27T17:12:30.400770Z","iopub.status.idle":"2024-10-27T17:12:30.409032Z","shell.execute_reply.started":"2024-10-27T17:12:30.400730Z","shell.execute_reply":"2024-10-27T17:12:30.408063Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"1865.3669 seconds used for training.\n31.09 minutes used for training.\nPeak reserved memory = 9.867 GB.\nPeak reserved memory for training = 3.863 GB.\nPeak reserved memory % of max memory = 66.936 %.\nPeak reserved memory for training % of max memory = 26.206 %.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Inference","metadata":{}},{"cell_type":"code","source":"inference_prompt_template = \"\"\"Below is a DOCUMENT written in {text_lang} that may contain sensitive identifiable information, such as people's names or telephone numbers.\n\nFind all the sensitive identifiable information in the DOCUMENT and tag these sections of the DOCUMENT.\n\nUse only the tags in the IDENTIFIABLE INFORMATION TAGS list below.\n\nReply with a LABELLED DOCUMENT which contains all the sensitive identifiable information.\n\nFollow the formatting of the EXAMPLE given below without deviation.\n\n### EXAMPLE:\n\ndocument: \"My name is Bob Smith and you can call me on 0800-134-5813 today.\"\nlabelled document: \"My name is <START OF IDENTIFIABLE INFORMATION : NAME>Bob Smith<END OF IDENTIFIABLE INFORMATION : NAME> and you can call me on <START OF IDENTIFIABLE INFORMATION : PHONE_NUMBER>0800-134-5813<END OF IDENTIFIABLE INFORMATION : PHONE_NUMBER> today.\"\n\n### DOCUMENT:\n\n{orig_text}\n\n### IDENTIFIABLE INFORMATION TAGS:\n\n- ACCOUNT_PIN\n- API_KEY\n- BANK_ROUTING_NUMBER\n- BBAN\n- COMPANY\n- CREDIT_CARD_NUMBER\n- CREDIT_CARD_SECURITY_CODE\n- CUSTOMER_ID\n- DATE\n- DATE_OF_BIRTH\n- DATE_TIME\n- DRIVER_LICENSE_NUMBER\n- EMAIL\n- EMPLOYEE_ID\n- FIRST_NAME\n- IBAN\n- IPV4\n- IPV6\n- LAST_NAME\n- LOCAL_LATLNG\n- NAME\n- PASSPORT_NUMBER\n- PASSWORD\n- PHONE_NUMBER\n- SSN\n- STREET_ADDRESS\n- SWIFT_BIC_CODE\n- TIME\n- USER_NAME\n\n### LABELLED DOCUMENT:\n\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-10-27T17:13:53.599585Z","iopub.execute_input":"2024-10-27T17:13:53.600035Z","iopub.status.idle":"2024-10-27T17:13:53.606176Z","shell.execute_reply.started":"2024-10-27T17:13:53.599997Z","shell.execute_reply":"2024-10-27T17:13:53.605232Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"query_lang = \"English\"\n\nquery_doc = \"Yeah so it's working OK but I need an update sent to Mr. Thomas Kylermanski at 89 Grovewood St. if possible by tomorrow. Login with K9xa123 to get the access if you need it\"","metadata":{"execution":{"iopub.status.busy":"2024-10-27T17:21:05.394548Z","iopub.execute_input":"2024-10-27T17:21:05.395414Z","iopub.status.idle":"2024-10-27T17:21:05.399819Z","shell.execute_reply.started":"2024-10-27T17:21:05.395375Z","shell.execute_reply":"2024-10-27T17:21:05.398776Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"FastLanguageModel.for_inference(model) # Unsloth has 2x faster inference!\n\ninputs = tokenizer(inference_prompt_template.format(text_lang=query_lang, orig_text=query_doc), return_tensors = \"pt\").to(\"cuda\")\n\noutputs = model.generate(input_ids = inputs.input_ids,\n                         attention_mask = inputs.attention_mask,\n                         max_new_tokens = 500)\n\n#tokenizer.batch_decode(outputs)","metadata":{"execution":{"iopub.status.busy":"2024-10-27T17:21:08.753256Z","iopub.execute_input":"2024-10-27T17:21:08.753663Z","iopub.status.idle":"2024-10-27T17:21:16.343949Z","shell.execute_reply.started":"2024-10-27T17:21:08.753624Z","shell.execute_reply":"2024-10-27T17:21:16.343146Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"res = tokenizer.batch_decode(outputs)\n\n# add 0 here - might not work when have several in batch TODO: test with dataset not just 1 sample\nstart_idx = res[0].index(\"### LABELLED DOCUMENT:\\n\\n\")\n\nprint(start_idx)\n\ngenerated_response = res[0][start_idx + len(\"### LABELLED DOCUMENT:\\n\\n\"):]\n\n","metadata":{"execution":{"iopub.status.busy":"2024-10-27T17:22:14.726684Z","iopub.execute_input":"2024-10-27T17:22:14.727094Z","iopub.status.idle":"2024-10-27T17:22:14.734442Z","shell.execute_reply.started":"2024-10-27T17:22:14.727055Z","shell.execute_reply":"2024-10-27T17:22:14.733439Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"1450\n","output_type":"stream"}]},{"cell_type":"code","source":"print(generated_response)","metadata":{"execution":{"iopub.status.busy":"2024-10-27T17:22:48.614267Z","iopub.execute_input":"2024-10-27T17:22:48.614672Z","iopub.status.idle":"2024-10-27T17:22:48.619736Z","shell.execute_reply.started":"2024-10-27T17:22:48.614635Z","shell.execute_reply":"2024-10-27T17:22:48.618778Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"Yeah so it's working OK but I need an update sent to <START OF IDENTIFIABLE INFORMATION : NAME>Mr. Thomas Kylermanski<END OF IDENTIFIABLE INFORMATION : NAME> at <START OF IDENTIFIABLE INFORMATION : STREET_ADDRESS>89 Grovewood St.<END OF IDENTIFIABLE INFORMATION : STREET_ADDRESS> if possible by tomorrow. Login with <START OF IDENTIFIABLE INFORMATION : USER_NAME>K9xa123<END OF IDENTIFIABLE INFORMATION : USER_NAME> to get the access if you need it<|end_of_text|>\n","output_type":"stream"}]},{"cell_type":"code","source":"query_lang = \"French\"\n\nquery_doc = \"oui je vous entends, mais c'est déjà envoyé chez vous au 23 bvd du Centre - je vous invite à me recontacter au 04 78 21 32 01 s'il y a toujours des soucis. On vous enverra un technicien de FibreMax Services pour voir sinon\"","metadata":{"execution":{"iopub.status.busy":"2024-10-27T17:25:20.143768Z","iopub.execute_input":"2024-10-27T17:25:20.144227Z","iopub.status.idle":"2024-10-27T17:25:20.149066Z","shell.execute_reply.started":"2024-10-27T17:25:20.144177Z","shell.execute_reply":"2024-10-27T17:25:20.148128Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"inputs = tokenizer(inference_prompt_template.format(text_lang=query_lang, orig_text=query_doc), return_tensors = \"pt\").to(\"cuda\")\n\noutputs = model.generate(input_ids = inputs.input_ids,\n                         attention_mask = inputs.attention_mask,\n                         max_new_tokens = 500)\n\nres = tokenizer.batch_decode(outputs)\n\n# add 0 here - might not work when have several in batch TODO: test with dataset not just 1 sample\nstart_idx = res[0].index(\"### LABELLED DOCUMENT:\\n\\n\")\n\nprint(start_idx)\n\ngenerated_response = res[0][start_idx + len(\"### LABELLED DOCUMENT:\\n\\n\"):]\n\nprint(generated_response)","metadata":{"execution":{"iopub.status.busy":"2024-10-27T17:25:40.394387Z","iopub.execute_input":"2024-10-27T17:25:40.394808Z","iopub.status.idle":"2024-10-27T17:25:49.435955Z","shell.execute_reply.started":"2024-10-27T17:25:40.394770Z","shell.execute_reply":"2024-10-27T17:25:49.434964Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stdout","text":"1499\noui je vous entends, mais c'est déjà envoyé chez vous au <START OF IDENTIFIABLE INFORMATION : STREET_ADDRESS>23 bvd du Centre<END OF IDENTIFIABLE INFORMATION : STREET_ADDRESS> - je vous invite à me recontacter au <START OF IDENTIFIABLE INFORMATION : PHONE_NUMBER>04 78 21 32 01<END OF IDENTIFIABLE INFORMATION : PHONE_NUMBER> s'il y a toujours des soucis. On vous enverra un technicien de <START OF IDENTIFIABLE INFORMATION : COMPANY>FibreMax Services<END OF IDENTIFIABLE INFORMATION : COMPANY> pour voir sinon<|end_of_text|>\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# saving","metadata":{}},{"cell_type":"code","source":"from huggingface_hub import notebook_login\n\nnotebook_login()","metadata":{"execution":{"iopub.status.busy":"2024-10-27T17:34:25.078981Z","iopub.execute_input":"2024-10-27T17:34:25.079796Z","iopub.status.idle":"2024-10-27T17:34:25.106836Z","shell.execute_reply.started":"2024-10-27T17:34:25.079754Z","shell.execute_reply":"2024-10-27T17:34:25.105930Z"},"trusted":true},"execution_count":55,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40e4b57e9a4f4fdead2cf4cd630549ac"}},"metadata":{}}]},{"cell_type":"code","source":"SAVE_NAME = \"Llama-3.1-8B\"\n\nmodel.push_to_hub(f\"benjaminzwhite/{SAVE_NAME}_pii-tags-test_LoRA\") \ntokenizer.push_to_hub(f\"benjaminzwhite/{SAVE_NAME}_pii-tags-test_LoRA\")","metadata":{"execution":{"iopub.status.busy":"2024-10-27T17:35:28.022037Z","iopub.execute_input":"2024-10-27T17:35:28.022507Z","iopub.status.idle":"2024-10-27T17:35:34.549919Z","shell.execute_reply.started":"2024-10-27T17:35:28.022468Z","shell.execute_reply":"2024-10-27T17:35:34.549080Z"},"trusted":true},"execution_count":56,"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/595 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d2e404b4211460a92b13c1624a1ff8f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"acfa9acb636a4367abcd2828aed10db0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/168M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"30ddf37be0c7479a8a1422e840890c4d"}},"metadata":{}},{"name":"stdout","text":"Saved model to https://huggingface.co/benjaminzwhite/Llama-3.1-8B_pii-tags-test_LoRA\n","output_type":"stream"}]},{"cell_type":"code","source":"#quant_methods = [\"q2_k\", \"q3_k_m\", \"q4_k_m\", \"q5_k_m\", \"q6_k\", \"q8_0\"]\nquant_methods = [\"q4_k_m\"]\nfor quant in quant_methods:\n    model.push_to_hub_gguf(f\"benjaminzwhite/{SAVE_NAME}_pii-tags-test_GGUF\", tokenizer, quant)","metadata":{"execution":{"iopub.status.busy":"2024-10-27T17:42:07.179227Z","iopub.execute_input":"2024-10-27T17:42:07.180151Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Cloning into 'llama.cpp'...\nSubmodule 'kompute' (https://github.com/nomic-ai/kompute.git) registered for path 'ggml/src/kompute'\nCloning into '/kaggle/working/llama.cpp/ggml/src/kompute'...\nSubmodule path 'ggml/src/kompute': checked out '4565194ed7c32d1d2efa32ceab4d3c6cae006306'\nmake: Entering directory '/kaggle/working/llama.cpp'\nI ccache not found. Consider installing it for faster compilation.\nI llama.cpp build info: \nI UNAME_S:   Linux\nI UNAME_P:   x86_64\nI UNAME_M:   x86_64\nI CFLAGS:    -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_AMX  -std=c11   -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -pthread -march=native -mtune=native -fopenmp -Wdouble-promotion \nI CXXFLAGS:  -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_AMX \nI NVCCFLAGS: -std=c++11 -O3 -g \nI LDFLAGS:    \nI CC:        cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\nI CXX:       c++ (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n\nrm -vrf *.dot libllava.a llama-baby-llama llama-batched llama-batched-bench llama-bench llama-cli llama-convert-llama2c-to-ggml llama-embedding llama-eval-callback llama-export-lora llama-gbnf-validator llama-gguf llama-gguf-hash llama-gguf-split llama-gritlm llama-imatrix llama-infill llama-llava-cli llama-minicpmv-cli llama-lookahead llama-lookup llama-lookup-create llama-lookup-merge llama-lookup-stats llama-parallel llama-passkey llama-perplexity llama-q8dot llama-quantize llama-quantize-stats llama-retrieval llama-save-load-state llama-server llama-simple llama-speculative llama-tokenize llama-vdot llama-cvector-generator llama-gen-docs tests/test-c.o tests/test-arg-parser tests/test-autorelease tests/test-backend-ops tests/test-chat-template tests/test-double-float tests/test-grad0 tests/test-grammar-integration tests/test-grammar-parser tests/test-json-schema-to-grammar tests/test-llama-grammar tests/test-log tests/test-model-load-cancel tests/test-opt tests/test-quantize-fns tests/test-quantize-perf tests/test-rope tests/test-sampling tests/test-tokenizer-0 tests/test-tokenizer-1-bpe tests/test-tokenizer-1-spm\nrm -rvf src/*.o\nrm -rvf tests/*.o\nrm -rvf examples/*.o\nrm -rvf common/*.o\nrm -rvf *.a\nrm -rvf *.dll\nrm -rvf *.so\nrm -rvf *.dot\nrm -rvf ggml/*.a\nrm -rvf ggml/*.dll\nrm -rvf ggml/*.so\nrm -vrf ggml/src/*.o\nrm -rvf ggml/src/llamafile/*.o\nrm -rvf common/build-info.cpp\nrm -vrf ggml/src/ggml-metal-embed.metal\nrm -vrf ggml/src/ggml-cuda/*.o\nrm -vrf ggml/src/ggml-cuda/template-instances/*.o\nrm -vrf ggml/src/ggml-amx/*.o\nrm -rvf libllava.a llama-baby-llama llama-batched llama-batched-bench llama-bench llama-cli llama-convert-llama2c-to-ggml llama-embedding llama-eval-callback llama-export-lora llama-gbnf-validator llama-gguf llama-gguf-hash llama-gguf-split llama-gritlm llama-imatrix llama-infill llama-llava-cli llama-minicpmv-cli llama-lookahead llama-lookup llama-lookup-create llama-lookup-merge llama-lookup-stats llama-parallel llama-passkey llama-perplexity llama-q8dot llama-quantize llama-quantize-stats llama-retrieval llama-save-load-state llama-server llama-simple llama-speculative llama-tokenize llama-vdot llama-cvector-generator llama-gen-docs tests/test-c.o\nrm -rvf tests/test-arg-parser tests/test-autorelease tests/test-backend-ops tests/test-chat-template tests/test-double-float tests/test-grad0 tests/test-grammar-integration tests/test-grammar-parser tests/test-json-schema-to-grammar tests/test-llama-grammar tests/test-log tests/test-model-load-cancel tests/test-opt tests/test-quantize-fns tests/test-quantize-perf tests/test-rope tests/test-sampling tests/test-tokenizer-0 tests/test-tokenizer-1-bpe tests/test-tokenizer-1-spm\nrm -f vulkan-shaders-gen ggml/src/ggml-vulkan-shaders.hpp ggml/src/ggml-vulkan-shaders.cpp\nrm -rvf main quantize quantize-stats perplexity imatrix embedding vdot q8dot convert-llama2c-to-ggml simple batched batched-bench save-load-state server gguf gguf-split eval-callback llama-bench libllava.a llava-cli baby-llama retrieval speculative infill tokenize parallel export-lora lookahead lookup passkey gritlm\nfind examples pocs -type f -name \"*.o\" -delete\nmake: Leaving directory '/kaggle/working/llama.cpp'\nmake: Entering directory '/kaggle/working/llama.cpp'\nI ccache not found. Consider installing it for faster compilation.\nI llama.cpp build info: \nI UNAME_S:   Linux\nI UNAME_P:   x86_64\nI UNAME_M:   x86_64\nI CFLAGS:    -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_AMX  -std=c11   -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -pthread -march=native -mtune=native -fopenmp -Wdouble-promotion \nI CXXFLAGS:  -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_AMX \nI NVCCFLAGS: -std=c++11 -O3 -g \nI LDFLAGS:    \nI CC:        cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\nI CXX:       c++ (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n\nc++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_AMX  -c ggml/src/llamafile/sgemm.cpp -o ggml/src/llamafile/sgemm.o\nc++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_AMX  -c ggml/src/ggml-amx.cpp -o ggml/src/ggml-amx.o\nc++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_AMX  -c ggml/src/ggml-amx/mmq.cpp -o ggml/src/ggml-amx/mmq.o\ncc  -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_AMX  -std=c11   -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -pthread -march=native -mtune=native -fopenmp -Wdouble-promotion    -c ggml/src/ggml.c -o ggml/src/ggml.o\ncc  -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_AMX  -std=c11   -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -pthread -march=native -mtune=native -fopenmp -Wdouble-promotion    -c ggml/src/ggml-alloc.c -o ggml/src/ggml-alloc.o\nc++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_AMX  -c ggml/src/ggml-backend.cpp -o ggml/src/ggml-backend.o\ncc -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_AMX  -std=c11   -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -pthread -march=native -mtune=native -fopenmp -Wdouble-promotion     -c ggml/src/ggml-quants.c -o ggml/src/ggml-quants.o\ncc -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_AMX  -std=c11   -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -pthread -march=native -mtune=native -fopenmp -Wdouble-promotion     -c ggml/src/ggml-aarch64.c -o ggml/src/ggml-aarch64.o\nc++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_AMX  -c src/llama.cpp -o src/llama.o\nc++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_AMX  -c src/llama-vocab.cpp -o src/llama-vocab.o\nc++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_AMX  -c src/llama-grammar.cpp -o src/llama-grammar.o\nc++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_AMX  -c src/llama-sampling.cpp -o src/llama-sampling.o\nc++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_AMX  -c src/unicode.cpp -o src/unicode.o\nc++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_AMX  -c src/unicode-data.cpp -o src/unicode-data.o\nc++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_AMX  -c common/common.cpp -o common/common.o\nc++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_AMX  -c common/arg.cpp -o common/arg.o\nc++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_AMX  -c common/log.cpp -o common/log.o\nc++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_AMX  -c common/console.cpp -o common/console.o\nc++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_AMX  -c common/ngram-cache.cpp -o common/ngram-cache.o\nc++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_AMX  -c common/sampling.cpp -o common/sampling.o\nc++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_AMX  -c common/train.cpp -o common/train.o\nc++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_AMX  -c common/json-schema-to-grammar.cpp -o common/json-schema-to-grammar.o\ncc -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_AMX  -std=c11   -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -pthread -march=native -mtune=native -fopenmp -Wdouble-promotion  -Iexamples/gguf-hash/deps -c examples/gguf-hash/deps/sha1/sha1.c -o examples/gguf-hash/deps/sha1/sha1.o\ncc -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_AMX  -std=c11   -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -pthread -march=native -mtune=native -fopenmp -Wdouble-promotion  -Iexamples/gguf-hash/deps -c examples/gguf-hash/deps/xxhash/xxhash.c -o examples/gguf-hash/deps/xxhash/xxhash.o\ncc -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_AMX  -std=c11   -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -pthread -march=native -mtune=native -fopenmp -Wdouble-promotion  -Iexamples/gguf-hash/deps -c examples/gguf-hash/deps/sha256/sha256.c -o examples/gguf-hash/deps/sha256/sha256.o\nc++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_AMX  -c pocs/vdot/vdot.cpp -o pocs/vdot/vdot.o\ncc -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_AMX  -std=c11   -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -pthread -march=native -mtune=native -fopenmp -Wdouble-promotion  -c tests/test-c.c -o tests/test-c.o\nc++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_AMX  -c tests/test-backend-ops.cpp -o tests/test-backend-ops.o\nc++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_AMX  -c tests/test-double-float.cpp -o tests/test-double-float.o\nc++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_AMX  ggml/src/ggml.o ggml/src/llamafile/sgemm.o ggml/src/ggml-amx.o ggml/src/ggml-amx/mmq.o ggml/src/ggml-alloc.o ggml/src/ggml-backend.o ggml/src/ggml-quants.o ggml/src/ggml-aarch64.o pocs/vdot/vdot.o -o llama-vdot  \nc++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_AMX  -c tests/test-grad0.cpp -o tests/test-grad0.o\nc++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_AMX   tests/test-double-float.o -o tests/test-double-float  \nc++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_AMX  -c tests/test-opt.cpp -o tests/test-opt.o\nc++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_AMX  ggml/src/llamafile/sgemm.o ggml/src/ggml-amx.o ggml/src/ggml-amx/mmq.o ggml/src/ggml.o ggml/src/ggml-alloc.o ggml/src/ggml-backend.o ggml/src/ggml-quants.o ggml/src/ggml-aarch64.o tests/test-opt.o -o tests/test-opt  \nc++ -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DGGML_USE_AMX  -c tests/test-quantize-fns.cpp -o tests/test-quantize-fns.o\n","output_type":"stream"}]}]}