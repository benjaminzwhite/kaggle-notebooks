{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Full ABSA task with Phi3\n\n- do EDA on dataset (get list of all possible aspect categories and sentiments)\n- run some of the dataset through a baseline phi3 mini to see\n- study parsing of results, and how to eval also","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset","metadata":{"execution":{"iopub.status.busy":"2024-09-16T20:30:04.328331Z","iopub.execute_input":"2024-09-16T20:30:04.328654Z","iopub.status.idle":"2024-09-16T20:30:05.936161Z","shell.execute_reply.started":"2024-09-16T20:30:04.328620Z","shell.execute_reply":"2024-09-16T20:30:05.935266Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"absa_quad = load_dataset(\"NEUDM/absa-quad\")","metadata":{"execution":{"iopub.status.busy":"2024-09-16T20:30:37.991442Z","iopub.execute_input":"2024-09-16T20:30:37.991999Z","iopub.status.idle":"2024-09-16T20:30:40.632339Z","shell.execute_reply.started":"2024-09-16T20:30:37.991964Z","shell.execute_reply":"2024-09-16T20:30:40.631514Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/2.83k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f5288e5dbb94f09b85ce33bdad22aa5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/2.00M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b854bbd25e9042d19eab2a94b9c32ba1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/503k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"17850c9f02904e1191b1c49576ccc706"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/1.03M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57a75b87e1e540ba9c26ff7d4a4c4a33"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/2098 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c1c1688231f48a18a9bc45bf4969256"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/525 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6197b08e3d2a43fe8a426a7512dfc58f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/1081 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8349b980e1984c2084bf5a9a62d35cef"}},"metadata":{}}]},{"cell_type":"code","source":"absa_quad","metadata":{"execution":{"iopub.status.busy":"2024-09-16T20:30:48.180732Z","iopub.execute_input":"2024-09-16T20:30:48.181528Z","iopub.status.idle":"2024-09-16T20:30:48.188790Z","shell.execute_reply.started":"2024-09-16T20:30:48.181487Z","shell.execute_reply":"2024-09-16T20:30:48.187596Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['task_type', 'dataset', 'input', 'output', 'situation', 'label', 'extra', 'instruction'],\n        num_rows: 2098\n    })\n    validation: Dataset({\n        features: ['task_type', 'dataset', 'input', 'output', 'situation', 'label', 'extra', 'instruction'],\n        num_rows: 525\n    })\n    test: Dataset({\n        features: ['task_type', 'dataset', 'input', 'output', 'situation', 'label', 'extra', 'instruction'],\n        num_rows: 1081\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"import ast","metadata":{"execution":{"iopub.status.busy":"2024-09-16T20:39:45.403579Z","iopub.execute_input":"2024-09-16T20:39:45.404312Z","iopub.status.idle":"2024-09-16T20:39:45.408521Z","shell.execute_reply.started":"2024-09-16T20:39:45.404275Z","shell.execute_reply":"2024-09-16T20:39:45.407414Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"ALL_SENTIMENTS = []\nALL_ASPECT_CATEGORIES = []\n\nfor example in absa_quad[\"train\"].iter(batch_size=1):\n    output_as_str = example[\"output\"][0]\n    \n    # list of quads\n    xs = ast.literal_eval(output_as_str)\n    for quad in xs:\n        ALL_SENTIMENTS.append(quad[2])\n        #if quad[2] == \"neutral\":\n        #    print(example) # <-- used to get examples with neutral for the prompt\n        ALL_ASPECT_CATEGORIES.append(quad[1])","metadata":{"execution":{"iopub.status.busy":"2024-09-16T21:09:34.293721Z","iopub.execute_input":"2024-09-16T21:09:34.294450Z","iopub.status.idle":"2024-09-16T21:09:34.553308Z","shell.execute_reply.started":"2024-09-16T21:09:34.294412Z","shell.execute_reply":"2024-09-16T21:09:34.552348Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"len(ALL_SENTIMENTS), len(ALL_ASPECT_CATEGORIES)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T20:41:01.888983Z","iopub.execute_input":"2024-09-16T20:41:01.889389Z","iopub.status.idle":"2024-09-16T20:41:01.895679Z","shell.execute_reply.started":"2024-09-16T20:41:01.889349Z","shell.execute_reply":"2024-09-16T20:41:01.894714Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"(3343, 3343)"},"metadata":{}}]},{"cell_type":"code","source":"from collections import Counter\n\nsentiment_cnt = Counter(ALL_SENTIMENTS)\naspect_category_cnt = Counter(ALL_ASPECT_CATEGORIES)\n\nsentiment_cnt, aspect_category_cnt","metadata":{"execution":{"iopub.status.busy":"2024-09-16T20:41:44.691929Z","iopub.execute_input":"2024-09-16T20:41:44.692323Z","iopub.status.idle":"2024-09-16T20:41:44.700635Z","shell.execute_reply.started":"2024-09-16T20:41:44.692286Z","shell.execute_reply":"2024-09-16T20:41:44.699731Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"(Counter({'positive': 2374, 'negative': 873, 'neutral': 96}),\n Counter({'food quality': 1195,\n          'service general': 597,\n          'restaurant general': 502,\n          'ambience general': 379,\n          'food style_options': 163,\n          'restaurant miscellaneous': 121,\n          'food prices': 103,\n          'restaurant prices': 98,\n          'drinks quality': 67,\n          'drinks style_options': 51,\n          'location general': 39,\n          'drinks prices': 27,\n          'food general': 1}))"},"metadata":{}}]},{"cell_type":"markdown","source":"# Load model and prepare for baseline evaluation","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, set_seed\n\nimport torch","metadata":{"execution":{"iopub.status.busy":"2024-09-16T20:42:49.624905Z","iopub.execute_input":"2024-09-16T20:42:49.625285Z","iopub.status.idle":"2024-09-16T20:43:06.384337Z","shell.execute_reply.started":"2024-09-16T20:42:49.625251Z","shell.execute_reply":"2024-09-16T20:43:06.383550Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\nMODEL_NAME = \"microsoft/Phi-3-mini-4k-instruct\"\n\nmodel = AutoModelForCausalLM.from_pretrained( \n    MODEL_NAME,  \n    device_map=device,  \n    torch_dtype=\"auto\",  \n    trust_remote_code=True,  \n) \n\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T20:43:12.148408Z","iopub.execute_input":"2024-09-16T20:43:12.149456Z","iopub.status.idle":"2024-09-16T20:44:06.442387Z","shell.execute_reply.started":"2024-09-16T20:43:12.149406Z","shell.execute_reply":"2024-09-16T20:44:06.441594Z"},"trusted":true},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/967 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"744ccdf263de49b7b3e9107a6ea843a6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"configuration_phi3.py:   0%|          | 0.00/11.2k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"973d8e41be024804898043257e2f1e4e"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-mini-4k-instruct:\n- configuration_phi3.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modeling_phi3.py:   0%|          | 0.00/73.2k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12b17e9af3a342dba527723f7e798c98"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-mini-4k-instruct:\n- modeling_phi3.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/16.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cac09cca629f45d5a972f28997a96a02"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"950ec06e88014eb1aec06e445a4116eb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"09ae7b86d3174e3ea6048ae23816284e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/2.67G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ae938763eee409b8a3e3ac5cb30bd02"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed585b23955a493c81a34913250f1767"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/181 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eaaa0173b6a84102983cc3e175af9486"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/3.44k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"71a281ec7bf1451d90d510056bb57ea2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e9b0f6f3456465dab850deafb2f50c1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.94M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1bb473c626c4a09b392d7b6d9c44309"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/306 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"280f6676dcee4f448cee9fc3e0d9bed3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/599 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6b369c129ec428c8305241714c452a1"}},"metadata":{}}]},{"cell_type":"markdown","source":"## Prompt template","metadata":{}},{"cell_type":"code","source":"template = \"\"\"## INSTRUCTIONS ##\n\nAspect-based sentiment analysis requires you to identify terms in a sentence that correspond to a person expressing an opinion. Each sentence may have several opinion terms. An opinion term is the exact string of words about which a sentiment is being expressed. The justification is the exact string of words, if any, that justifies or explains the corresponding opinion term.\n\nBelow are some examples of aspect-based sentiment analysis performed on different restaurant reviews.\n\nThen there is a list of Aspect Categories: each category is a feature of interest to classifying a specific part of the review, such as \"ambience general\" or \"food style_options\".\n\nThen there is a list of allowed Sentiments that you can label each opinion term with.\n\nFinally there is a query which consists of an actual telephone product review. Perform the same aspect-based sentiment analysis as shown in the example. Extract the terms and the justifications directly from the review, without any modification. Only use labels given in the Aspect Category list and in the Sentiment list. Use the exact word NULL if there is no occurrence in the sentence for any of the individual requested items in the output. Follow the exact same output formatting without deviation.\n\n## EXAMPLES OF ASPECT-BASED SENTIMENT ANALYSIS ##\n\n{examples_absa}\n\n## LIST OF ASPECT CATEGORIES ##\n\n- food quality\n- service general\n- restaurant general\n- ambience general\n- food style_options\n- restaurant miscellaneous\n- food prices\n- restaurant prices\n- drinks quality\n- drinks style_options\n- location general\n- drinks prices\n- food general\n\n## LIST OF SENTIMENTS ##\n\n- positive\n- negative\n- neutral\n\n## QUERY ##\n\nrestaurant review: {query}\nabsa output:\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-09-16T21:19:03.570042Z","iopub.execute_input":"2024-09-16T21:19:03.570444Z","iopub.status.idle":"2024-09-16T21:19:03.576220Z","shell.execute_reply.started":"2024-09-16T21:19:03.570399Z","shell.execute_reply":"2024-09-16T21:19:03.575248Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# TODO - try adding a summarize-first step, then generate ABSA\nexamples_absa = \"\"\"\nrestaurant review: I can not imagine better Indian food in all of the city.\nabsa output:\n[{ \\\"opinion term\\\": \\\"Indian food\\\", \\\"aspect category\\\": \\\"food quality\\\", \\\"sentiment\\\": \\\"positive\\\", \\\"justification\\\": \\\"better\\\" }]\n\nrestaurant review: I've been many times and have never been disappointed.\nabsa output:\n[{ \\\"opinion term\\\": \\\"NULL\\\", \\\"aspect category\\\": \\\"restaurant general\\\", \\\"sentiment\\\": \\\"positive\\\", \\\"justification\\\": \\\"never been disappointed\\\" }]\n\nrestaurant review: \"Skip this restaurant, it 's a big disappointment.\"\nabsa output:\n[{ \\\"opinion term\\\": \\\"restaurant\\\", \\\"aspect category\\\": \\\"restaurant general\\\", \\\"sentiment\\\": \\\"negative\\\", \\\"justification\\\": \\\"Skip\\\" }, { \\\"opinion term\\\": \\\"restaurant\\\", \\\"aspect category\\\": \\\"restaurant general\\\", \\\"sentiment\\\": \\\"negative\\\", \\\"justification\\\": \\\"disappointment\\\" }]\n\nrestaurant review: \"With the exception of our lemon salad that had so much pepper on it that our eyes started watering, the food here was decent, not great.\"\nabsa output:\n[{ \\\"opinion term\\\": \\\"food\\\", \\\"aspect category\\\": \\\"food quality\\\", \\\"sentiment\\\": \\\"neutral\\\", \\\"justification\\\": \\\"decent\\\" }, { \\\"opinion term\\\": \\\"food\\\", \\\"aspect category\\\": \\\"food quality\\\", \\\"sentiment\\\": \\\"negative\\\", \\\"justification\\\": \\\"not great\\\" }, { \\\"opinion term\\\": \\\"lemon salad\\\", \\\"aspect category\\\": \\\"food quality\\\", \\\"sentiment\\\": \\\"negative\\\", \\\"justification\\\": \\\"exception\\\" }]\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-09-16T21:21:06.487533Z","iopub.execute_input":"2024-09-16T21:21:06.488321Z","iopub.status.idle":"2024-09-16T21:21:06.494007Z","shell.execute_reply.started":"2024-09-16T21:21:06.488283Z","shell.execute_reply":"2024-09-16T21:21:06.492983Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"pipe = pipeline(\n    \"text-generation\",\n    model=model,\n    tokenizer=tokenizer,\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T21:17:43.800447Z","iopub.execute_input":"2024-09-16T21:17:43.801336Z","iopub.status.idle":"2024-09-16T21:17:43.805806Z","shell.execute_reply.started":"2024-09-16T21:17:43.801294Z","shell.execute_reply":"2024-09-16T21:17:43.804755Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"## Test single example","metadata":{}},{"cell_type":"code","source":"for example in absa_quad[\"train\"].iter(batch_size=1):\n    example_text = example[\"input\"][0]\n    #print(example_text, type(example_text))\n    input_text = ast.literal_eval(example_text)[0]\n    \n    prompt = template.format(examples_absa=examples_absa, query=input_text)\n\n    messages = [ \n        {\"role\": \"system\", \"content\": \"You are helpful asssistant that performs aspect-based sentiment analysis on restaurant reviews. You strictly follow all formatting instructions without deviation.\"}, \n        {\"role\": \"user\", \"content\": prompt}, \n    ] \n\n    generation_args = { \n        \"max_new_tokens\": 500, \n        \"return_full_text\": False, \n        \"temperature\": 0.0, \n        #\"do_sample\": False, \n    }\n    \n    output = pipe(messages, **generation_args)\n    \n    print(\"==== INPUT TEXT ====\")\n    print(input_text)\n    print(\"---- MODEL OUTPUT ----\")\n    print(output[0]['generated_text'])\n    \n    break","metadata":{"execution":{"iopub.status.busy":"2024-09-16T21:21:11.088195Z","iopub.execute_input":"2024-09-16T21:21:11.088615Z","iopub.status.idle":"2024-09-16T21:21:24.547504Z","shell.execute_reply.started":"2024-09-16T21:21:11.088573Z","shell.execute_reply":"2024-09-16T21:21:24.546552Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"==== INPUT TEXT ====\nThe wait here is long for dim sum , but if you do n't like sharing tables or if the typical raucous dim sum atmosphere is not your gig , this is a sleek ( for Chinatown ) alternative .\n---- MODEL OUTPUT ----\n [{ \"opinion term\": \"wait\", \"aspect category\": \"service general\", \"sentiment\": \"negative\", \"justification\": \"long\" }, { \"opinion term\": \"dim sum\", \"aspect category\": \"food quality\", \"sentiment\": \"neutral\", \"justification\": \"for\" }, { \"opinion term\": \"tables\", \"aspect category\": \"restaurant general\", \"sentiment\": \"negative\", \"justification\": \"don't like sharing\" }, { \"opinion term\": \"dim sum atmosphere\", \"aspect category\": \"ambience general\", \"sentiment\": \"negative\", \"justification\": \"not your gig\" }, { \"opinion term\": \"sleek\", \"aspect category\": \"restaurant general\", \"sentiment\": \"positive\", \"justification\": \"alternative\" }, { \"opinion term\": \"Chinatown\", \"aspect category\": \"location general\", \"sentiment\": \"positive\", \"justification\": \"for\" }]\n","output_type":"stream"}]},{"cell_type":"code","source":"import json\n\n# note has leading whitespace, but json loads seems to work ok\ntest_json = json.loads( output[0]['generated_text'] )\n\ntest_json","metadata":{"execution":{"iopub.status.busy":"2024-09-16T21:33:06.152637Z","iopub.execute_input":"2024-09-16T21:33:06.153624Z","iopub.status.idle":"2024-09-16T21:33:06.161171Z","shell.execute_reply.started":"2024-09-16T21:33:06.153569Z","shell.execute_reply":"2024-09-16T21:33:06.160187Z"},"trusted":true},"execution_count":39,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"[{'opinion term': 'wait',\n  'aspect category': 'service general',\n  'sentiment': 'negative',\n  'justification': 'long'},\n {'opinion term': 'dim sum',\n  'aspect category': 'food quality',\n  'sentiment': 'neutral',\n  'justification': 'for'},\n {'opinion term': 'tables',\n  'aspect category': 'restaurant general',\n  'sentiment': 'negative',\n  'justification': \"don't like sharing\"},\n {'opinion term': 'dim sum atmosphere',\n  'aspect category': 'ambience general',\n  'sentiment': 'negative',\n  'justification': 'not your gig'},\n {'opinion term': 'sleek',\n  'aspect category': 'restaurant general',\n  'sentiment': 'positive',\n  'justification': 'alternative'},\n {'opinion term': 'Chinatown',\n  'aspect category': 'location general',\n  'sentiment': 'positive',\n  'justification': 'for'}]"},"metadata":{}}]},{"cell_type":"markdown","source":"# Run train dataset through model\n\n- store raw completions, and the input text + its gold annotations","metadata":{}},{"cell_type":"code","source":"all_results = [] # store a list of jsons, each json contains input text, gold annotations, raw model completion\n\nEXAMPLES_TO_TEST = 50\nexample_counter = 0\n\nfor example in absa_quad[\"train\"].iter(batch_size=1):\n    \n    curr_example_data = {\"example_id\":example_counter, \"input_text\":None, \"gold_quads\":[]}\n    \n    # === process gold data and save it ===\n    example_text = example[\"input\"][0]\n    input_text = ast.literal_eval(example_text)[0]\n    curr_example_data[\"input_text\"] = input_text\n    \n    gold_labels = example[\"output\"][0]\n    \n    # go through list of quads\n    golds = ast.literal_eval(gold_labels)\n    for quad in golds:\n        tmp_d = {}\n        tmp_d[\"opinion term\"] = quad[0]\n        tmp_d[\"aspect category\"] = quad[1]\n        tmp_d[\"sentiment\"] = quad[2]\n        tmp_d[\"justification\"] = quad[3]\n        curr_example_data[\"gold_quads\"].append(tmp_d)\n    \n    # === GET MODEL COMPLETION ===\n    print(f\"=== Sending example number {example_counter} to model ===\")\n    #print(f\"--- current example is : {input_text} ---\")\n    \n    prompt = template.format(examples_absa=examples_absa, query=input_text)\n\n    messages = [ \n        {\"role\": \"system\", \"content\": \"You are helpful asssistant that performs aspect-based sentiment analysis on restaurant reviews. You strictly follow all formatting instructions without deviation.\"}, \n        {\"role\": \"user\", \"content\": prompt}, \n    ] \n\n    generation_args = { \n        \"max_new_tokens\": 500, \n        \"return_full_text\": False, \n        \"temperature\": 0.0, \n        #\"do_sample\": False, \n    }\n    \n    try:\n        output = pipe(messages, **generation_args)\n        raw_completion = output[0]['generated_text']\n        \n        curr_example_data[\"raw_completion\"] = raw_completion\n    except Exception as e:\n        print(example_counter, \"===>\", e)\n        curr_example_data[\"raw_completion\"] = \"__DID_NOT_COMPLETE__\"\n    \n    # === append full dict to all results list ===\n    all_results.append(curr_example_data)\n    #print(\"--- heading to next example ---\")\n    \n    # === loop logic ===\n    example_counter += 1\n    if example_counter >= EXAMPLES_TO_TEST:\n        break   ","metadata":{"execution":{"iopub.status.busy":"2024-09-16T22:00:22.013819Z","iopub.execute_input":"2024-09-16T22:00:22.014813Z","iopub.status.idle":"2024-09-16T22:05:37.674233Z","shell.execute_reply.started":"2024-09-16T22:00:22.014759Z","shell.execute_reply":"2024-09-16T22:05:37.673167Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"=== Sending example number 0 to model ===\n=== Sending example number 1 to model ===\n=== Sending example number 2 to model ===\n=== Sending example number 3 to model ===\n=== Sending example number 4 to model ===\n=== Sending example number 5 to model ===\n=== Sending example number 6 to model ===\n=== Sending example number 7 to model ===\n=== Sending example number 8 to model ===\n=== Sending example number 9 to model ===\n=== Sending example number 10 to model ===\n=== Sending example number 11 to model ===\n=== Sending example number 12 to model ===\n=== Sending example number 13 to model ===\n=== Sending example number 14 to model ===\n=== Sending example number 15 to model ===\n=== Sending example number 16 to model ===\n=== Sending example number 17 to model ===\n=== Sending example number 18 to model ===\n=== Sending example number 19 to model ===\n=== Sending example number 20 to model ===\n=== Sending example number 21 to model ===\n=== Sending example number 22 to model ===\n=== Sending example number 23 to model ===\n=== Sending example number 24 to model ===\n=== Sending example number 25 to model ===\n=== Sending example number 26 to model ===\n=== Sending example number 27 to model ===\n=== Sending example number 28 to model ===\n=== Sending example number 29 to model ===\n=== Sending example number 30 to model ===\n=== Sending example number 31 to model ===\n=== Sending example number 32 to model ===\n=== Sending example number 33 to model ===\n=== Sending example number 34 to model ===\n=== Sending example number 35 to model ===\n=== Sending example number 36 to model ===\n=== Sending example number 37 to model ===\n=== Sending example number 38 to model ===\n=== Sending example number 39 to model ===\n=== Sending example number 40 to model ===\n=== Sending example number 41 to model ===\n=== Sending example number 42 to model ===\n=== Sending example number 43 to model ===\n=== Sending example number 44 to model ===\n=== Sending example number 45 to model ===\n=== Sending example number 46 to model ===\n=== Sending example number 47 to model ===\n=== Sending example number 48 to model ===\n=== Sending example number 49 to model ===\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Save 50 results to JSON for later/offline","metadata":{}},{"cell_type":"code","source":"with open('absa-quad-phi3-baseline-inference-50-samples.json', 'w') as file:\n    json.dump(all_results, file)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T22:06:55.144402Z","iopub.execute_input":"2024-09-16T22:06:55.145345Z","iopub.status.idle":"2024-09-16T22:06:55.152409Z","shell.execute_reply.started":"2024-09-16T22:06:55.145301Z","shell.execute_reply":"2024-09-16T22:06:55.151504Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"!ls","metadata":{"execution":{"iopub.status.busy":"2024-09-16T22:06:58.462345Z","iopub.execute_input":"2024-09-16T22:06:58.463118Z","iopub.status.idle":"2024-09-16T22:06:59.491981Z","shell.execute_reply.started":"2024-09-16T22:06:58.463076Z","shell.execute_reply":"2024-09-16T22:06:59.490807Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"absa-quad-phi3-baseline-inference-50-samples.json\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Quick data analysis before close session\n\n- check how many of the 50 completions load directly to JSON\n- check how many times you get a Aspect Category or Sentiment label that is not in allowed list","metadata":{}},{"cell_type":"code","source":"# do this in pandas later, just quickly for now\ndoes_not_load_to_json = 0\n\nREFERENCE_KEYS = set( [\"opinion term\", \"aspect category\", \"sentiment\", \"justification\"])\nquad_dict_has_bad_keys = 0\ntotal_quad_dicts = 0\n\naspect_category_not_in_allowed = 0\n\nsentiment_not_in_allowed = 0\n\nfor single_result in all_results:\n    try:\n        json_completion = json.loads(single_result[\"raw_completion\"])\n        # go over aspect categories and sentiments\n        \n        for quad_dict in json_completion:\n            # check keys are those expected\n            if set(quad_dict.keys()) != REFERENCE_KEYS:\n                quad_dict_has_bad_keys += 1\n            total_quad_dicts += 1\n            \n            if quad_dict.get(\"aspect category\", None) not in aspect_category_cnt:\n                aspect_category_not_in_allowed += 1\n                \n            if quad_dict.get(\"sentiment\", None) not in sentiment_cnt:\n                sentiment_not_in_allowed += 1\n    except Exception as e:\n        does_not_load_to_json += 1\n        print(e)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T22:17:13.113682Z","iopub.execute_input":"2024-09-16T22:17:13.114069Z","iopub.status.idle":"2024-09-16T22:17:13.123163Z","shell.execute_reply.started":"2024-09-16T22:17:13.114032Z","shell.execute_reply":"2024-09-16T22:17:13.122162Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"print(total_quad_dicts)\nprint(quad_dict_has_bad_keys)\nprint(aspect_category_not_in_allowed)\nprint(sentiment_not_in_allowed)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T22:17:55.483101Z","iopub.execute_input":"2024-09-16T22:17:55.484070Z","iopub.status.idle":"2024-09-16T22:17:55.489251Z","shell.execute_reply.started":"2024-09-16T22:17:55.484027Z","shell.execute_reply":"2024-09-16T22:17:55.488210Z"},"trusted":true},"execution_count":56,"outputs":[{"name":"stdout","text":"85\n0\n0\n0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Temporary conclusions\n\n- seems like the behavior is 100% so far, without any structuring, just with good prompting","metadata":{}}]}